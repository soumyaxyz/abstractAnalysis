# 1
### http://arxiv.org/abs/cs/9809093v1
## A Delay Based Approach for Congestion Avoidance in Interconnected Heterogeneous Computer Networks


0	    In heterogeneous networks, achieving congestion avoidance is difficult because the congestion feedback from one subnetwork may have no meaning to source on other other subnetworks.
1	    We propose using changes in round-trip delay as an implicit feedback.
1	    Using a black-box model of the network, we derive an expression for the optimal window as a function of the gradient of the delay-window curve.
2	    The problems of selfish optimum and social optimum are also addressed.
2	    It is shown that without a careful design, it is possible to get into a race condition during heavy congestion, where each user wants more resources than others, thereby leading to a diverging congestion   It is shown that congestion avoidance using round trip delay is a promising approach.
2	    The aproach has the advantage that there is absolutely no overhead for the network itself.
1	    It is exemplified by a simple scheme.
1	    The performance of the scheme is analyzed using a simulation model.
2	    The scheme is shown to be efficient, fair, convergent and adaptive to changes in network configuration.
2	    The scheme as described works only for networks that can ne modelled with queueing servers with constant service times.
2	    Further research is required to extend it for implementation in practical networks.
2	    Several directions for future research have beensuggested.


# 2
### http://arxiv.org/abs/cs/9809095v1
## Congestion Avoidance in Computer Networks with a Connectionless Network Layer, Part I: Concepts, Goals and Methodology


0	    Congestion is said to occur in the network when the resource demands exceed the capacity and packets are lost due to too much queuing in the network.
0	    During congestion, the network throughput may drop to zero and the path delay may become very high.
0	    A congestion control scheme helps the network to recover from the congestion state.
1	    A congestion avoidance scheme allows a network to operate in the region of low delay and high throughput.
0	    Such schemes prevent a network from entering the congested state.
0	    Congestion avoidance is a prevention mechanism while congestion control is a recovery mechanism.
0	    We compare the concept of congestion avoidance with that of flow control and congestion control.
1	    A number of possible alternative for congestion avoidance have been identified.
1	    From these a few were selected for study.
1	    The criteria for selection and goals for these schemes have been described.
1	    In particular, we wanted the scheme to be globally efficient, fair, dynamic, convergent, robust, distributed, configuration independent, etc.
1	    These goals and the test cases used to verify whether a particular scheme has met the goals have been described.
1	    We model the network and the user policies for congestion avoidance as a feedback control system.
1	    The key components of a generic congestion avoidance scheme are: congestion detection, congestion feedback, feedback selector, signal filter, decision function, and increase/decrease algorithms.
2	    These components have been explained.


# 3
### http://arxiv.org/abs/cs/9905006v1
## The Design and Analysis of Virtual Network Configuration for a Wireless Mobile ATM Network


1	    This research concentrates on the design and analysis of an algorithm referred to as Virtual Network Configuration (VNC) which uses predicted future states of a system for faster network configuration and management.
1	    VNC is applied to the configuration of a wireless mobile ATM network.
1	    VNC is built on techniques from parallel discrete event simulation merged with constraints from real-time systems and applied to mobile ATM configuration and handoff.
1	    Configuration in a mobile network is a dynamic and continuous process.
1	    Factors such as load, distance, capacity and topology are all constantly changing in a mobile environment.
2	    The VNC algorithm anticipates configuration changes and speeds the reconfiguration process by pre-computing and caching results.
2	    VNC propagates local prediction results throughout the VNC enhanced system.
1	    The Global Positioning System is an enabling technology for the use of VNC in mobile networks because it provides location information and accurate time for each node.
0	    This research has resulted in well defined structures for the encapsulation of physical processes within Logical Processes and a generic library for enhancing a system with VNC.
0	    Enhancing an existing system with VNC is straight forward assuming the existing physical processes do not have side effects.
0	    The benefit of prediction is gained at the cost of additional traffic and processing.
1	    This research includes an analysis of VNC and suggestions for optimization of the VNC algorithm and its parameters.


# 4
### http://arxiv.org/abs/cs/0002011v1
## An Internet Multicast System for the Stock Market


0	    We are moving toward a distributed, international, twenty-four hour, electronic stock exchange.
0	    The exchange will use the global Internet, or internet technology.
0	    This system is a natural application of multicast because there are a large number of receivers that should receive the same information simultaneously.
0	    The data requirements for the stock exchange are discussed.
0	    The current multicast protocols lack the reliability, fairness, and scalability needed in this application.
1	    We describe a distributed architecture together with a reliable multicast protocol, a modification of the RMP protocol, that has characteristics appropriate for this application.
1	    The architecture is used in three applications: In the first, we construct a unified stock ticker of the transactions that are being conducted on the various physical and electronic exchanges.
0	    Our objective is to deliver the the same combined ticker reliably and simultaneously to all receivers, anywhere in the world.
1	    In the second, we construct a unified sequence of buy and sell offers that are delivered to a single exchange or a collection of exchanges.
1	    Our objective is to give all traders the same fair access to an exchange independent of their relative distances to the exchange or the loss characteristics of the international network.
1	    In the third, we construct a distributed, electronic trading floor that can replace the current exchanges.
1	    This application uses the innovations from the first two applications to combine their fairness attributes.


# 5
### http://arxiv.org/abs/cs/0105031v1
## State Analysis and Aggregation Study for Multicast-based Micro Mobility


0	    IP mobility addresses the problem of changing the network point-of-attachment transparently during movement.
0	    Mobile IP is the proposed standard by IETF.
0	    Several studies, however, have shown that Mobile IP has several drawbacks, such as triangle routing and poor handoff performance.
0	    Multicast-based mobility has been proposed as a promising solution to the above problems, incurring less end-to-end delays and fast smooth handoff.
1	    Nonetheless, such architecture suffers from multicast state scalability problems with the growth in number of mobile nodes.
2	    This architecture also requires ubiquitous multicast deployment and more complex security measures.
1	    To alleviate these problems, we propose an intra-domain multicast-based mobility solution.
1	    A mobility proxy allocates a multicast address for each mobile that moves to its domain.
1	    The mobile uses this multicast address within a domain for micro mobility.
1	    Also, aggregation is considered to reduce the multicast state.
1	    We conduct multicast state analysis to study the efficiency of several aggregation techniques.
1	    We use extensive simulation to evaluate our protocol's performance over a variety of real and generated topologies.
1	    We take aggregation gain as metric for our evaluation.
2	    Our simulation results show that in general leaky aggregation obtains better gains than perfect aggregation.
2	    Also, we notice that aggregation gain increases with the increase in number of visiting mobile nodes and with the decrease in number of mobility proxies within a domain.


# 6
### http://arxiv.org/abs/cs/0208024v1
## Contact-Based Architecture for Resource Discovery (CARD) in Large Scale MANets


0	    In this paper we propose a novel architecture, CARD, for resource discovery in large scale Mobile Ad hoc Networks (MANets) which, may scale up to thousands of nodes and may span wide geographical regions.
1	    Unlike previously proposed schemes, our architecture avoids expensive mechanisms such as global flooding as well as complex coordination between nodes to form a hierarchy.
1	    CARD is also independent of any external source of information such as GPS.
1	    In our architecture nodes within a limited number of hops from each node form the neighborhood of that node.
1	    Resources within the neighborhood can be readily accessed with the help of a proactive scheme within the neighborhood.
1	    For accessing resources beyond the neighborhood, each node also maintains a few distant nodes called contacts.
1	    Contacts help in creating a small world in the network and provide an efficient way to query for resources beyond the neighborhood.
2	    As the number of contacts of a node increases, the network view (reachability) of the node increases.
1	    Paths to contacts are validated periodically to adapt to mobility.
2	    We present mechanisms for contact selection and maintenance that attempt to increase reachability while minimizing overhead.
2	    Our simulation results show a clear trade-off between increase in reachability on one hand, and contact selection and maintenance overhead on the other.
2	    Our results suggest that CARD can be configured to provide a desirable reachability distribution for different network sizes.
2	    Comparisons with other schemes for resource discovery, such as flooding and bordercasting, show our architecture to be much more efficient and scalable.


# 7
### http://arxiv.org/abs/cs/0208025v1
## Efficient Micro-Mobility using Intra-domain Multicast-based Mechanisms (M&M)


0	    One of the most important metrics in the design of IP mobility protocols is the handover performance.
0	    The current Mobile IP (MIP) standard has been shown to exhibit poor handover performance.
0	    Most other work attempts to modify MIP to slightly improve its efficiency, while others propose complex techniques to replace MIP.
1	    Rather than taking these approaches, we instead propose a new architecture for providing efficient and smooth handover, while being able to co-exist and inter-operate with other technologies.
1	    Specifically, we propose an intra-domain multicast-based mobility architecture, where a visiting mobile is assigned a multicast address to use while moving within a domain.
1	    Efficient handover is achieved using standard multicast join/prune mechanisms.
0	    Two approaches are proposed and contrasted.
1	    The first introduces the concept proxy-based mobility, while the other uses algorithmic mapping to obtain the multicast address of visiting mobiles.
2	    We show that the algorithmic mapping approach has several advantages over the proxy approach, and provide mechanisms to support it.
1	    Network simulation (using NS-2) is used to evaluate our scheme and compare it to other routing-based micro-mobility schemes - CIP and HAWAII.
2	    The proactive handover results show that both M&M and CIP shows low handoff delay and packet reordering depth as compared to HAWAII.
2	    The reason for M&M's comparable performance with CIP is that both use bi-cast in proactive handover.
0	    The M&M, however, handles multiple border routers in a domain, where CIP fails.
1	    We also provide a handover algorithm leveraging the proactive path setup capability of M&M, which is expected to outperform CIP in case of reactive handover.


# 8
### http://arxiv.org/abs/cs/0411013v1
## Efficient Algorithms for Large-Scale Topology Discovery


0	    There is a growing interest in discovery of internet topology at the interface level.
0	    A new generation of highly distributed measurement systems is currently being deployed.
0	    Unfortunately, the research community has not examined the problem of how to perform such measurements efficiently and in a network-friendly manner.
1	    In this paper we make two contributions toward that end.
1	    First, we show that standard topology discovery methods (e.g., skitter) are quite inefficient, repeatedly probing the same interfaces.
0	    This is a concern, because when scaled up, such methods will generate so much traffic that they will begin to resemble DDoS attacks.
1	    We measure two kinds of redundancy in probing (intra- and inter-monitor) and show that both kinds are important.
2	    We show that straightforward approaches to addressing these two kinds of redundancy must take opposite tacks, and are thus fundamentally in conflict.
1	    Our second contribution is to propose and evaluate Doubletree, an algorithm that reduces both types of redundancy simultaneously on routers and end systems.
1	    The key ideas are to exploit the tree-like structure of routes to and from a single point in order to guide when to stop probing, and to probe each path by starting near its midpoint.
2	    Our results show that Doubletree can reduce both types of measurement load on the network dramatically, while permitting discovery of nearly the same set of nodes and links.
1	    We then show how to enable efficient communication between monitors through the use of Bloom filters.


# 9
### http://arxiv.org/abs/cs/0411054v1
## J2EE Deployment: The JOnAS Case Study


1	    La specification J2EE (Java 2 platform Enterprise Edition) definit une architecture de serveur d'application Java.
1	    Jusqu'a J2EE 1.3, seuls les aspects de deploiement concernant le developpeur d'applications etaient adresses.
1	    Avec J2EE 1.4, les interfaces et les etapes de deploiement ont ete plus precisement specifiees dans la specification "J2EE Deployment".
1	    JOnAS (Java Open Application Server) est une plate-forme J2EE developpee au sein du consortium ObjectWeb.
1	    Les aspects deploiement sont en cours de developpement.
1	    Cet article decrit les concepts lies au deploiement dans J2EE, ainsi que les problematiques levees lors de leur mise en oeuvre pour JOnAS.
1	    Il n'a pas pour but de presenter un travail abouti, mais illustre le deploiement par un cas concret et ebauche une liste de besoins non encore satisfaits dans le domaine.
1	    -----   The J2EE (Java 2 platform Enterprise Edition) specification defines an architecture for Java Application Servers.
1	    Until J2EE 1.3, the deployment aspect was addressed from the developer point of view only.
0	    Since J2EE 1.4, deployment APIs and steps have been more precisely specified within the "J2EE Deployment Specification".
1	    JOnAS (Java Open Application Server) is a J2EE platform implementation by ObjectWeb.
0	    The deployment aspects are under development.
1	    This article describes the J2EE Deployment concepts, and the issues raised when implementing deployment features within JOnAS.
0	    It does not provide a complete solution, but illustrates deployment through a concrete example and initiates a list of non fulfilled requirements.


# 10
### http://arxiv.org/abs/cs/0411058v1
## Deployment in dynamic environments


0	    Information and communication technologies are moving towards a new stage where applications will be dynamically deployed, uninstalled, updated and (re)configured.
0	    Several approaches have been followed with the goal of creating a fully automated and context-aware deployment system.
2	    Ideally, this system should be capable of handling the dynamics of this new situation, without losing sight of other factors, such as performance, security, availability or scalability.
1	    We will take some of the technologies that follow the principles of Service Oriented Architectures, SOA, as a paradigm of dynamic environments.
1	    SOA promote the breaking down of applications into sets of loosely coupled elements, called services.
1	    Services can be dynamically bound, deployed, reconfigured, uninstalled and updated.
2	    First of all, we will try to offer a broad view on the specific deployment issues that arise in these environments.
2	    Later on, we will present our approach to the problem.
1	    One of the essential points that has to be tackled to develop an automated deployment engine will be to have enough information to carry out tasks without human intervention.
1	    In the article we will focus on the format and contents of deployment descriptors.
1	    Additionally, we will go into the details of the deployment framework for OSGi enabled gateways that has been developed by our research group.
2	    Finally we will give some concluding remarks and some ideas for future work


# 11
### http://arxiv.org/abs/cs/0411070v1
## Data Path Processing in Fast Programmable Routers


0	    Internet is growing at a fast pace.
0	    The link speeds are surging toward 40 Gbps with the emergence of faster link technologies.
0	    New applications are coming up which require intelligent processing at the intermediate routers.
0	    Switches and routers are becoming the bottlenecks in fast communication.
1	    On one hand faster links deliver more packets every second and on the other hand intelligent processing consumes more CPU cycles at the router.
0	    The conflicting goals of providing faster but computationally expensive processing call for new approaches in designing routers.
1	    This survey takes a look at the core functionalities, like packet classification, buffer memory management, switch scheduling and output link scheduling performed by a router in its data path processing and discusses the algorithms that aim to reduce the performance bound for these operations.
0	    An important requirement for the routers is to provide Quality of Service guarantees.
1	    We propose an algorithm to guarantee QoS in Input Queued Routers.
1	    The hardware solution to speed up router operation was Application Specific Integrated Circuits (ASICs).
2	    But the inherent inflexibility of the method is a demerit as network standards and application requirements are constantly evolving, which seek a faster turnaround time to keep up with the changes.
1	    The promise of Network Processors (NP) is the flexibility of general-purpose processors together with the speed of ASICs.
1	    We will study the architectural choices for the design of Network Processors and focus on some of the commercially available NPs.
0	    There is a plethora of NP vendors in the market.
1	    The discussion on the NP benchmarks sets the normalizing platform to evaluate these NPs.


# 12
### http://arxiv.org/abs/cs/0504002v1
## On the Effect of Fading on Ad hoc Networking


0	    Most MANET (Mobile Ad hoc NETwork) research assumes idealized propagation models.
0	    Experimental results have shown significant divergence from simulation results due to the effect of signal fading in realistic wireless communication channels.
0	    In this paper, we characterize the impact of fading on protocol performance.
1	    We first study the effect of fading on MAC performance and show that its effect can be dominating.
2	    One of our important conclusions is that eliminating RTS/CTS packets results in more effective operation under fading.
2	    We also identify an unfairness problem that arises due to backoffs in the presence of fading.
0	    Moreover, fading results in several subtle interactions between the MAC and routing layers.
1	    We identify several of these problems and make observations about effective approaches for addressing them.
0	    For example, the criteria for determining the best path should not only consider the link status but also the link order.
0	    In addition, because routing protocols rely on MAC level transmission failure (when the retry limit is exceeded), route failure errors are often generated unnecessarily.
0	    Finally, because MAC level broadcasts are unreliable, they are especially vulnerable to fading.
1	    We analyze these effects and outline preliminary solutions to them.


# 13
### http://arxiv.org/abs/cs/0504073v1
## Rendezvous Regions: A Scalable Architecture for Resource Discovery and Service Location in Large-Scale Mobile Networks


0	    In large-scale wireless networks such as mobile ad hoc and sensor networks, efficient and robust service discovery and data-access mechanisms are both essential and challenging.
0	    Rendezvous-based mechanisms provide a valuable solution for provisioning a wide range of services.
1	    In this paper, we describe Rendezvous Regions (RRs) - a novel scalable rendezvous-based architecture for wireless networks.
0	    RR is a general architecture proposed for service location and bootstrapping in ad hoc networks, in addition to data-centric storage, configuration, and task assignment in sensor networks.
0	    In RR the network topology is divided into geographical regions, where each region is responsible for a set of keys representing the services or data of interest.
1	    Each key is mapped to a region based on a hash-table-like mapping scheme.
0	    A few elected nodes inside each region are responsible for maintaining the mapped information.
0	    The service or data provider stores the information in the corresponding region and the seekers retrieve it from there.
1	    We run extensive detailed simulations, and high-level simulations and analysis, to investigate the design space, and study the architecture in various environments including node mobility and failures.
1	    We evaluate it against other approaches to identify its merits and limitations.
2	    The results show high success rate and low overhead even with dynamics.
2	    RR scales to large number of nodes and is highly robust and efficient to node failures.
2	    It is also robust to node mobility and location inaccuracy with a significant advantage over point-based rendezvous mechanisms.


# 14
### http://arxiv.org/abs/cs/0609026v1
## Rarest First and Choke Algorithms Are Enough


0	    The performance of peer-to-peer file replication comes from its piece and peer selection strategies.
0	    Two such strategies have been introduced by the BitTorrent protocol: the rarest first and choke algorithms.
0	    Whereas it is commonly admitted that BitTorrent performs well, recent studies have proposed the replacement of the rarest first and choke algorithms in order to improve efficiency and fairness.
1	    In this paper, we use results from real experiments to advocate that the replacement of the rarest first and choke algorithms cannot be justified in the context of peer-to-peer file replication in the Internet.
1	    We instrumented a BitTorrent client and ran experiments on real torrents with different characteristics.
0	    Our experimental evaluation is peer oriented, instead of tracker oriented, which allows us to get detailed information on all exchanged messages and protocol events.
1	    We go beyond the mere observation of the good efficiency of both algorithms.
1	    We show that the rarest first algorithm guarantees close to ideal diversity of the pieces among peers.
2	    In particular, on our experiments, replacing the rarest first algorithm with source or network coding solutions cannot be justified.
2	    We also show that the choke algorithm in its latest version fosters reciprocation and is robust to free riders.
2	    In particular, the choke algorithm is fair and its replacement with a bit level tit-for-tat solution is not appropriate.
1	    Finally, we identify new areas of improvements for efficient peer-to-peer file replication protocols.


# 15
### http://arxiv.org/abs/0807.1153v1
## CSI: A Paradigm for Behavior-oriented Delivery Services in Mobile Human Networks


0	    We propose behavior-oriented services as a new paradigm of communication in mobile human networks.
0	    Our study is motivated by the tight user-network coupling in future mobile societies.
0	    In such a paradigm, messages are sent to inferred behavioral profiles, instead of explicit IDs.
0	    Our paper provides a systematic framework in providing such services.
1	    First, user behavioral profiles are constructed based on traces collected from two large wireless networks, and their spatio-temporal stability is analyzed.
0	    The implicit relationship discovered between mobile users could be utilized to provide a service for message delivery and discovery in various network environments.
1	    As an example application, we provide a detailed design of such a service in challenged opportunistic network architecture, named CSI.
1	    We provide a fully distributed solution using behavioral profile space gradients and small world structures.
2	    Our analysis shows that user behavioral profiles are surprisingly stable, i.e., the similarity of the behavioral profile of a user to its future behavioral profile is above 0.8 for two days and 0.75 for one week, and remains above 0.6 for five weeks.
2	    The correlation coefficient of the similarity metrics between a user pair at different time instants is above 0.7 for four days, 0.62 for a week, and remains above 0.5 for two weeks.
2	    Leveraging such a stability in user behaviors, the CSI service achieves delivery rate very close to the delay-optimal strategy (above 94%), with minimal overhead (less than 84% of the optimal).
2	    We believe that this new paradigm will act as an enabler of multiple new services in mobile societies, and is potentially applicable in server-based, heterogeneous or infrastructure-less wireless environments.


# 166
### http://arxiv.org/abs/1802.02828v2
## PTP: Path-specified Transport Protocol for Concurrent Multipath Transmission in Named Data Networks


0	    Named Data Networking (NDN) is a promising Future Internet architecture to support content distribution.
2	    Its inherent addressless routing paradigm brings valuable characteristics to improve the transmission robustness and efficiency, e.g. users are enabled to download content from multiple providers concurrently.
0	    However, multipath transmission NDN is different from that in Multipath TCP, i.e. the "paths" in NDN are transparent to and uncontrollable by users.
1	    To this end, the user controls the traffic on all transmission paths as an entirety, which leads to a noticeable problem of low bandwidth utilization.
0	    In particular, the congestion of a certain path will trigger the traffic reduction on the other transmission paths that are underutilized.
0	    Some solutions have been proposed by letting routers balance the loads of different paths to avoid congesting a certain path prematurely.
0	    However, the complexity of obtaining an optimal load balancing solution (of solving a Multi-Commodity Flow problem) becomes higher with the increasing network size, which limits the universal NDN deployments.
0	    This paper introduces a compromising solution - Path-specified Transport Protocol (PTP).
1	    PTP supports both the label switching and the addressless routing schemes.
2	    Specifically, the label switching scheme facilitates users to precisely control the traffic on each transmission path, and the addressless routing scheme maintains the valuable feature of retrieving content from any provider to guarantee robustness.
2	    As the traffic on a transmission path can be explicitly controlled by consumers, load balancing is no longer needed in routers, which reduce the computational burden of routers and consequently increase the system scalability.
2	    The experimental results show that PTP significantly increases the users' downloading rates and improved the network throughput.


# 167
### http://arxiv.org/abs/1802.08818v1
## Optimal QoS Constraint Service Composition in Mobile Ad Hoc Networks


0	    In recent year's computational capability of the mobile nodes have been greatly improved.
0	    The mobile nodes have the capability of running different applications.
0	    Implementation of services in Mobile Ad Hoc Networks (MANETs) increases the flexibility of using mobile devices for running a wide variety of applications.
2	    Single service cannot satisfy the user needs.
2	    The complex needs of the users can be satisfied by the service composition.
1	    Service composition means, combining the atomic services into a complex service.
1	    In this paper we propose QoS constraint service composition in MANETs.
1	    We considered both service QoS parameters as well node parameters.
1	    Response time and throughput as parameters for services and energy and hop count as node parameters.
1	    These four QoS parameters are optimized using a mathematical model Hammerstein model to generate a single output.
1	    Based on generated output, max valued (optimal) services are considered in service composition path.
2	    The simulation results shown that, our proposed method outperforms than the traditional AODV method of service composition.


# 168
### http://arxiv.org/abs/1803.03780v1
## Energy and Delay Optimization for Cache-Enabled Dense Small Cell Networks


0	    Caching popular files in small base stations (SBSs) has been proved to be an effective way to reduce bandwidth pressure on the backhaul links of dense small cell networks (DSCNs).
0	    Many existing studies on cache-enabled DSCNs attempt to improve user experience by optimizing end-to-end file delivery delay.
0	    However, under practical scenarios where files (e.g., video files) have diverse quality of service requirements, energy consumption at SBSs should also be concerned from the network perspective.
1	    In this paper,we attempt to optimize these two critical metrics in cache-enabled DSCNs.
1	    Firstly, we formulate the energy-delay optimization problem as a Mixed Integer Programming (MIP) problem, where file placement, user association and power control are jointly considered.
1	    To model the tradeoff relationship between energy consumption and end-to-end file delivery delay, a utility function linearly combining these two metrics is used as an objective function of the optimization problem.
1	    Then, we solve the problem in two stages, i.e. caching stage and delivery stage, based on the observation that caching is performed during off-peak time.
1	    At the caching stage, a local popular file placement policy is proposed by estimating user preference at each SBS.
1	    At the delivery stage, with given caching status at SBSs, the MIP problem is further decomposed by Benders' decomposition method.
1	    An efficient algorithm is proposed to approach the optimal association and power solution by iteratively shrinking the gap of the upper and lower bounds.
1	    Finally, extension simulations are performed to validate our analytical and algorithmic work.
2	    The results demonstrate that the proposed algorithms can achieve the optimal tradeoff between energy consumption and end-to-end file delivery delay.


# 169
### http://arxiv.org/abs/1803.08634v2
## Joint Head Selection and Airtime Allocation for Data Dissemination in Mobile Social Networks


0	    Mobile social networks (MSNs) enable people with similar interests to interact without Internet access.
0	    By forming a temporary group, users can disseminate their data to other interested users in proximity with short-range communication technologies.
0	    However, due to user mobility, airtime available for users in the same group to disseminate data is limited.
1	    In addition, for practical consideration, a star network topology among users in the group is expected.
1	    For the former, unfair airtime allocation among the users will undermine their willingness to participate in MSNs.
2	    For the latter, a group head is required to connect other users.
2	    These two problems have to be properly addressed to enable real implementation and adoption of MSNs.
1	    To this aim, we propose a Nash bargaining-based joint head selection and airtime allocation scheme for data dissemination within the group.
1	    Specifically, the bargaining game of joint head selection and airtime allocation is first formulated.
1	    Then, Nash bargaining solution (NBS) based optimization problems are proposed for a homogeneous case and a more general heterogeneous case.
1	    For both cases, the existence of solution to the optimization problem is proved, which guarantees Pareto optimality and proportional fairness.
1	    Next, an algorithm, allowing distributed implementation, for join head selection and airtime allocation is introduced.
2	    Finally, numerical results are presented to evaluate the performance, validate intuitions and derive insights of the proposed scheme.


# 170
### http://arxiv.org/abs/1803.10369v2
## SRLA: A real time sliding time window super point cardinality estimation algorithm for high speed network based on GPU


0	    Super point is a special host in network which communicates with lots of other hosts in a certain time period.
1	    The number of hosts contacting with a super point is called as its cardinality.
0	    Cardinality estimating plays important roles in network management and security.
1	    All of existing works focus on how to estimate super point's cardinality under discrete time window.
1	    But discrete time window causes great delay and the accuracy of estimating result is subject to the starting of the window.
2	    sliding time window, moving forwarding a small slice every time, offers a more accuracy and timely scale to monitor super point's cardinality.
2	    On the other hand, super point's cardinality estimating under sliding time window is more difficult because it requires an algorithm to record the cardinality incrementally and report them immediately at the end of the sliding duration.
1	    This paper firstly solves this problem by devising a sliding time window available algorithm SRLA.
1	    SRLA records hosts cardinality by a novel structure which could be updated incrementally.
1	    In order to reduce the cardinality estimating time at the end of every sliding time window, SRLA generates a super point candidate list while scanning packets and calculates the cardinality of hosts in the candidate list only.
2	    It also has the ability to run parallel to deal with high speed network in line speed.
1	    This paper gives the way to deploy SRLA on a common GPU.
2	    Experiments on real world traffics which have 40 GB/s bandwidth show that SRLA successfully estimates super point's cardinality within 100 milliseconds under sliding time window when running on a low cost Nvidia GPU, GTX650 with 1 GB memory.
2	    The estimating time of SRLA is much smaller than that of other algorithms which consumes more than 2000 milliseconds under discrete time window.


# 171
### http://arxiv.org/abs/1804.02723v1
## TCP Decoupling for Next Generation Communication System


0	    In traditional networks, interfaces of network nodes are duplex.
0	    But, emerging communication technologies such as visible light communication, millimeter-wave communications, can only provide a unidirectional interface when cost is limited.
0	    It's urgent to find effective solutions to utilize such new unidirectional communication skills.
1	    Decoupling implies separating one single resource to two independent resources.
2	    This idea can be applied at physical layer, link layer, network layer, even transport layer.
2	    TCP decoupling is an end to end solution provided at transport layer.
0	    With decoupled TCP, two distinct unidirectional path can be created to meet the requirements of reliable information transfer.
0	    However, it is not an easy task to decouple a bidirectional logical path at transport layer.
1	    In this paper, we dwell on the idea of TCP decoupling.
1	    Advantages of decoupling at transport layer are analyzed also.
1	    In addition, an experiment is carried out to figure out how to implement a decouple TCP.
2	    Our results show decoupling at transport layer is possible and the modified protocol is available.


# 172
### http://arxiv.org/abs/1804.09089v2
## Automated Network Service Scaling in NFV: Concepts, Mechanisms and Scaling Workflow


0	    Next-generation systems are anticipated to be digital platforms supporting innovative services with rapidly changing traffic patterns.
1	    To cope with this dynamicity in a cost-efficient manner, operators need advanced service management capabilities such as those provided by NFV.
2	    NFV enables operators to scale network services with higher granularity and agility than today.
1	    For this end, automation is key.
1	    In search of this automation, the European Telecommunications Standards Institute (ETSI) has defined a reference NFV framework that make use of model-driven templates called Network Service Descriptors (NSDs) to operate network services through their lifecycle.
1	    For the scaling operation, an NSD defines a discrete set of instantiation levels among which a network service instance can be resized throughout its lifecycle.
1	    Thus, the design of these levels is key for ensuring an effective scaling.
1	    In this article, we provide an overview of the automation of the network service scaling operation in NFV, addressing the options and boundaries introduced by ETSI normative specifications.
1	    We start by providing a description of the NSD structure, focusing on how instantiation levels are constructed.
1	    For illustrative purposes, we propose an NSD for a representative NS.
1	    This NSD includes different instantiation levels that enable different ways to automatically scale this NS.
1	    Then, we show the different scaling procedures the NFV framework has available, and how it may automate their triggering.
1	    Finally, we propose an ETSI-compliant workflow to describe in detail a representative scaling procedure.
2	    This workflow clarifies the interactions and information exchanges between the functional blocks in the NFV framework when performing the scaling operation.


# 173
### http://arxiv.org/abs/1805.00004v1
## Maximum Likelihood Coordinate Systems for Wireless Sensor Networks: from physical coordinates to topology coordinates


0	    Many WSN protocols require the location coordinates of the sensor nodes, as it is useful to consider the data collected by the sensors in the context of the location from which they were collected.
0	    Thus, one of the major challenges in WSNs is to determine the coordinates of sensors while minimizing the hardware cost.
1	    To address this, numerous localization algorithms have been proposed in the literature.
0	    However, outcomes of these algorithms are affected by noise, fading, and interference.
0	    As a result, their levels of accuracy may become unacceptable in complex environments that contain obstacles and reflecting surfaces.
0	    The alternative is to use topological maps based only on connectivity information.
0	    Since they do not contain information about physical distances, however, they are not faithful representatives of the physical layout.
0	    Thus, the primary goal of this research is to discover a topology map that provides more accurate information about physical layouts.
2	    In doing so, this research has resulted in four main contributions.
1	    First, a novel concept Maximum-Likelihood Topology Map for RF WSNs is presented.
1	    This topology map provides a more accurate physical representation, by using the probability of packet reception.
1	    The second contribution is Millimetre wave Topology Map calculation, which is a novel topology mapping algorithm based on maximum likelihood estimation for millimetre wave WSNs.
1	    The third contribution is a distributed algorithm being proposed to calculate the topology coordinates of sensors by themselves as two algorithms above calculate centrally, which requires time.
1	    Since a topology map contains significant non-linear distortions, two WSN applications i.e. target searching and extremum seeking, which use a proposed topology map to localize the sensors and perform its specified task are presented as the final contribution of this dissertation.


# 174
### http://arxiv.org/abs/1805.02719v1
## Mobility-Aware Analysis of 5G and B5G Cellular Networks: A Tutorial


0	    Providing network connectivity to mobile users is a key requirement for cellular wireless networks.
1	    User mobility impacts network performance as well as user perceived service quality.
0	    For efficient network dimensioning and optimization, it is therefore required to characterize the mobility-aware network performance metrics such as the handoff rate, handoff probability, sojourn time, direction switch rate, and users' throughput or coverage.
0	    This characterization is particularly challenging for heterogeneous, dense/ultra-dense, and random cellular networks such as the emerging 5G and beyond 5G (B5G) networks.
1	    In this article, we provide a tutorial on mobility-aware performance analysis of both the spatially random and non-random, single-tier and multi-tier cellular networks.
1	    We first provide a summary of the different mobility models which include purely random models, spatially correlated, and temporally correlated models.
1	    The differences among various mobility models, their statistical properties, and their pros and cons are presented.
1	    We then describe two main analytical approaches for mobility-aware performance analysis of both random and non-random cellular networks.
1	    For the first approach, we describe a general methodology and present several case studies for different cellular network tessellations such as square lattice, hexagon lattice, single-tier and multi-tier models in which base-stations (BSs) follow a homogeneous Poisson Point Process (PPP).
1	    For the second approach, we also outline the general methodology.
1	    In addition, we discuss some limitations/imperfections of the existing techniques and provide corrections to these imperfections.
2	    Finally, we point out specific 5G application scenarios where the impact of mobility would be significant and outline the challenges associated with mobility-aware analysis of those scenarios.


# 175
### http://arxiv.org/abs/1805.06053v2
## SAS-Assisted Coexistence-Aware Dynamic Channel Assignment in CBRS Band


0	    The paradigm of shared spectrum allows secondary devices to opportunistically access spectrum bands underutilized by primary owners.
0	    Recently, the FCC has targeted the sharing of the 3.5 GHz (3550-3700 MHz) federal spectrum with commercial systems such as small cells.
1	    The rules require a Spectrum Access System (SAS) to accommodate three service tiers: 1) Incumbent Access, 2) Priority Access (PA), and 3) Generalized Authorized Access (GAA).
1	    In this work, we study the SAS-assisted dynamic channel assignment (CA) for PA and GAA tiers.
1	    We introduce the node-channel-pair conflict graph to capture pairwise interference, channel and geographic contiguity constraints, spatially varying channel availability, and coexistence awareness.
2	    The proposed conflict graph allows us to formulate PA CA and GAA CA with binary conflicts as max-cardinality and max-reward CA, respectively.
1	    Approximate solutions can be found by a heuristic-based algorithm that search for the maximum weighted independent set.
1	    We further formulate GAA CA with non-binary conflicts as max-utility CA.
2	    We show that the utility function is submodular, and the problem is an instance of matroid-constrained submodular maximization.
1	    A polynomial-time algorithm based on local search is proposed that provides a provable performance guarantee.
1	    Extensive simulations using a real-world Wi-Fi hotspot location dataset are conducted to evaluate the proposed algorithms.
2	    Our results have demonstrated the advantages of the proposed graph representation and improved performance of the proposed algorithms over the baseline algorithms.


# 176
### http://arxiv.org/abs/1807.02205v1
## OSDF: An Intent-based Software Defined Network Programming Framework


0	    Software Defined Networking (SDN) offers flexibility to program a network based on a set of network requirements.
0	    Programming the networks using SDN is not completely straightforward because a programmer must deal with low level details.
0	    To solve the problem, researchers proposed a set of network programming languages that provide a set of high level abstractions to hide low level hardware details.
0	    Most of the proposed languages provide abstractions related to packet processing and flows, and still require a programmer to specify low-level match-action fields to configure and monitor a network.
0	    Recently, in an attempt to raise the level at which programmers work, researchers have begun to investigate Intent-based, descriptive northbound interfaces.
0	    The work is still in early stages, and further investigation is required before intent-based systems will be adopted by enterprise networks.
1	    To help achieve the goal of moving to an intent-based design, we propose an SDN-based network programming framework, the Open Software Defined Framework (OSDF).
1	    OSDF provides a high level Application Programming Interface (API) that can be used by managers and network administrators to express network requirements for applications and policies for multiple domains.
1	    OSDF also provides a set of high level network operation services that handle common network configuration, monitoring, and Quality of Service (QoS) provisioning.
1	    OSDF is equipped with a policy conflict management module to help a network administrator detect and resolve policy conflicts.
1	    The paper shows how OSDF can be used and explains application-based policies.
2	    Finally, the paper reports the results of both testbed measurements and simulations that are used to evaluate the framework from multiple perspectives, including functionality and performance.


# 177
### http://arxiv.org/abs/1808.02975v2
## Auto-Scaling Network Resources using Machine Learning to Improve QoS and Reduce Cost


0	    Virtualization of network functions (as virtual routers, virtual firewalls, etc.)
1	    enables network owners to efficiently respond to the increasing dynamicity of network services.
0	    Virtual Network Functions (VNFs) are easy to deploy, update, monitor, and manage.
0	    The number of VNF instances, similar to generic computing resources in cloud, can be easily scaled based on load.
0	    Hence, auto-scaling (of resources without human intervention) has been receiving attention.
0	    Prior studies on auto-scaling use measured network traffic load to dynamically react to traffic changes.
1	    In this study, we propose a proactive Machine Learning (ML) based approach to perform auto-scaling of VNFs in response to dynamic traffic changes.
1	    Our proposed ML classifier learns from past VNF scaling decisions and seasonal/spatial behavior of network traffic load to generate scaling decisions ahead of time.
1	    Compared to existing approaches for ML-based auto-scaling, our study explores how the properties (e.g., start-up time) of underlying virtualization technology impacts Quality of Service (QoS) and cost savings.
1	    We consider four different virtualization technologies: Xen and KVM, based on hypervisor virtualization, and Docker and LXC, based on container virtualization.
2	    Our results show promising accuracy of the ML classifier using real data collected from a private ISP.
1	    We report in-depth analysis of the learning process (learning-curve analysis), feature ranking (feature selection, Principal Component Analysis (PCA), etc.),
1	    impact of different sets of features, training time, and testing time.
2	    Our results show how the proposed methods improve QoS and reduce operational cost for network owners.
2	    We also demonstrate a practical use-case example (Software-Defined Wide Area Network (SD-WAN) with VNFs and backbone network) to show that our ML methods save significant cost for network service leasers.


# 178
### http://arxiv.org/abs/1808.06722v1
## Mechanisms for Resilient Video Transmission


0	    Wireless networks are envisaged to be one of the most important technologies to provide cost-efficient content delivery, including for video applications.
0	    They will allow thousands of thousands of fixed and mobile users to access, produce, share, and consume video content in a ubiquitous way.
0	    Real-time video services over these networks are becoming a part of everyday life and have been used to spread information ranging from education to entertainment content.
0	    However, the challenge of dealing with the fluctuating bandwidth, scarce resources, and time-varying error rate of these networks, highlights the need for error-resilient video transmission.
1	    In this context, the combination of Forward Error Correction (FEC) and Unequal Error Protection (UEP) approaches is known to provide the distribution of video applications for wireless users with Quality of Experience (QoE) assurance.
1	    This thesis proposed a procedure to assess the video characteristics and their related impact on the perceived quality to end-users.
0	    This thesis proposes a series of cross-layer video-aware and FEC-based mechanisms with UEP to enhance video transmission in several types of wireless networks.
1	    A number of methods to set an adaptive amount of redundancy were used in these mechanisms, such as heuristic techniques, random neural networks, ant colony optimisation, and fuzzy logic.
0	    In the first one, heuristic techniques, the mechanisms rely on human experience to define the best strategy.
2	    The advantages and drawbacks of the proposed mechanisms were demonstrated in realistic simulations using real video sequences and actual network traces.
1	    The assessments were conducted with well-known QoE metrics.
2	    The results show that all the proposed mechanisms were able to outperform the competitors on both perceived video quality and network footprint.


# 179
### http://arxiv.org/abs/1808.09242v1
## Introducing Development Features for Virtualized Network Services


0	    Network virtualization and softwarizing network functions are trends aiming at higher network efficiency, cost reduction and agility.
1	    They are driven by the evolution in Software Defined Networking (SDN) and Network Function Virtualization (NFV).
2	    This shows that software will play an increasingly important role within telecommunication services, which were previously dominated by hardware appliances.
2	    Service providers can benefit from this, as it enables faster introduction of new telecom services, combined with an agile set of possibilities to optimize and fine-tune their operations.
0	    However, the provided telecom services can only evolve if the adequate software tools are available.
1	    In this article, we explain how the development, deployment and maintenance of such an SDN/NFV-based telecom service puts specific requirements on the platform providing it.
1	    A Software Development Kit (SDK) is introduced, allowing service providers to adequately design, test and evaluate services before they are deployed in production and also update them during their lifetime.
1	    This continuous cycle between development and operations, a concept known as DevOps, is a well known strategy in software development.
0	    To extend its context further to SDN/NFV-based services, the functionalities provided by traditional cloud platforms are not yet sufficient.
2	    By giving an overview of the currently available tools and their limitations, the gaps in DevOps for SDN/NFV services are highlighted.
2	    The benefit of such an SDK is illustrated by a secure content delivery network service (enhanced with deep packet inspection and elastic routing capabilities).
2	    With this use-case, the dynamics between developing and deploying a service are further illustrated.


# 180
### http://arxiv.org/abs/1809.02826v3
## Delay-Constrained Input-Queued Switch


0	    In this paper, we study the delay-constrained input-queued switch where each packet has a deadline and it will expire if it is not delivered before its deadline.
0	    Such new scenario is motivated by the proliferation of real-time applications in multimedia communication systems, tactile Internet, networked controlled systems, and cyber-physical systems.
2	    The delay-constrained input-queued switch is completely different from the well-understood delay-unconstrained one and thus poses new challenges.
2	    We focus on three fundamental problems centering around the performance metric of timely throughput: (i) how to characterize the capacity region? (
0	    ii) how to design a feasibility/throughput-optimal scheduling policy?
0	    and (iii) how to design a network-utility-maximization scheduling policy?
1	    We use three different approaches to solve these three fundamental problems.
1	    The first approach is based on Markov Decision Process (MDP) theory, which can solve all three problems.
0	    However, it suffers from the curse of dimensionality.
1	    The second approach breaks the curse of dimensionality by exploiting the combinatorial features of the problem.
1	    It gives a new capacity region characterization with only a polynomial number of linear constraints.
1	    The third approach is based on the framework of Lyapunov optimization, where we design a polynomial-time maximum-weight T-disjoint-matching scheduling policy which is proved to be feasibility/throughput-optimal.
2	    Our three approaches apply to the frame-synchronized traffic pattern but our MDP-based approach can be extended to more general traffic patterns.


# 181
### http://arxiv.org/abs/1809.03412v1
## S2VC: An SDN-based Framework for Maximizing QoE in SVC-Based HTTP Adaptive Streaming


0	    HTTP adaptive streaming (HAS) is quickly becoming the dominant video delivery technique for adaptive streaming over the Internet.
0	    Still considered as its primary challenges are determining the optimal rate adaptation and improving both the quality of experience (QoE) and QoE-fairness.
0	    Most of the proposed approaches have relied on local information to find a result.
0	    However, employing techniques that provide a comprehensive and central view of the network resources can lead to more gains in performance.
1	    By leveraging software defined networking (SDN), this paper proposes an SDN-based framework, named S2VC, to maximize QoE metrics and QoE-fairness in SVC-based HTTP adaptive streaming.
1	    The proposed framework determines both the optimal adaptation and data paths for delivering the requested video files from HTTP-media servers to DASH clients.
1	    In fact, by utilizing an SDN controller and its complete view of the network, we introduce an SVC flow optimizer (SFO) application module to determine the optimal solution in a centralized and time slot fashion.
1	    In the current approach, we first formulate the problem as a mixed integer linear programming (MILP) optimization model.
1	    The MILP is designed in such a way that it applies defined policies, e.g. setting priorities for clients in obtaining video quality.
1	    Secondly, we show that this problem is NP-complete and propose an LP-relaxation model to enable S2VC framework for performing rate adaptation on a large-scale network.
1	    Finally, we conduct experiments by emulating the proposed framework in Mininet, with the usage of Floodlight as the SDN controller.
2	    In terms of improving QoE-fairness and QoE metrics, the effectiveness of the proposed framework is validated by a comparison with different approaches.


# 182
### http://arxiv.org/abs/1810.02596v1
## Interference Management Based on RT/nRT Traffic Classification for FFR-Aided Small Cell/Macrocell Heterogeneous Networks


0	    Cellular networks are constantly lagging in terms of the bandwidth needed to support the growing high data rate demands.
0	    The system needs to efficiently allocate its frequency spectrum such that the spectrum utilization can be maximized while ensuring the quality of service (QoS) level.
0	    Owing to the coexistence of different types of traffic (e.g., real-time (RT) and non-real-time (nRT)) and different types of networks (e.g., small cell and macrocell), ensuring the QoS level for different types of users becomes a challenging issue in wireless networks.
0	    Fractional frequency reuse (FFR) is an effective approach for increasing spectrum utilization and reducing interference effects in orthogonal frequency division multiple access networks.
1	    In this paper, we propose a new FFR scheme in which bandwidth allocation is based on RT/nRT traffic classification.
1	    We consider the coexistence of small cells and macrocells.
2	    After applying FFR technique in macrocells, the remaining frequency bands are efficiently allocated among the small cells overlaid by a macrocell.
1	    In our proposed scheme, total frequency-band allocations for different macrocells are decided on the basis of the traffic intensity.
1	    The transmitted power levels for different frequency bands are controlled based on the level of interference from a nearby frequency band.
0	    Frequency bands with a lower level of interference are assigned to the RT traffic to ensure a higher QoS level for the RT traffic.
0	    RT traffic calls in macrocell networks are also given a higher priority compared with nRT traffic calls to ensure the low call-blocking rate.
2	    Performance analyses show significant improvement under the proposed scheme compared with conventional FFR schemes.


# 183
### http://arxiv.org/abs/1810.05090v1
## A cognitive radio ad hoc networks based disaster management scheme with efficient spectrum management, collaboration and interoperability


0	    In this work, a disaster management scheme based on cognitive radio ad hoc network (CRAHN) has been presented.
0	    Disaster management has been a big problem for mankind for years.
0	    However, still not much research work has been presented on this problem.
0	    Technology has been employed in past few years to address this problem.
1	    Cognitive radio ad hoc network presents a viable solution for disaster management.
2	    It can be deployed rapidly without infrastructure and it solves the spectrum scarcity and congestion issues that arise during disaster.
1	    This paper presents a novel solution for disaster management.
1	    It provides a multi-layer perceptron (MLP) based disaster detection scheme based on WSN.
0	    To solve the spectrum scarcity problem, a MLP based spectrum management scheme has been proposed.
1	    In order to ensure collaboration among rescue workers during disaster, a novel service discovery scheme has been proposed.
1	    To ensure interoperability during communication, XML format has been recommended.
1	    A real-time GUI has been proposed to provide shared situation awareness to rescue workers and enabling better decision making.
1	    The proposed approach has been implemented in NS-2 simulator.
2	    The results show accurate disaster detection, efficient spectrum usage, and interoperability and collaboration among nodes with reduced latency.


# 184
### http://arxiv.org/abs/1810.08111v1
## Enabling Hard Service Guarantees in Software-Defined Smart Grid Infrastructures


0	    Information and Communication Technology (ICT) infrastructures play a key role in the evolution from traditional power systems to Smart Grids.
0	    Increasingly fluctuating power flows, sparked by the transition towards sustainable energy generation, become a major issue for power grid stability.
0	    To deal with this challenge, future Smart Grids require precise monitoring and control, which in turn demand for reliable, real-time capable and cost-efficient communications.
1	    For this purpose, we propose applying Software-Defined Networking (SDN) to handle the manifold requirements of Smart Grid communications.
1	    To achieve reliability, our approach encompasses fast recovery after failures in the communication network and dynamic service-aware network (re-)configuration.
1	    Network Calculus (NC) logic is embedded into our SDN controller for meeting latency requirements imposed by the standard IEC 61850 of the International Electrotechnical Committee (IEC).
0	    Thus, routing provides delay-optimal paths under consideration of existing cross traffic.
1	    Also, continuous latency bound compliance is ensured by combining NC delay supervision with means of flexible reconfiguration.
1	    For evaluation we consider the well-known Nordic 32 test system, on which we map a corresponding communication network in both experiment and emulation.
2	    The described functionalities are validated, employing realistic IEC 61850 transmissions and distributed control traffic.
2	    Our results show that hard service guarantees can be ensured with the help of the proposed SDN solution.
2	    On this basis, we derive extremely time critical services, which must not be subjected to flexible reconfiguration.


# 185
### http://arxiv.org/abs/1810.11280v1
## Virtual Network Embedding via Decomposable LP Formulations: Orientations of Small Extraction Width and Beyond


0	    The Virtual Network Embedding Problem (VNEP) considers the efficient allocation of resources distributed in a substrate network to a set of request networks.
1	    Many existing works discuss either heuristics or exact algorithms, resulting in a choice between quick runtimes and quality guarantees for the solutions.
1	    Recently, the first fixed-parameter tractable (FPT) approximation algorithm for the VNEP with arbitrary request and substrate topologies has been published by Rost and Schmid.
1	    This algorithm is based on a LP formulation and is FPT in the newly introduced graph parameter extraction width (EW).
2	    It therefore combines positive traits of heuristics and exact approaches: The runtime is polynomial for instances with bounded EW, and the algorithm returns approximate solutions with high probability.
1	    We propose two extensions of this algorithm to optimize its runtime.
1	    Firstly, we develop a new LP formulation related to tree decompositions.
2	    We show that this LP formulation is always smaller, and that the resulting algorithm is FPT in the new parameter extraction label width (ELW).
2	    We improve on two important results by Rost and Schmid: For centrally rooted half-wheel topologies, the EW scales linearly with request size, whereas the ELW is constant.
2	    Further, adding any number of paths parallel to an existing edge increases the EW by at most the maximum degree of the request.
2	    By contrast, the ELW only increases by at most one.
2	    Lastly, we show that finding the minimal ELW is NP-hard.
1	    Secondly, we consider the approach of partitioning the request into subgraphs which are processed independently, yielding even smaller LP formulations.
2	    While this algorithm may lead to higher ELW within the subgraphs, we show that this increase is always smaller than the size of the inter-subgraph boundary.
2	    In particular, the algorithm has zero additional cost when subgraphs are separated by a single node.


# 186
### http://arxiv.org/abs/1811.09160v1
## Towards energy efficient buildings: how ICTs can convert advances?


1	    This work is a positioning research paper for energy efficient building based on ICT solutions.
1	    Through the literature about the solutions for energy control of buildings during operational phase, a 3-layers model is proposed to integrate these solutions: first level consists in communication technologies, second level is about data modelling and third level is related to decision-making tools.
1	    For each level, key research topics and remaining problems are identified in order to achieve a concrete step forward.
1	    CONTEXT AND PROBLEMATICS Through studies on ICT solutions for energy control of buildings, a 3-layers model is proposed to integrate these solutions and position a new way for energy efficiency.
1	    The building sector is the largest user of energy and CO 2 emitter in the EU, estimated at approximately 40% of the total consumption (Sharples et al.,
2	    According to the International Panel on Climate Change (European Union, 2010), 30% of energy used in buildings could be reduced with net economic benefits by 2030.
1	    Such a reduction, however, is meaningless unless "sustainability" is considered.
0	    Because of these factors, healthy, sustainable, and energy efficient buildings have become active topics in international research; there is an urgent need for a new kind of high-technology driven and integrative research that should lead to the massive development of smart buildings and, in the medium term, smart cities.
1	    From a building lifecycle perspective, most of the energy (~80%) is consumed during the operational stage of the building (European Union, 2010) (Bilsen et al.,
0	    Reducing building energy consumption may be addressed by the physical modifications which can be operated on a building like upgrading windows, heating systems or modifying thermic characteristics by insulating.
0	    Another possible path to reduce the energy consumption of a building is to use Information and Communication Technologies (ICT).
2	    According to the International Panel on Climate Change, a reduction of energy even greater than the 30% can be targeted by 2030 by considering ICT solutions.
2	    In support of this claim, some specialists believe that ICT-based solutions have the potential to enable 50-80% greenhouse gas reduction globally.
1	    In this respect, ICT innovation opens prospects for the development of a new range of new services highly available, flexible, safe, easy to integrate, and user friendly (Bilsen et al.,
1	    This, in turn, should foster a sophisticated, reliable and fast communication infrastructure for the connection of various distributed elements (sensors, generators, substations...) that enables to exchange real-time data, information and knowledge needed to improve efficiency (e.g., to monitor and control energy consumption), reliability (e.g., to facilitate maintenance operations), flexibility (e.g., to integrate new rules to meet new consumer expectations), and investment returns, but also to induce a shift in consumer behaviour.


# 187
### http://arxiv.org/abs/1812.01846v1
## HashFlow For Better Flow Record Collection


0	    Collecting flow records is a common practice of network operators and researchers for monitoring, diagnosing and understanding a network.
0	    Traditional tools like NetFlow face great challenges when both the speed and the complexity of the network traffic increase.
1	    To keep pace up, we propose HashFlow, a tool for more efficient and accurate collection and analysis of flow records.
1	    The central idea of HashFlow is to maintain accurate records for elephant flows, but summarized records for mice flows, by applying a novel collision resolution and record promotion strategy to hash tables.
2	    The performance bound can be analyzed with a probabilistic model, and with this strategy, HashFlow achieves a better utilization of space, and also more accurate flow records, without bringing extra complexity.
1	    We have implemented HashFlow, as well as several latest flow measurement algorithms such as FlowRadar, HashPipe and ElasticSketch, in a P4 software switch.
1	    Then we use traces from different operational networks to evaluate them.
2	    In these experiments, for various types of traffic analysis applications, HashFlow consistently demonstrates a clearly better performance against its state-of-the-art competitors.
0	    For example, using a small memory of 1 MB, HashFlow can accurately record around 55K flows, which is often 12.5% higher than the others.
2	    For estimating the sizes of 50K flows, HashFlow achieves a relative error of around 11.6%, while the estimation error of the best competitor is 42.9% higher.
2	    It detects 96.1% of the heavy hitters out of 250K flows with a size estimation error of 5.6%, which is 11.3% and 73.7% better than the best competitor respectively.
2	    At last, we show these merits of HashFlow come with almost no degradation of throughput.


# 188
### http://arxiv.org/abs/1812.05744v1
## FREE - Fine-grained Scheduling for Reliable and Energy Efficient Data Collection in LoRaWAN


0	    Collecting data from remote sensor devices with limited infrastructure is still considered a challenging task.
1	    Here, LoRa radios and LoRaWAN networks represent an appealing option due to their inexpensively, high link budgets, low energy consumption and one-hop system architecture.
0	    However, LoRaWAN suffers from a scalability issue due to its Aloha-like MAC layer.
1	    Additionally, the duty cycle restriction at the gateway limits the acknowledgment handling even in medium size networks.
1	    Therefore, we propose FREE as a fine-grained scheduling scheme for reliable and energy-efficient data collection in LoRaWAN.
0	    FREE schedules spreading factors, transmission powers, frequency channels, timeslots, and slot numbers in frames for LoRa end-devices.
0	    As a result, FREE overcomes the scalability issue of LoRaWAN by eliminating collisions and grouping acknowledgments.
1	    We propose two objective functions for FREE to either optimize the energy consumption or the data collection time.
1	    Their choice depends on gateway availability.
1	    We evaluate the performance of FREE for different LoRaWAN configurations.
2	    The numerical results show that FREE scales well for unconfirmable and confirmable transmissions.
2	    Furthermore, FREE achieves almost 100% data delivery and the estimated device lifetime is likely over 10 years regardless of the running application and the network size


# 189
### http://arxiv.org/abs/1812.06287v1
## On Virtual Network Embedding: Paths and Cycles


0	    Network virtualization provides a promising solution to overcome the ossification of current networks, allowing multiple Virtual Network Requests (VNRs) embedded on a common infrastructure.
1	    The major challenge in network virtualization is the Virtual Network Embedding (VNE) problem, which is to embed VNRs onto a shared substrate network and known to be $\mathcal{NP}$-hard.
2	    The topological heterogeneity of VNRs is one important factor hampering the performance of the VNE.
0	    However, in many specialized applications and infrastructures, VNRs are of some common structural features $\textit{e.g.}$, paths and cycles.
2	    To achieve better outcomes, it is thus critical to design dedicated algorithms for these applications and infrastructures by taking into accounting topological characteristics.
2	    Besides, paths and cycles are two of the most fundamental topologies that all network structures consist of.
0	    Exploiting the characteristics of path and cycle embeddings is vital to tackle the general VNE problem.
1	    In this paper, we investigated the path and cycle embedding problems.
1	    For path embedding, we proved its $\mathcal{NP}$-hardness and inapproximability.
1	    Then, by utilizing Multiple Knapsack Problem (MKP) and Multi-Dimensional Knapsack Problem (MDKP), we proposed an efficient and effective MKP-MDKP-based algorithm.
1	    For cycle embedding, we proposed a Weighted Directed Auxiliary Graph (WDAG) to develop a polynomial-time algorithm to determine the least-resource-consuming embedding.
2	    Numerical results showed our customized algorithms can boost the acceptance ratio and revenue compared to generic embedding algorithms in the literature.


# 190
### http://arxiv.org/abs/1812.07931v1
## Energy Efficient IoT Virtualization Framework with Peer to Peer Networking and Processing


1	    In this paper, an energy efficient IoT virtualization framework with P2P networking and edge computing is proposed.
1	    In this network, the IoT task processing requests are served by peers.
1	    The peers in our work are represented by IoT objects and relays that host virtual machines (VMs).
1	    We have considered three scenarios to investigate the saving in power consumption and the system capabilities in terms of task processing.
1	    The first scenario is the relays only scenario, where the task requests are processed using relays only.
1	    The second scenario is the objects only scenario, where the task requests are processed using the IoT objects only.
1	    The last scenario is a hybrid scenario, where the task requests are processed using both IoT objects and VMs.
1	    We have developed a mixed integer linear programming (MILP) model to maximize the number of processing tasks served by the system and minimize the total power consumed by the IoT network.
1	    We investigated our framework under the impact of VMs placement constraints, fairness constraints between the objects, tasks number limitations, uplink and downlink limited capacities, and processing capability limitations.
1	    Based on the MILP model principles, we developed an energy efficient virtualized IoT P2P networks heuristic (EEVIPN).
2	    The heuristic results were comparable to those of the MILP in terms of energy efficiency and tasks processing.
2	    Our results show that the hybrid scenario serves up to 77% (57% on average) processing task requests, but with higher energy consumption compared to the other scenarios.
2	    The relays only scenario can serve 74% (57% on average) of the processing task requests with 8% saving in power consumption compared to the hybrid scenario.
2	    In contrast, 28% (22% on average) of task requests can be successfully handled by applying the objects only scenario with up to 62% power saving compared to the hybrid scenario.


# 191
### http://arxiv.org/abs/1812.08309v1
## A Novel Adaptive Caching Mechanism for Video on Demand System over Wireless Mobile Network


0	    Video on Demand system over the wireless mobile network is a system that provides video services to mobile clients.
1	    The main problem with these systems is the high service delay where the mobile clients have to wait to view their favorite movie.
1	    The importance of this paper is based on finding a solution on how to reduce the delay time in the VOD system.
1	    This paper introduces a novel caching mechanism named Proxy Server Cache mechanism to tackle the issue of service delay.
2	    This delay happens when the broadcasting phase that is related to the first segment is missed by a client from the current broadcasting channels.
2	    This delay happens when the broadcasting phase that is related to the first segment is missed by a client from the current broadcasting channels.
1	    The delayed clients will directly acquire the first segment from the proxy server instead of waiting for the following broadcasting channel pertaining to the first segment.
1	    The proposed scheme ensures obtaining the first segment from mobile clients when they arrive.
2	    Additionally, the performance of the proposed scheme is validated by applying the VOD system, which can involve the balancing mechanism to retain particular requests through to the local proxy server to provide a fair dissemination for these requests.
2	    The obtained result confirms that the proposed scheme reduces the time delay of the system in comparison with the best existing schemes.
2	    The results of the average time delay in the Proxy-Cache scheme is 179.2505 milliseconds when 10 clients arrive each minute (Client/minute), the average time delay is 140 milliseconds when the video lengths are 30, 60 and 90.
2	    Meanwhile, the failure probability for obtaining the first segment of the video remains zero when the number of arrived requests is set to 2, 4, 6, 8 and 10.


# 192
### http://arxiv.org/abs/1812.11837v1
## Multi-Player Multi-Armed Bandit Based Resource Allocation for D2D Communications


0	    Device-to-device (D2D) communications is expected to play a significant role in increasing the system capacity of the fifth generation (5G) wireless networks.
0	    To accomplish this, efficient power and resource allocation algorithms need to be devised for the D2D users.
0	    Since the D2D users are treated as secondary users, their interference to the cellular users (CUs) should not hamper the CU communications.
0	    Most of the prior works on D2D resource allocation assume full channel state information (CSI) at the base station (BS).
0	    However, the required channel gains for the D2D pairs may not be known.
0	    To acquire these in a fast fading channel requires extra power and control overhead.
1	    In this paper, we assume partial CSI and formulate the D2D power and resource allocation problem as a multi-armed bandit problem.
1	    We propose a power allocation scheme for the D2D users in which the BS allocates power to the D2D users if a certain signal-to-interference-plus-noise ratio (SINR) is maintained for the CUs.
1	    In a single player environment a D2D user selects a CU in every time slot by employing UCB1 algorithm.
1	    Since this resource allocation problem can also be considered as an adversarial bandit problem we have applied the exponential-weight algorithm for exploration and exploitation (Exp3) to solve it.
1	    In a multiple player environment, we extend UCB1 and Exp3 to multiple D2D users.
1	    We also propose two algorithms that are based on distributed learning algorithm with fairness (DLF) and kth-UCB1 algorithms in which the D2D users are ranked.
2	    Our simulation results show that our proposed algorithms are fair and achieve good performance.


# 193
### http://arxiv.org/abs/1901.01603v2
## Should I stay or should I go: Analysis of the impact of application QoS on user engagement in YouTube


0	    To improve the quality of experience (QoE), especially under moderate to high traffic demand, it is important to understand the impact of the network and application QoS on user experience.
2	    This paper comparatively evaluates the impact of impairments, their intensity and temporal dynamics, on user engagement in the context of video streaming.
2	    The analysis employed two large YouTube datasets.
1	    To characterize the user engagement and the impact of impairments, several new metrics were defined.
1	    We assessed whether or not there is a statistically significant relationship between different types of impairments and QoE and user engagement metrics, taking into account not only the characteristics of the impairments but also the covariates of the session (e.g., video duration, mean datarate).
1	    After observing the relationships across the entire dataset, we tested whether these relationships also persist under specific conditions with respect to the covariates.
2	    The introduction of several new metrics and of various covariates in the analysis are two innovative aspects of this work.
2	    We found that the number of negative bitrate changes (BR-) is a stronger predictor of abandonment than rebufferrings (RB).
2	    Even positive bitrate changes (BR+) are associated with increases in abandonment.
2	    Specifically, BR+ in low resolution sessions is not well received.
2	    Temporal dynamics of the impairments have also an impact: a BR- that follows much later a RB appears to be perceived as a worse impairment than a BR- that occurs immediately after a RB.
2	    These results can be used to guide the design of the video streaming adaptation as well as suggest which parameters should be varied in controlled field studies.


# 194
### http://arxiv.org/abs/1901.02111v1
## Scheduling for VoLTE: Resource Allocation Optimization and Low-Complexity Algorithms


0	    We consider scheduling and resource allocation in long-term evolution (LTE) networks across voice over LTE (VoLTE) and best-effort data users.
2	    The difference between these two is that VoLTE users get scheduling priority to receive their required quality of service.
2	    As we show, strict priority causes data services to suffer.
1	    We propose new scheduling and resource allocation algorithms to maximize the sum- or proportional fair (PF) throughout amongst data users while meeting VoLTE demands.
1	    Essentially, we use VoLTE as an example application with both a guaranteed bit-rate and strict application-specific requirements.
1	    We first formulate and solve the frame-level optimization problem for throughput maximization; however, this leads to an integer problem coupled across the LTE transmission time intervals (TTIs).
1	    We then propose a TTI-level problem to decouple scheduling across TTIs.
1	    Finally, we propose a heuristic, with extremely low complexity.
2	    The formulations illustrate the detail required to realize resource allocation in an implemented standard.
2	    Numerical results show that the performance of the TTI-level scheme is very close to that of the frame-level upper bound.
2	    Similarly, the heuristic scheme works well compared to TTI-level optimization and a baseline scheduling algorithm.
2	    Finally, we show that our PF optimization retains the high fairness index characterizing PF-scheduling.


# 195
### http://arxiv.org/abs/1901.02306v1
## Tutorial on UAV: A Blue Sky View on Wireless Communication


0	    The growing use of Unmanned Aerial Vehicles (UAVs) for various applications requires ubiquitous and reliable connectivity for safe control and data exchange between these devices and ground terminals.
0	    Depending on the application, UAV-mounted wireless equipment can either be an aerial user equipment (AUE) that co-exists with the terrestrial users, or it can be a part of wireless infrastructure providing a range of services to the ground users.
1	    For instance, AUE can be used for real-time search and rescue and Aerial Base Station (ABS) can enhance coverage, capacity and energy efficiency of wireless networks.
0	    In both cases, UAV-based solutions are scalable, mobile, fast to deploy.
0	    However, several technical challenges have to be addressed.
1	    In this work, we present a tutorial on wireless communication with UAVs, taking into account a wide range of potential applications.
1	    The main goal of this work is to provide a complete overview of the main scenarios (AUE and ABS), channel and performance models, compare them, and discuss open research points.
1	    This work gives a comprehensive overview of the research done until now and depicts a comprehensive picture to foster new ideas and solutions while avoiding duplication of past work.
1	    We start by discussing the open challenges of wireless communication with UAVs.
0	    To give answers to the posed questions, we focus on the UAV communication basics, mainly providing the necessary channel modeling background and giving guidelines on how various channel models should be used.
0	    Next, theoretical, simulation- and measurement-based approaches, to address the key challenges for AUE usage, are presented.
0	    Moreover, in this work, we aim to provide a comprehensive overview on how UAV-mounted equipment can be used as a part of a communication network.
2	    Based on the theoretical analysis, we show how various network parameters can be optimized.


# 196
### http://arxiv.org/abs/1901.02700v1
## Multi-layer Game-Theoretical Analysis of Wireless Markets with Market Segmentation


0	    New larger and more diverse wireless markets have emerged.
0	    Modelling them can be challenging due to various business and network aspects.
0	    Existing models of wireless markets are either microscopic, focusing on a specific technical aspect (e.g., network topology) at a fine scale or macroscopic modelling wireless markets at a large-scale, e.g., considering homogeneous populations.
0	    In contrast to these approaches, this work develops a multi-layer game-theoretical framework, which allows providers to model users at multiple-level of detail by considering a different number of user sub-populations.
0	    It also models the mobility, traffic demand, and networks of providers.
1	    A population game using Logit dynamics models the user selection of the dataplan and provider, capturing the diversity in customer profile and relaxing the assumption about the user rationality.
1	    It analytically computes the equilibriums of users and providers and numerically evaluates the performance of the market as a function of the traffic demand, the number of available dataplans, and the knowledge about customer population.
2	    Significant benefits in revenue can be achieved by a provider when it integrates more detailed information about the user population.
2	    The number of disconnected users also decreases.
2	    Moreover the availability of several dataplans further enhances the gains.
2	    The stronger the provider, the more prominent the benefits.
2	    However the benefits diminish when all the providers model the customer population at the same degree of detail due to an increased competition.
2	    The analysis highlights the strategies of the providers depending on their capacity, level of knowledge about the customer population, and traffic conditions.
0	    It illustrates how a provider changes its strategy under different conditions, focusing potentially on different customer segments and also the pressure introduced by specific customer types.


# 197
### http://arxiv.org/abs/1901.10156v2
## TNT, Watch me Explode: A Light in the Dark for Revealing MPLS Tunnels


0	    Internet topology discovery has been a recurrent research topic for nearly 20 years now.
0	    Usually, it works by sending hop-limited probes (i.e., traceroute) towards a set of destinations to collect topological data in order to infer the Internet topology at a given scale (e.g., at the router or the AS level).
0	    However, traceroute comes with multiple limitations, in particular with layer-2 clouds such as MPLS that might hide their content to traceroute exploration.
0	    Thus, the resulting Internet topology data and models are incomplete and inaccurate.
1	    In this paper, we introduce TNT (Trace the Naughty Tunnels), an extension to Paris traceroute for revealing most (if not all) MPLS tunnels along a path.
1	    TNT works in two basic stages.
1	    First, along with traceroute probes, it looks for evidences of the potential presence of hidden tunnels.
0	    Those evidences are surprising patterns in the traceroute output, e.g., abrupt and significant TTL shifts.
0	    Second, if alarms are triggered due to the presence of such evidences, TNT launches additional and dedicated probing for possibly revealing the content of the hidden tunnel.
1	    We validate TNT through emulation with GNS3 and tune its parameters through a dedicated measurement campaign.
1	    We also largely deploy TNT on the Archipelago platform and provide a quantification of tunnels, updating so the state of the art vision of MPLS tunnels.
2	    Finally, TNT and its validation platform are fully and publicly available, as well as the collected data and scripts used for processing data.


# 198
### http://arxiv.org/abs/1902.01669v1
## Rama: Controller Fault Tolerance in Software-Defined Networking Made Practical


0	    In Software-Defined Networking (SDN), network applications use the logically centralized network view provided by the controller to remotely orchestrate the network switches.
0	    To avoid the controller being a single point of failure, traditional fault-tolerance techniques are employed to guarantee availability, a fundamental requirement in production environments.
0	    Unfortunately, these techniques fall short of ensuring correct network behaviour under controller failures.
0	    The problem of these techniques is that they deal with only part of the problem: guaranteeing that application and controller state remains consistent between replicas.
0	    However, in an SDN the switches maintain hard state that must also be handled consistently.
0	    Fault-tolerant SDN must therefore include switch state into the problem.
1	    A recently proposed fault-tolerant controller platform, Ravana, solves this problem by extending fault-tolerant SDN control with mechanisms that guarantee control messages to be processed transactionally and exactly once, at both the controllers and the switches.
1	    These guarantees are given even in the face of controller and switch crashes.
1	    The elegance of this solution comes at a cost.
1	    Ravana requires switches to be modified and OpenFlow to be extended with hitherto unforeseen additions to the protocol.
1	    In face of this challenge we propose Rama, a fault-tolerant SDN controller platform that offers the same strong guarantees as Ravana without requiring modifications to switches or to the OpenFlow protocol.
2	    Experiments with our prototype implementation show the additional overhead to be modest, making Rama the first fault-tolerant SDN solution that can be immediately deployable.


# 199
### http://arxiv.org/abs/1902.01926v1
## IoT Device Fingerprint using Deep Learning


1	    Device Fingerprinting (DFP) is the identification of a device without using its network or other assigned identities including IP address, Medium Access Control (MAC) address, or International Mobile Equipment Identity (IMEI) number.
1	    DFP identifies a device using information from the packets which the device uses to communicate over the network.
1	    Packets are received at a router and processed to extract the information.
1	    In this paper, we worked on the DFP using Inter Arrival Time (IAT).
1	    IAT is the time interval between the two consecutive packets received.
0	    This has been observed that the IAT is unique for a device because of different hardware and the software used for the device.
1	    The existing work on the DFP uses the statistical techniques to analyze the IAT and to further generate the information using which a device can be identified uniquely.
1	    This work presents a novel idea of DFP by plotting graphs of IAT for packets with each graph plotting 100 IATs and subsequently processing the resulting graphs for the identification of the device.
1	    This approach improves the efficiency to identify a device DFP due to achieved benchmark of the deep learning libraries in the image processing.
1	    We configured Raspberry Pi to work as a router and installed our packet sniffer application on the Raspberry Pi .
1	    The packet sniffer application captured the packet information from the connected devices in a log file.
1	    We connected two Apple devices iPad4 and iPhone 7 Plus to the router and created IAT graphs for these two devices.
1	    We used Convolution Neural Network (CNN) to identify the devices and observed the accuracy of 86.7%.


# 200
### http://arxiv.org/abs/1902.01937v1
## Virtually the Same: Comparing Physical and Virtual Testbeds


0	    Network designers, planners, and security professionals increasingly rely on large-scale virtual testbeds to emulate networks and make decisions about real-world deployments.
0	    However, there has been limited research on how well these virtual testbeds match their physical counterparts.
2	    Specifically, does the virtualization that these testbeds depend on actually capture real-world behaviors sufficiently well to support decisions?
1	    As a first step, we perform simple experiments on both physical and virtual testbeds to begin to understand where and how the testbeds differ.
1	    We set up a web service on one host and run ApacheBench against this service from a different host, instrumenting each system during these tests.
1	    We define an initial repeatable methodology to quantitatively compare testbeds.
1	    Specifically, we compare the testbeds at three levels of abstraction: application, operating system (OS) and network.
1	    For the application level, we use the ApacheBench results.
2	    For OS behavior, we compare patterns of system call orderings using Markov chains.
2	    This provides a unique visual representation of the workload and OS behavior in our testbeds.
1	    We also drill down into read-system-call behaviors and show how at one level both systems are deterministic and identical, but as we move up in abstractions that consistency declines.
1	    Finally, we use packet captures to compare network behaviors and performance.
1	    We reconstruct flows and compare per-flow and per-experiment statistics.
2	    We find that the behavior of the workload in the testbeds is similar but that the underlying processes to support it do vary.
2	    The low-level network behavior can vary widely in packetization depending on the virtual network driver.
2	    While these differences can be important, and knowing about them will help experiment designers, the core application and OS behaviors still represent similar processes.


# 201
### http://arxiv.org/abs/1902.06933v1
## A Quasi-random Algorithm for Anonymous Rendezvous in Heterogeneous Cognitive Radio Networks


0	    The multichannel rendezvous problem that asks two secondary users to rendezvous on a common available channel in a cognitive radio network (CRN) has received a lot of attention lately.
1	    Most rendezvous algorithms in the literature focused on constructing channel hopping (CH) sequences that guarantee finite maximum time-to-rendezvous (MTTR).
1	    However, these algorithms perform rather poorly in terms of the expected time-to-rendezvous (ETTR) even when compared to the simple random algorithm.
1	    In this paper, we propose the quasi-random (QR) CH algorithm that has a comparable ETTR to the random algorithm and a comparable MTTR to the best bound in the literature.
1	    Our QR algorithm does not require the unique identifier (ID) assumption and it is very simple to implement in the symmetric, asynchronous, and heterogeneous setting with multiple radios.
1	    In a CRN with $N$ commonly labelled channels, the MTTR of the QR algorithm is bounded above by $9 M \lceil n_1/m_1 \rceil \cdot \lceil n_2/m_2 \rceil$ time slots, where $n_1$ (resp.
1	    $n_2$) is the number of available channels to user $1$ (resp.
1	    $m_2$) is the number of radios for user $1$ (resp.
1	    2), and $M=\lceil \lceil \log_2 N \rceil /4 \rceil *5+6$. Such a bound is only slightly larger than the best $O((\log \log N) \frac{n_1 n_2}{m_1 m_2})$ bound in the literature.
1	    When each SU has a single radio, the ETTR is bounded above by $\frac{n_1 n_2}{G}+9Mn_1n_2 \cdot (1-\frac{G}{n_1 n_2})^M$, where $G$ is the number of common channels between these two users.
2	    By conducting extensive simulations, we show that for both the MTTR and the ETTR, our algorithm is comparable to the simple random algorithm and it outperforms several existing algorithms in the literature.


# 202
### http://arxiv.org/abs/1903.00951v1
## Practical Prediction of Human Movements Across Device Types and Spatiotemporal Granularities


0	    Understanding and predicting mobility are essential for the design and evaluation of future mobile edge caching and networking.
0	    Consequently, research on prediction of human mobility has drawn significant attention in the last decade.
0	    Employing information-theoretic concepts and machine learning methods, earlier research has shown evidence that human behavior can be highly predictable.
0	    Despite existing studies, more investigations are needed to capture intrinsic mobility characteristics constraining predictability, and to explore more dimensions (e.g. device types) and spatio-temporal granularities, especially with the change in human behavior and technology.
1	    We analyze extensive longitudinal datasets with fine spatial granularity (AP level) covering 16 months.
2	    The study reveals device type as an important factor affecting predictability.
0	    Ultra-portable devices such as smartphones have "on-the-go" mode of usage (and hence dubbed "Flutes"), whereas laptops are "sit-to-use" (dubbed "Cellos").
0	    The goal of this study is to investigate practical prediction mechanisms to quantify predictability as an aspect of human mobility modeling, across time, space and device types.
1	    We apply our systematic analysis to wireless traces from a large university campus.
1	    We compare several algorithms using varying degrees of temporal and spatial granularity for the two modes of devices; Flutes vs. Cellos.
1	    Through our analysis, we quantify how the mobility of Flutes is less predictable than the mobility of Cellos.
2	    In addition, this pattern is consistent across various spatio-temporal granularities, and for different methods (Markov chains, neural networks/deep learning, entropy-based estimators).
0	    This work substantiates the importance of predictability as an essential aspect of human mobility, with direct application in predictive caching, user behavior modeling and mobility simulations.


# 203
### http://arxiv.org/abs/1903.06613v2
## Grid Computing Model for Mobile: A Better Mobile Grid Computing Model


0	    Grid Computing is an idea of a new kind of network technology in which research work in progress.
1	    There is a great deal of hype in this technology based area for that reason it is getting a great deal of attention of the computing community.
1	    Grid Computing makes use of clusters of PCs (personal computers), network servers or other computing technology-based systems.
1	    These systems are connecting jointly to deal with complex calculations, communication and collaboration.
1	    Grid Computing offers a great deal of support for offering corporations to make use of their idle computing power, or systems processing cycles, to produce a type of supercomputer arrangement.
1	    The technology of grid computing has newly transferred from customary high performance plus distributed technology based computing systems to utility and pervasive based computing arrangements.
0	    These technology-based structures are having superior potentials of the wireless networks communication and collaboration as well as having thin, lightweight and remotely accessible devices.
0	    This has as produced the establishment new computing technology paradigm known as Mobile Grid Computing.
1	    This research is going to assess and analyze the grid computing and mobile computing technology based arrangements.
1	    Here I will assess the feasibility analysis of the mobile grid computing.
1	    This research will analyze the mapping of grid computing techniques on the mobile domain.
1	    In this scenario, I will assess how can, we achieve grid architecture in mobile devices.
1	    For the sake of implementing a mobile gird arrangement, I will analyze the existing grid computing models and discuss the design, implementation, architecture and its limitations.
2	    This research will also highlight the effect of grid computing on mobiles load balancing, high processing efficiency and less network communication.


# 204
### http://arxiv.org/abs/1903.07904v1
## Resource Allocation for Loss Tolerant Video Streaming in eMBMS


0	    Bandwidth hungry video content has become the dominant contributor to the data traffic world over.
0	    Cellular networks are constantly evolving to meet the growing traffic demands.
0	    Over the past few years, wireless multicast has been garnering a lot of attention as a means of efficient resource utilization.
2	    Multicast transmission lets spectral resources to be shared between users streaming the same content.
2	    Even though multicast transmission allows to serve multiple users on the same resources, in order to serve all these users successfully, the base station cannot transmit the content at a rate greater than that decodable by the user with the worst channel conditions.
1	    In this paper, we propose a way to overcome this bottleneck.
0	    Video streaming services can sustain a certain amount of packet loss without any significant degradation in the quality experienced by the users.
1	    We leverage this loss tolerant nature of video streaming applications to improve the performance of multicast video services in LTE and 5G. We convert the problem of resource allocation for loss tolerant multicasting into the problem of stabilizing a queueing system.
1	    We then propose two throughput optimal Maximum Weight (MW) policies that successfully stabilize the constructed queueing system.
0	    However, brute force implementation of MW policies is mostly NP-hard.
1	    To overcome this, we propose a maximum weight bipartite matching approach that results in a polynomial time implementation of the proposed policies.
1	    We also evaluate the performance of our policies via extensive simulations.


# 205
### http://arxiv.org/abs/1903.08974v1
## HELPER: Heterogeneous Efficient Low Power Radio for Enabling Ad Hoc Emergency Public Safety Networks


0	    Natural and man-made disasters have been causing destruction and distress to humanity all over the world.
0	    In these scenarios, communication infrastructures are the most affected entities making emergency response operations extremely challenging.
0	    This invokes a need to equip the affected people and the emergency responders with the ability to rapidly set up and use independent means of communication.
1	    Therefore, in this work, we present a complete end-to-end solution that can connect survivors of a disaster with each other and the authorities using a completely self-sufficient ad hoc network that can be setup rapidly.
0	    Accordingly, we develop a Heterogeneous Efficient Low Power Radio (HELPER) that acts as an access point for end-users to connect using custom website application.
1	    These HELPERs then coordinate with each other to form a LoRa based ad hoc network.
1	    To this end, we propose a novel cross-layer optimized distributed energy-efficient routing (SEEK) algorithm that aims to maximize the network lifetime.
1	    The HELPER is prototyped using WiFi enabled Raspberry Pi and LoRa module that is configured to run using Li-ion batteries.
1	    We implement the required cross-layer protocol stack along with the SEEK routing algorithm.
1	    We have conducted demonstrations to establish the feasibility of exchanging of text messages over the HELPER network, live map updates, ability to send distress messages to authorities.
2	    Emergency responders can leverage this technology to remotely monitor the connectivity of the affected area and alert users of imminent dangers.
2	    SEEK algorithm was shown to outperform a greedy geographical routing algorithm implemented on HELPER testbed by up to 53 % in terms of network lifetime and up to 28 % in terms of throughput.
2	    Overall, we hope this technology will become instrumental in improving the efficiency and effectiveness of public safety activities.


# 206
### http://arxiv.org/abs/1903.10071v1
## On the Performance of Mobility-Aware D2D Caching Networks


0	    The increase in demand for spectrum-based services forms a bottleneck in wireless networks.
0	    Device-to-Device (D2D) caching networks tackle this problem by exploiting user's behavior predictability and the possibility of sharing data between them to alleviate the network congestion.
0	    However, capturing mobility statistics allows Service Providers (SPs) to enhance their caching strategies.
1	    In this work, we introduce a mobility-aware D2D caching network where SP harnesses user demand and mobility statistics to minimize the incurred service cost through an optimal caching policy.
1	    We investigate two caching schemes: centralized and decentralized caching schemes.
1	    In the centralized caching scheme, SP makes the caching decision towards its cost minimization to increase its profit.
0	    However, the complexity of optimal caching policy grows exponentially with the number of users.
1	    Therefore, we discuss a greedy caching algorithm which has a polynomial order complexity.
1	    We also use this greedy algorithm to establish upper and lower bounds on the proactive service gain achieved by the optimal caching policy.
1	    In the decentralized caching scheme, users take over and make their caching decisions, in a distributed fashion affected by the SP pricing policy, towards their payment minimization.
1	    We formulated the tension between the SP and users as a Stackelberg game.
1	    The Best response analysis was used to identify a sub-game perfect Nash equilibrium (SPNE) between users.
2	    The optimal solution of proposed model was found to depend on the SP reward preference, which affects the assigned memory in users' devices.
2	    We found some regimes for the reward value where the SPNE was non-unique.
1	    A fair allocation caching policy was adopted to choose one of these SPNEs.
0	    To understand the impact of user behavior, we investigated some special cases to explore how user's mobility statistics affect their caching decision.


# 207
### http://arxiv.org/abs/1903.10289v2
## A Dataset of Full-Stack ITS-G5 DSRC Communications over Licensed and Unlicensed Bands Using a Large-Scale Urban Testbed


0	    A large-scale dataset of measurements of ETSI ITS-G5 Dedicated Short Range Communications (DSRC) is presented.
1	    Our dataset consists of network interactions happening between two On-Board Units (OBUs) and four Road Side Units (RSUs).
1	    Each OBU was fitted onto a vehicle.
1	    The two vehicles have been driven across the Innovate UK-funded FLOURISH Test Track encompassing key roads in the center of Bristol, UK.
1	    As for the RSUs, they were located at fixed locations around the track.
1	    Each RSU and OBU were equipped with two transceivers operating at different frequencies.
1	    During our experiments, each transceiver broadcast Cooperative Awareness Messages (CAMs) every 10 ms to the neighboring RSUs and OBUs.
1	    Our dataset contains eight experimental sessions of the length of $\sim$2 h each that have taken place over four days -- allocating two experimental sessions per-day.
1	    On each day, the two transceivers onboard each device were operated on two different frequencies.
1	    In particular, we operated the transceivers both over the licensed DSRC band, and over the unlicensed Industrial, Scientific, and Medical radio (ISM) bands 2.4 GHz-2.5 GHz and 5.725 GHz-5.875 GHz.
1	    During each experimental session, for each transceiver, all the transmitted and received CAMs were recorded.
1	    For each of the received CAMs, we also recorded its Received Signal Strength Indicator (RSSI) and the location of the receiving transceiver.
2	    The dataset can be found at https://doi.org/10.5523/bris.eupowp7h3jl525yxhm3521f57, and it has been analyzed in the following paper: I. Mavromatis, A. Tassi, and R. J. Piechocki, "Operating ITS-G5 DSRC over Unlicensed Bands: A City-Scale Performance Evaluation," Submitted to IEEE VTC-Spring 2019. [


# 208
### http://arxiv.org/abs/1903.11550v1
## Optimal Virtual Network Function Placement and Resource Allocation in Multi-Cloud Service Function Chaining Architecture


1	    Service Function Chaining (SFC) is the problem of deploying various network service instances over geographically distributed data centers and providing inter-connectivity among them.
0	    The goal is to enable the network traffic to flow smoothly through the underlying network, resulting in an optimal quality of experience to the end-users.
0	    Proper chaining of network functions leads to optimal utilization of distributed resources.
0	    This has been a de-facto model in the telecom industry with network functions deployed over underlying hardware.
0	    Though this model has served the telecom industry well so far, it has been adapted mostly to suit the static behavior of network services and service demands due to the deployment of the services directly over physical resources.
2	    This results in network ossification with larger delays to the end-users, especially with the data-centric model in which the computational resources are moving closer to end users.
1	    A novel networking paradigm, Network Function Virtualization (NFV), meets the user demands dynamically and reduces operational expenses (OpEx) and capital expenditures (CapEx), by implementing network functions in the software layer known as virtual network functions (VNFs).
1	    VNFs are then interconnected to form a complete end-to-end service, also known as service function chains (SFCs).
1	    In this work, we study the problem of deploying service function chains over network function virtualized architecture.
1	    Specifically, we study virtual network function placement problem for the optimal SFC formation across geographically distributed clouds.
1	    We set up the problem of minimizing inter-cloud traffic and response time in a multi-cloud scenario as an ILP optimization problem, along with important constraints such as total deployment costs and service level agreements (SLAs).
2	    We consider link delays and computational delays in our model.


# 209
### http://arxiv.org/abs/1904.00381v1
## Exploring the Effectiveness of Service Decomposition in Fog Computing Architecture for the Internet of Things


0	    The Internet of Things (IoT) aims to connect everyday physical objects to the internet.
0	    These objects will produce a significant amount of data.
1	    The traditional cloud computing architecture aims to process data in the cloud.
0	    As a result, a significant amount of data needs to be communicated to the cloud.
0	    This creates a number of challenges, such as high communication latency between the devices and the cloud, increased energy consumption of devices during frequent data upload to the cloud, high bandwidth consumption, while making the network busy by sending the data continuously, and less privacy because of less control on the transmitted data to the server.
0	    Fog computing has been proposed to counter these weaknesses.
0	    Fog computing aims to process data at the edge and substantially eliminate the necessity of sending data to the cloud.
0	    However, combining the Service Oriented Architecture (SOA) with the fog computing architecture is still an open challenge.
0	    In this paper, we propose to decompose services to create linked-microservices (LMS).
0	    Linked-microservices are services that run on multiple nodes but closely linked to their linked-partners.
1	    Linked-microservices allow distributing the computation across different computing nodes in the IoT architecture.
1	    Using four different types of architectures namely cloud, fog, hybrid and fog+cloud, we explore and demonstrate the effectiveness of service decomposition by applying four experiments to three different type of datasets.
2	    Evaluation of the four architectures shows that decomposing services into nodes reduce the data consumption over the network by 10% - 70%.
2	    Overall, these results indicate that the importance of decomposing services in the context of fog computing for enhancing the quality of service.


# 210
### http://arxiv.org/abs/1904.01700v1
## Research of Stability in Ad Hoc Self-Organizated Wireless Networks


0	    To date, there is a need for the development of efficient data and device exchange protocols that this exchange will provide, since standard protocols used in traditional networks can not fully meet the needs of a new type of network.
1	    The article describes the process of development and implementation of a full-scale model of noise-resistant and sensor network breaks.
1	    The stability of this network is achieved by building a distributed network, in which all nodes send messages to all available nodes.
0	    Wireless mobile peer-to-peer network (MANET) can be configured automatically, so the nodes in it can move freely.
0	    Wireless networks do not have the complexity of infrastructure and management, which allows devices to create and join on-the-go networks - anywhere, anytime.
1	    In this paper, the theoretical part of the functioning of such networks and the field of their use is considered.
1	    After that, an initial analysis of the available equipment used for constructing such hardware solutions was conducted.
1	    The software for developing such solutions is considered in detail, as well as examples of finished models that implement the investigated functional.
1	    After that, several variants of the model of network nodes, as well as the test device for creating a payload on the network, are collected.
1	    For this purpose, third-party open solutions were used in conjunction with their own developments.
1	    The system received a series of tests that made it possible to understand the weak and strong points of such a network and draw conclusions for the further development of the project and the creation of an improved working prototype.
1	    The article presents the basic electrical circuits of devices, the list of used equipment and software used and the photographic material of prototypes of the created system.


# 211
### http://arxiv.org/abs/cs/0007005v1
## Systematic Testing of Multicast Routing Protocols: Analysis of Forward and Backward Search Techniques


0	    In this paper, we present a new methodology for developing systematic and automatic test generation algorithms for multipoint protocols.
0	    These algorithms attempt to synthesize network topologies and sequences of events that stress the protocol's correctness or performance.
0	    This problem can be viewed as a domain-specific search problem that suffers from the state space explosion problem.
0	    One goal of this work is to circumvent the state space explosion problem utilizing knowledge of network and fault modeling, and multipoint protocols.
1	    The two approaches investigated in this study are based on forward and backward search techniques.
1	    We use an extended finite state machine (FSM) model of the protocol.
1	    The first algorithm uses forward search to perform reduced reachability analysis.
1	    Using domain-specific information for multicast routing over LANs, the algorithm complexity is reduced from exponential to polynomial in the number of routers.
0	    This approach, however, does not fully automate topology synthesis.
1	    The second algorithm, the fault-oriented test generation, uses backward search for topology synthesis and uses backtracking to generate event sequences instead of searching forward from initial states.
1	    Using these algorithms, we have conducted studies for correctness of the multicast routing protocol PIM.
1	    We propose to extend these algorithms to study end-to-end multipoint protocols using a virtual LAN that represents delays of the underlying multicast distribution tree.


# 212
### http://arxiv.org/abs/cs/0203030v2
## Source Routing and Scheduling in Packet Networks


0	    We study {\em routing} and {\em scheduling} in packet-switched networks.
1	    We assume an adversary that controls the injection time, source, and destination for each packet injected.
1	    A set of paths for these packets is {\em admissible} if no link in the network is overloaded.
1	    We present the first on-line routing algorithm that finds a set of admissible paths whenever this is feasible.
1	    Our algorithm calculates a path for each packet as soon as it is injected at its source using a simple shortest path computation.
1	    The length of a link reflects its current congestion.
1	    We also show how our algorithm can be implemented under today's Internet routing paradigms.
1	    When the paths are known (either given by the adversary or computed as above) our goal is to schedule the packets along the given paths so that the packets experience small end-to-end delays.
1	    The best previous delay bounds for deterministic and distributed scheduling protocols were exponential in the path length.
1	    In this paper we present the first deterministic and distributed scheduling protocol that guarantees a polynomial end-to-end delay for every packet.
1	    Finally, we discuss the effects of combining routing with scheduling.
1	    We first show that some unstable scheduling protocols remain unstable no matter how the paths are chosen.
0	    However, the freedom to choose paths can make a difference.
2	    For example, we show that a ring with parallel links is stable for all greedy scheduling protocols if paths are chosen intelligently, whereas this is not the case if the adversary specifies the paths.


# 213
### http://arxiv.org/abs/cs/0206001v1
## Neural Net Model for Featured Word Extraction


0	    Search engines perform the task of retrieving information related to the user-supplied query words.
1	    This task has two parts; one is finding "featured words" which describe an article best and the other is finding a match among these words to user-defined search terms.
0	    There are two main independent approaches to achieve this task.
1	    The first one, using the concepts of semantics, has been implemented partially.
1	    For more details see another paper of Marko et al.,
0	    The second approach is reported in this paper.
1	    It is a theoretical model based on using Neural Network (NN).
1	    Instead of using keywords or reading from the first few lines from papers/articles, the present model gives emphasis on extracting "featured words" from an article.
1	    Obviously we propose to exclude prepositions, articles and so on, that is, English words like "of, the, are, so, therefore, " etc.
1	    from such a list.
1	    A neural model is taken with its nodes pre-assigned energies.
1	    Whenever a match is found with featured words and userdefined search words, the node is fired and jumps to a higher energy.
1	    This firing continues until the model attains a steady energy level and total energy is now calculated.
2	    Clearly, higher match will generate higher energy; so on the basis of total energy, a ranking is done to the article indicating degree of relevance to the user's interest.
1	    Another important feature of the proposed model is incorporating a semantic module to refine the search words; like finding association among search words, etc.
2	    In this manner, information retrieval can be improved markedly.


# 214
### http://arxiv.org/abs/cs/0208023v1
## The STRESS Method for Boundary-point Performance Analysis of End-to-end Multicast Timer-Suppression Mechanisms


0	    Evaluation of Internet protocols usually uses random scenarios or scenarios based on designers' intuition.
0	    Such approach may be useful for average-case analysis but does not cover boundary-point (worst or best-case) scenarios.
0	    To synthesize boundary-point scenarios a more systematic approach is needed.
1	    In this paper, we present a method for automatic synthesis of worst and best case scenarios for protocol boundary-point evaluation.
1	    Our method uses a fault-oriented test generation (FOTG) algorithm for searching the protocol and system state space to synthesize these scenarios.
1	    The algorithm is based on a global finite state machine (FSM) model.
1	    We extend the algorithm with timing semantics to handle end-to-end delays and address performance criteria.
1	    We introduce the notion of a virtual LAN to represent delays of the underlying multicast distribution tree.
1	    The algorithms used in our method utilize implicit backward search using branch and bound techniques and start from given target events.
0	    This aims to reduce the search complexity drastically.
1	    As a case study, we use our method to evaluate variants of the timer suppression mechanism, used in various multicast protocols, with respect to two performance criteria: overhead of response messages and response time.
2	    Simulation results for reliable multicast protocols show that our method provides a scalable way for synthesizing worst-case scenarios automatically.
2	    Results obtained using stress scenarios differ dramatically from those obtained through average-case analyses.
2	    We hope for our method to serve as a model for applying systematic scenario generation to other multicast protocols.


# 215
### http://arxiv.org/abs/cs/0703004v1
## Accelerating Socio-Technological Evolution: from ephemeralization and stigmergy to the global brain


0	    Evolution is presented as a trial-and-error process that produces a progressive accumulation of knowledge.
0	    At the level of technology, this leads to ephemeralization, i.e. ever increasing productivity, or decreasing of the friction that normally dissipates resources.
0	    As a result, flows of matter, energy and information circulate ever more easily across the planet.
0	    This global connectivity increases the interactions between agents, and thus the possibilities for conflict.
0	    However, evolutionary progress also reduces social friction, via the creation of institutions.
0	    The emergence of such "mediators" is facilitated by stigmergy: the unintended collaboration between agents resulting from their actions on a shared environment.
1	    The Internet is a near ideal medium for stigmergic interaction.
0	    Quantitative stigmergy allows the web to learn from the activities of its users, thus becoming ever better at helping them to answer their queries.
2	    Qualitative stigmergy stimulates agents to collectively develop novel knowledge.
2	    Both mechanisms have direct analogues in the functioning of the human brain.
2	    This leads us to envision the future, super-intelligent web as a "global brain" for humanity.
2	    The feedback between social and technological advances leads to an extreme acceleration of innovation.
2	    An extrapolation of the corresponding hyperbolic growth model would forecast a singularity around 2040.
2	    This can be interpreted as the evolutionary transition to the Global Brain regime.


# 216
### http://arxiv.org/abs/0810.1226v1
## Traffic Dynamics of Computer Networks


0	    Two important aspects of the Internet, namely the properties of its topology and the characteristics of its data traffic, have attracted growing attention of the physics community.
0	    My thesis has considered problems of both aspects.
1	    First I studied the stochastic behavior of TCP, the primary algorithm governing traffic in the current Internet, in an elementary network scenario consisting of a standalone infinite-sized buffer and an access link.
1	    The effect of the fast recovery and fast retransmission (FR/FR) algorithms is also considered.
2	    I showed that my model can be extended further to involve the effect of link propagation delay, characteristic of WAN.
2	    I continued my thesis with the investigation of finite-sized semi-bottleneck buffers, where packets can be dropped not only at the link, but also at the buffer.
0	    I demonstrated that the behavior of the system depends only on a certain combination of the parameters.
2	    Moreover, an analytic formula was derived that gives the ratio of packet loss rate at the buffer to the total packet loss rate.
1	    This formula makes it possible to treat buffer-losses as if they were link-losses.
1	    Finally, I studied computer networks from a structural perspective.
1	    I demonstrated through fluid simulations that the distribution of resources, specifically the link bandwidth, has a serious impact on the global performance of the network.
1	    Then I analyzed the distribution of edge betweenness in a growing scale-free tree under the condition that a local property, the in-degree of the "younger" node of an arbitrary edge, is known in order to find an optimum distribution of link capacity.
1	    The derived formula is exact even for finite-sized networks.
1	    I also calculated the conditional expectation of edge betweenness, rescaled for infinite networks.


# 217
### http://arxiv.org/abs/0901.2689v1
## Peer-to-Peer Secure Multi-Party Numerical Computation Facing Malicious Adversaries


1	    We propose an efficient framework for enabling secure multi-party numerical computations in a Peer-to-Peer network.
0	    This problem arises in a range of applications such as collaborative filtering, distributed computation of trust and reputation, monitoring and other tasks, where the computing nodes is expected to preserve the privacy of their inputs while performing a joint computation of a certain function.
0	    Although there is a rich literature in the field of distributed systems security concerning secure multi-party computation, in practice it is hard to deploy those methods in very large scale Peer-to-Peer networks.
2	    In this work, we try to bridge the gap between theoretical algorithms in the security domain, and a practical Peer-to-Peer deployment.
1	    We consider two security models.
1	    The first is the semi-honest model where peers correctly follow the protocol, but try to reveal private information.
2	    We provide three possible schemes for secure multi-party numerical computation for this model and identify a single light-weight scheme which outperforms the others.
2	    Using extensive simulation results over real Internet topologies, we demonstrate that our scheme is scalable to very large networks, with up to millions of nodes.
1	    The second model we consider is the malicious peers model, where peers can behave arbitrarily, deliberately trying to affect the results of the computation as well as compromising the privacy of other peers.
1	    For this model we provide a fourth scheme to defend the execution of the computation against the malicious peers.
2	    The proposed scheme has a higher complexity relative to the semi-honest model.
2	    Overall, we provide the Peer-to-Peer network designer a set of tools to choose from, based on the desired level of security.


# 218
### http://arxiv.org/abs/0907.0678v1
## Design and Analysis of an Attack Resilient and Adaptive Medium access Control Protocol for Computer Networks


0	    The challenge of designing an efficient Medium Access Control (MAC) protocol and analyzing it has been an important research topic for over 30 years.
0	    This paper focuses on the performance analysis (through simulation) and modification of a well known MAC protocol CSMA/CD.
0	    The existing protocol does not consider the wastage of bandwidth due to unutilized periods of the channel.
0	    By considering this fact, performance of MAC protocol can be enhanced.
0	    The purpose of this work is to modify the existing protocol by enabling it to adapt according to state of the network.
2	    The modified protocol takes appropriate action whenever unutilized periods detected.
1	    In this way, to increase the effective bandwidth utilization and determine how it behaves under increasing load, and varying packet sizes.
1	    It will also include effects of attacks i.e. Denial of service attacks, Replay Attack, Continuous Channel Access or Exhaustion attack, Flooding attack, Jamming (Radio interference) attack, Selective forwarding attack which degrade performance of MAC protocol.
1	    In Continuous Channel Access or Exhaustion attack, a malicious node disrupts the MAC protocol, by continuously requesting or transmitting over the channel.
0	    This eventually leads a starvation for other nodes in the network w.r.t channel access.
0	    remedy may be the network ignores excessive requests without sending expensive radio transmissions.
0	    This limit however cannot drop below the expected maximum data rate the network has to support.
0	    This limit is usually coded into the protocol during the design phase and requires additional logic also.
1	    Repeated application of these exhaustion or collision based MAC layer attacks can lead into unfairness.


# 219
### http://arxiv.org/abs/0908.0981v2
## A New Scheme for Minimizing Malicious Behavior of Mobile Nodes in Mobile Ad Hoc Networks


0	    The performance of Mobile Ad hoc networks (MANET) depends on the cooperation of all active nodes.
1	    However, supporting a MANET is a cost-intensive activity for a mobile node.
1	    From a single mobile node perspective, the detection of routes as well as forwarding packets consume local CPU time, memory, network-bandwidth, and last but not least energy.
1	    We believe that this is one of the main factors that strongly motivate a mobile node to deny packet forwarding for others, while at the same time use their services to deliver its own data.
0	    This behavior of an independent mobile node is commonly known as misbehaving or selfishness.
0	    A vast amount of research has already been done for minimizing malicious behavior of mobile nodes.
0	    However, most of them focused on the methods/techniques/algorithms to remove such nodes from the MANET.
2	    We believe that the frequent elimination of such miss-behaving nodes never allowed a free and faster growth of MANET.
2	    This paper provides a critical analysis of the recent research wok and its impact on the overall performance of a MANET.
1	    In this paper, we clarify some of the misconceptions in the understating of selfishness and miss-behavior of nodes.
1	    Moreover, we propose a mathematical model that based on the time division technique to minimize the malicious behavior of mobile nodes by avoiding unnecessary elimination of bad nodes.
2	    Our proposed approach not only improves the resource sharing but also creates a consistent trust and cooperation (CTC) environment among the mobile nodes.
2	    The simulation results demonstrate the success of the proposed approach that significantly minimizes the malicious nodes and consequently maximizes the overall throughput of MANET than other well known schemes.


# 220
### http://arxiv.org/abs/0909.1402v1
## Impact of Rushing attack on Multicast in Mobile Ad Hoc Network


1	    A mobile ad hoc network (MANETs) is a self-organizing system of mobile nodes that communicate with each other via wireless links with no fixed infrastructure or centralized administration such as base station or access points.
1	    Nodes in a MANETs operate both as host as well as routers to forward packets for each other in a multihop fashion.
0	    For many applications in wireless networks, multicasting is an important and frequent communication service.
0	    By multicasting, since a single message can be delivered to multiple receivers simultaneously.
0	    It greatly reduces the transmission cost when sending the same packet to multiple recipients.
0	    The security issue of MANETs in group communications is even more challenging because of involvement of multiple senders and multiple receivers.
0	    At that time of multicasting, mobile ad hoc network are unprotected by the attacks of malicious nodes because of vulnerabilities of routing protocols.
0	    Some of the attacks are Rushing attack, Blackhole attack, Sybil attack, Neighbor attack and Jellyfish attack.
1	    This paper is based on Rushing attack.
2	    In Rushing attack, the attacker exploits the duplicate suppression mechanism by quickly forwarding route discovery packets in order to gain access to the forwarding group and this will affect the Average Attack Success Rate.
1	    In this paper, the goal is to measure the impact of Rushing attack and their node positions which affect the performance metrics of Average Attack Success Rate with respect to three scenarios: near sender, near receiver and anywhere within the network.
1	    The performance of the Attack Success Rate with respect to above three scenarios is also compared.


# 221
### http://arxiv.org/abs/0909.3122v1
## A note on the data-driven capacity of P2P networks


0	    We consider two capacity problems in P2P networks.
1	    In the first one, the nodes have an infinite amount of data to send and the goal is to optimally allocate their uplink bandwidths such that the demands of every peer in terms of receiving data rate are met.
1	    We solve this problem through a mapping from a node-weighted graph featuring two labels per node to a max flow problem on an edge-weighted bipartite graph.
1	    In the second problem under consideration, the resource allocation is driven by the availability of the data resource that the peers are interested in sharing.
1	    That is a node cannot allocate its uplink resources unless it has data to transmit first.
1	    The problem of uplink bandwidth allocation is then equivalent to constructing a set of directed trees in the overlay such that the number of nodes receiving the data is maximized while the uplink capacities of the peers are not exceeded.
1	    We show that the problem is NP-complete, and provide a linear programming decomposition decoupling it into a master problem and multiple slave subproblems that can be resolved in polynomial time.
1	    We also design a heuristic algorithm in order to compute a suboptimal solution in a reasonable time.
2	    This algorithm requires only a local knowledge from nodes, so it should support distributed implementations.
1	    We analyze both problems through a series of simulation experiments featuring different network sizes and network densities.
1	    On large networks, we compare our heuristic and its variants with a genetic algorithm and show that our heuristic computes the better resource allocation.
2	    On smaller networks, we contrast these performances to that of the exact algorithm and show that resource allocation fulfilling a large part of the peer can be found, even for hard configuration where no resources are in excess.


# 222
### http://arxiv.org/abs/0911.4395v1
## Introduction to Distributed Systems


0	    Computing has passed through many transformations since the birth of the first computing machines.
0	    Developments in technology have resulted in the availability of fast and inexpensive processors, and progresses in communication technology have resulted in the availability of lucrative and highly proficient computer networks.
2	    Among these, the centralized networks have one component that is shared by users all the time.
0	    All resources are accessible, but there is a single point of control as well as a single point of failure.
1	    The integration of computer and networking technologies gave birth to new paradigm of computing called distributed computing in the late 1970s.
0	    Distributed computing has changed the face of computing and offered quick and precise solutions for a variety of complex problems for different fields.
1	    Nowadays, we are fully engrossed by the information age, and expending more time communicating and gathering information through the Internet.
2	    The Internet keeps on progressing along more than a few magnitudes, abiding end systems increasingly to communicate in more and more different ways.
0	    Over the years, several methods have evolved to enable these developments, ranging from simplistic data sharing to advanced systems supporting a multitude of services.
1	    This article provides an overview of distributed computing systems.
1	    The definition, architecture, characteristics of distributed systems and the various distributed computing fallacies are discussed in the beginning.
2	    Finally, discusses client/server computing, World Wide Web and types of distributed systems.


# 223
### http://arxiv.org/abs/1003.4074v1
## Cloud Computing


0	    Computing as you know it is about to change, your applications and documents are going to move from the desktop into the cloud.
1	    I'm talking about cloud computing, where applications and files are hosted on a "cloud" consisting of thousands of computers and servers, all linked together and accessible via the Internet.
1	    With cloud computing, everything you do is now web based instead of being desktop based.
1	    You can access all your programs and documents from any computer that's connected to the Internet.
1	    How will cloud computing change the way you work?
1	    For one thing, you're no longer tied to a single computer.
2	    You can take your work anywhere because it's always accessible via the web.
2	    In addition, cloud computing facilitates group collaboration, as all group members can access the same programs and documents from wherever they happen to be located.
0	    Cloud computing might sound far-fetched, but chances are you're already using some cloud applications.
0	    If you're using a web-based email program, such as Gmail or Hotmail, you're computing in the cloud.
1	    If you're using a web-based application such as Google Calendar or Apple Mobile Me, you're computing in the cloud.
1	    If you're using a file- or photo-sharing site, such as Flickr or Picasa Web Albums, you're computing in the cloud.
2	    It's the technology of the future, available to use today.


# 224
### http://arxiv.org/abs/1008.3614v1
## Control and Optimization Meet the Smart Power Grid - Scheduling of Power Demands for Optimal Energy Management


0	    The smart power grid aims at harnessing information and communication technologies to enhance reliability and enforce sensible use of energy.
0	    Its realization is geared by the fundamental goal of effective management of demand load.
1	    In this work, we envision a scenario with real-time communication between the operator and consumers.
1	    The grid operator controller receives requests for power demands from consumers, with different power requirement, duration, and a deadline by which it is to be completed.
0	    The objective is to devise a power demand task scheduling policy that minimizes the grid operational cost over a time horizon.
1	    The operational cost is a convex function of instantaneous power consumption and reflects the fact that each additional unit of power needed to serve demands is more expensive as demand load increases.
1	    First, we study the off-line demand scheduling problem, where parameters are fixed and known.
1	    Next, we devise a stochastic model for the case when demands are generated continually and scheduling decisions are taken online and focus on long-term average cost.
1	    We present two instances of power consumption control based on observing current consumption.
1	    First, the controller may choose to serve a new demand request upon arrival or to postpone it to the end of its deadline.
2	    Second, the additional option exists to activate one of the postponed demands when an active demand terminates.
1	    For both instances, the optimal policies are threshold based.
1	    We derive a lower performance bound over all policies, which is asymptotically tight as deadlines increase.
1	    We propose the Controlled Release threshold policy and prove it is asymptotically optimal.
0	    The policy activates a new demand request if the current power consumption is less than a threshold, otherwise it is queued.
0	    Queued demands are scheduled when their deadline expires or when the consumption drops below the threshold.


# 225
### http://arxiv.org/abs/1008.3681v1
## EVM as generic QoS trigger for heterogeneous wieless overlay network


0	    Fourth Generation (4G) Wireless System will integrate heterogeneous wireless overlay systems i.e. interworking of WLAN/ GSM/ CDMA/ WiMAX/ LTE/ etc with guaranteed Quality of Service (QoS) and Experience (QoE).QoS(E) vary from network to network and is application sensitive.
0	    User needs an optimal mobility solution while roaming in Overlaid wireless environment i.e. user could seamlessly transfer his session/ call to a best available network bearing guaranteed Quality of Experience.
1	    And If this Seamless transfer of session is executed between two networks having different access standards then it is called Vertical Handover (VHO).
1	    Contemporary VHO decision algorithms are based on generic QoS metrics viz.
1	    SNR, bandwidth, jitter, BER and delay.
1	    In this paper, Error Vector Magnitude (EVM) is proposed to be a generic QoS trigger for VHO execution.
1	    EVM is defined as the deviation of inphase/ quadrature (I/Q) values from ideal signal states and thus provides a measure of signal quality.
1	    In 4G Interoperable environment, OFDM is the leading Modulation scheme (more prone to multi-path fading).
0	    EVM (modulation error) properly characterises the wireless link/ channel for accurate VHO decision.
0	    EVM depends on the inherent transmission impairments viz.
1	    frequency offset, phase noise, non-linear-impairment, skewness etc.
1	    for a given wireless link.
1	    Paper provides an insight to the analytical aspect of EVM & measures EVM (%) for key management subframes like association/re-association/disassociation/ probe request/response frames.
1	    EVM relation is explored for different possible NAV-Network Allocation Vectors (frame duration).
2	    Finally EVM is compared with SNR, BER and investigation concludes EVM as a promising QoS trigger for OFDM based emerging wireless standards.


# 226
### http://arxiv.org/abs/1008.4900v1
## Managing Clouds in Cloud Platforms


0	    Managing cloud services is a fundamental challenge in todays virtualized environments.
0	    These challenges equally face both providers and consumers of cloud services.
2	    The issue becomes even more challenging in virtualized environments that support mobile clouds.
0	    Cloud computing platforms such as Amazon EC2 provide customers with flexible, on demand resources at low cost.
0	    However, they fail to provide seamless infrastructure management and monitoring capabilities that many customers may need.
1	    For instance, Amazon EC2 doesn't fully support cloud services automated discovery and it requires a private set of authentication credentials.
2	    Salesforce.com, on the other hand, do not provide monitoring access to their underlying systems.
2	    Moreover, these systems fail to provide infrastructure monitoring of heterogenous and legacy systems that don't support agents.
1	    In this work, we explore how to build a cloud management system that combines heterogeneous management of virtual resources with comprehensive management of physical devices.
1	    We propose an initial prototype for automated cloud management and monitoring framework.
1	    Our ultimate goal is to develop a framework that have the capability of automatically tracking configuration and relationships while providing full event management, measuring performance and testing thresholds, and measuring availability consistently.
2	    Armed with such a framework, operators can make better decisions quickly and more efficiently.


# 227
### http://arxiv.org/abs/1010.1583v1
## Multi Layer Approach to Defend DDoS Attacks Caused by Spam


0	    Corporate mail services are designed to perform better than public mail services.
0	    Fast mail delivery, large size file transfer as an attachments, high level spam and virus protection, commercial advertisement free environment are some of the advantages worth to mention.
0	    But these mail services are frequent target of hackers and spammers.
0	    Distributed Denial of service attacks are becoming more common and sophisticated.
0	    The researchers have proposed various solutions to the DDOS attacks.
0	    Can we stop these kinds of attacks with available technology?
2	    These days the DDoS attack through spam has increased and disturbed the mail services of various organizations.
1	    Spam penetrates through all the filters to establish DDoS attacks, which causes serious problems to users and the data.
1	    In this paper we propose a multilayer approach to defend DDoS attack caused by spam mails.
1	    This approach is a combination of fine tuning of source filters, content filters, strictly implementing mail policies, educating user, network monitoring and logical solutions to the ongoing attack.
2	    We have conducted several experiments in corporate mail services; the results show that this approach is highly effective to prevent DDoS attack caused by spam.
2	    The defense mechanism reduced 60% of the incoming spam traffic and repelled many DDoS attacks caused by spam


# 228
### http://arxiv.org/abs/1012.0610v1
## Novel Mechanism to Defend DDoS Attacks Caused by Spam


0	    Corporate mail services are designed to perform better than public mail services.
0	    Fast mail delivery, large size file transfer as an attachments, high level spam and virus protection, commercial advertisement free environment are some of the advantages worth to mention.
0	    But these mail services are frequent target of hackers and spammers.
0	    Distributed Denial of service attacks are becoming more common and sophisticated.
0	    The researchers have proposed various solutions to the DDOS attacks.
0	    Can we stop these kinds of attacks with available technology?
2	    These days the DDoS attack through spam has increased and disturbed the mail services of various organizations.
1	    Spam penetrates through all the filters to establish DDoS attacks, which causes serious problems to users and the data.
1	    In this paper we propose a novel approach to defend DDoS attack caused by spam mails.
1	    This approach is a combination of fine tuning of source filters, content filters, strictly implementing mail policies,educating user, network monitoring and logical solutions to the ongoing attack.
2	    We have conducted several experiments in corporate mail services; the results show that this approach is highly effective to prevent DDoS attack caused by spam.
2	    The novel defense mechanism reduced 60% of the incoming spam traffic and repelled many DDoS attacks caused by spam.


# 229
### http://arxiv.org/abs/1012.1665v1
## An In-depth Analysis of Spam and Spammers


0	    Electronic mail services have become an important source of communication for millions of people all over the world.
0	    Due to this tremendous growth, there has been a significant increase in spam traffic.
0	    Spam messes up user's inbox, consumes network resources and spread worms and viruses.
1	    In this paper we study the characteristics of spam and the technology used by spammers.
0	    In order to counter anti spam technology, spammers change their mode of operation, therefore continues evaluation of the characteristics of spam and spammers technology has become mandatory.
1	    These evaluations help us to enhance the existing anti spam technology and thereby help us to combat spam effectively.
1	    In order to characterize spam, we collected four hundred thousand spam mails from a corporate mail server for a period of 14 months from January 2006 to February 2007.
1	    For analysis we classified spam based on attachment and contents.
1	    We observed that spammers use software tools to send spam with attachment.
1	    The main features of this software are hiding sender's identity, randomly selecting text messages, identifying open relay machines, mass mailing capability and defining spamming duration.
2	    Spammers do not use spam software to send spam without attachment.
1	    From our study we observed that, four years old heavy users email accounts attract more spam than four years old light users mail accounts.
1	    Relatively new email accounts which are 14 months old do not receive spam.
1	    But in some special cases like DDoS attacks, we found that new email accounts receive spam and 14 months old heavy users email accounts have attracted more spam than 14 months old light users.
2	    We believe that this analysis could be useful to develop more efficient anti spam techniques.


# 230
### http://arxiv.org/abs/1012.3071v1
## Seamless Flow Migration on Smartphones without Network Support


0	    This paper addresses the following question: Is it possible to migrate TCP/IP flows between different networks on modern mobile devices, without infrastructure support or protocol changes?
0	    To answer this question, we make three research contributions. (
1	    i) We report a comprehensive characterization of IP traffic on smartphones using traces collected from 27 iPhone 3GS users for three months. (
1	    ii) Driven by the findings from the characterization, we devise two novel system mechanisms for mobile devices to sup-port seamless flow migration without network support, and extensively evaluate their effectiveness using our field collected traces of real-life usage.
2	    Wait-n-Migrate leverages the fact that most flows are short lived.
2	    It establishes new flows on newly available networks but allows pre-existing flows on the old network to terminate naturally, effectively decreasing, or even eliminating, connectivity gaps during network switches.
1	    Resumption Agent takes advantage of the functionality integrated into many modern protocols to securely resume flows without application intervention.
1	    When combined, Wait-n-Migrate and Resumption Agent provide an unprecedented opportunity to immediately deploy performance and efficiency-enhancing policies that leverage multiple networks to improve the performance, efficiency, and connectivity of mobile devices. (
2	    iii) Finally, we report an iPhone 3GS based implementation of these two system mechanisms and show that their overhead is negligible.
1	    Furthermore, we employ an example network switching policy, called AutoSwitch, to demonstrate their performance.
0	    AutoSwitch improves the Wi-Fi user experience by intelligently migrating TCP flows between Wi-Fi and cellular networks.
2	    Through traces and field measurements, we show that AutoSwitch reduces the number of user disruptions by an order of magnitude.


# 231
### http://arxiv.org/abs/1101.3067v1
## Wiselib: A Generic Algorithm Library for Heterogeneous Sensor Networks


0	    One unfortunate consequence of the success story of wireless sensor networks (WSNs) in separate research communities is an ever-growing gap between theory and practice.
0	    Even though there is a increasing number of algorithmic methods for WSNs, the vast majority has never been tried in practice; conversely, many practical challenges are still awaiting efficient algorithmic solutions.
1	    The main cause for this discrepancy is the fact that programming sensor nodes still happens at a very technical level.
1	    We remedy the situation by introducing Wiselib, our algorithm library that allows for simple implementations of algorithms onto a large variety of hardware and software.
1	    This is achieved by employing advanced C++ techniques such as templates and inline functions, allowing to write generic code that is resolved and bound at compile time, resulting in virtually no memory or computation overhead at run time.
2	    The Wiselib runs on different host operating systems, such as Contiki, iSense OS, and ScatterWeb.
1	    Furthermore, it runs on virtual nodes simulated by Shawn.
1	    For any algorithm, the Wiselib provides data structures that suit the specific properties of the target platform.
1	    Algorithm code does not contain any platform-specific specializations, allowing a single implementation to run natively on heterogeneous networks.
1	    In this paper, we describe the building blocks of the Wiselib, and analyze the overhead.
1	    We demonstrate the effectiveness of our approach by showing how routing algorithms can be implemented.
2	    We also report on results from experiments with real sensor-node hardware.


# 232
### http://arxiv.org/abs/1101.5617v1
## Optimal Pricing in Networks with Externalities


1	    We study the optimal pricing strategies of a monopolist selling a divisible good (service) to consumers that are embedded in a social network.
1	    A key feature of our model is that consumers experience a (positive) local network effect.
0	    In particular, each consumer's usage level depends directly on the usage of her neighbors in the social network structure.
0	    Thus, the monopolist's optimal pricing strategy may involve offering discounts to certain agents, who have a central position in the underlying network.
1	    First, we consider a setting where the monopolist can offer individualized prices and derive an explicit characterization of the optimal price for each consumer as a function of her network position.
1	    In particular, we show that it is optimal for the monopolist to charge each agent a price that is proportional to her Bonacich centrality in the social network.
1	    In the second part of the paper, we discuss the optimal strategy of a monopolist that can only choose a single uniform price for the good and derive an algorithm polynomial in the number of agents to compute such a price.
1	    Thirdly, we assume that the monopolist can offer the good in two prices, full and discounted, and study the problem of determining which set of consumers should be given the discount.
2	    We show that the problem is NP-hard, however we provide an explicit characterization of the set of agents that should be offered the discounted price.
1	    Next, we describe an approximation algorithm for finding the optimal set of agents.
2	    We show that if the profit is nonnegative under any feasible price allocation, the algorithm guarantees at least 88% of the optimal profit.
2	    Finally, we highlight the value of network information by comparing the profits of a monopolist that does not take into account the network effects when choosing her pricing policy to those of a monopolist that uses this information optimally.


# 233
### http://arxiv.org/abs/1102.1226v1
## Secure Routing in Wireless Mesh Networks


0	    Wireless mesh networks (WMNs) have emerged as a promising concept to meet the challenges in next-generation networks such as providing flexible, adaptive, and reconfigurable architecture while offering cost-effective solutions to the service providers.
1	    Unlike traditional Wi-Fi networks, with each access point (AP) connected to the wired network, in WMNs only a subset of the APs are required to be connected to the wired network.
1	    The APs that are connected to the wired network are called the Internet gateways (IGWs), while the APs that do not have wired connections are called the mesh routers (MRs).
0	    The MRs are connected to the IGWs using multi-hop communication.
0	    The IGWs provide access to conventional clients and interconnect ad hoc, sensor, cellular, and other networks to the Internet.
0	    However, most of the existing routing protocols for WMNs are extensions of protocols originally designed for mobile ad hoc networks (MANETs) and thus they perform sub-optimally.
0	    Moreover, most routing protocols for WMNs are designed without security issues in mind, where the nodes are all assumed to be honest.
0	    In practical deployment scenarios, this assumption does not hold.
0	    This chapter provides a comprehensive overview of security issues in WMNs and then particularly focuses on secure routing in these networks.
1	    First, it identifies security vulnerabilities in the medium access control (MAC) and the network layers.
1	    Various possibilities of compromising data confidentiality, data integrity, replay attacks and offline cryptanalysis are also discussed.
1	    Then various types of attacks in the MAC and the network layers are discussed.
0	    After enumerating the various types of attacks on the MAC and the network layer, the chapter briefly discusses on some of the preventive mechanisms for these attacks.


# 234
### http://arxiv.org/abs/1104.5150v1
## File Transfer Application For Sharing Femto Access


0	    In wireless access network optimization, today's main challenges reside in traffic offload and in the improvement of both capacity and coverage networks.
0	    The operators are interested in solving their localized coverage and capacity problems in areas where the macro network signal is not able to serve the demand for mobile data.
0	    Thus, the major issue for operators is to find the best solution at reasonable expanses.
0	    The femto cell seems to be the answer to this problematic.
1	    In this work (This work is supported by the COMET project AWARE.
1	    http://www.ftw.at/news/project-start-for-aware-ftw), we focus on the problem of sharing femto access between a same mobile operator's customers.
0	    This problem can be modeled as a game where service requesters customers (SRCs) and service providers customers (SPCs) are the players.
0	    This work addresses the sharing femto access problem considering only one SPC using game theory tools.
1	    We consider that SRCs are static and have some similar and regular connection behavior.
1	    We also note that the SPC and each SRC have a software embedded respectively on its femto access, user equipment (UE).
1	    After each connection requested by a SRC, its software will learn the strategy increasing its gain knowing that no information about the other SRCs strategies is given.
1	    The following article presents a distributed learning algorithm with incomplete information running in SRCs software.
1	    We will then answer the following questions for a game with $N$ SRCs and one SPC: how many connections are necessary for each SRC in order to learn the strategy maximizing its gain?
1	    Does this algorithm converge to a stable state?
2	    If yes, does this state a Nash Equilibrium and is there any way to optimize the learning process duration time triggered by SRCs software?


# 235
### http://arxiv.org/abs/1106.2677v1
## A Framework for Enabling Distributed Applications on the Internet


0	    The last five years have seen the rapid rise in popularity of what we term internet distributed applications (IDAs).
0	    These are internet applications with which many users interact simultaneously.
0	    IDAs range from P2P file-sharing applications, to collaborative distributed computing projects, to massively multiplayer online games (MMOGs).
1	    Currently, there is no framework that combines IDAs collectively within a single context.
1	    We provide a basis for such a framework here.
1	    In considering IDAs collectively, we found that there was no generic description that had been applied to them as a group.
1	    We have therefore put forward such a description here.
1	    In our description, IDAs are functionality separated into three logic layers, which are designed and built individually.
1	    Each layer is represented by functionality on the software client running on each participating computer, which together comprise the overall IDA.
1	    The core contribution of this work is a framework, called the Internet Distributed Application Framework (IDAF), which outlines how IDAs can be designed, built and run.
1	    The IDAF outlines a set of constraints that each implementing software system must abide by.
1	    To verify the IDAF, we have built a system prototype implementation called the Internet Distributed Application System (IDAS).
1	    The IDAS includes an implementation of the IDAF layer model, which specifies IDAs are built.
1	    The IDAS also includes a generic software client that is capable of simultaneously running and managing arbitrary IDAs.
1	    We provide sample IDAs and demonstrations to verify both that the IDAF is implementable and that the IDAS is a workable usable system.


# 236
### http://arxiv.org/abs/1108.2080v1
## Going Beyond Pollution Attacks: Forcing Byzantine Clients to Code Correctly


0	    Network coding achieves optimal throughput in multicast networks.
0	    However, throughput optimality \emph{relies} on the network nodes or routers to code \emph{correctly}. A Byzantine node may introduce junk packets in the network (thus polluting downstream packets and causing the sinks to receive the wrong data) or may choose coding coefficients in a way that significantly reduces the throughput of the network.
0	    Most prior work focused on the problem of Byzantine nodes polluting packets.
0	    However, even if a Byzantine node does not pollute packets, he can still affect significantly the throughput of the network by not coding correctly.
1	    No previous work attempted to verify if a certain node \emph{coded correctly using random coefficients} over \emph{all} of the packets he was supposed to code over.
1	    We provide two novel protocols (which we call PIP and Log-PIP) for detecting whether a node coded correctly over all the packets received (i.e., according to a random linear network coding algorithm).
1	    Our protocols enable any node in the network to examine a packet received from another node by running a "verification test".
1	    With our protocols, the worst an adversary can do and still pass the packet verification test is in fact equivalent to random linear network coding, which has been shown to be optimal in multicast networks.
2	    Our protocols resist collusion among nodes and are applicable to a variety of settings.
2	    Our topology simulations show that the throughput in the worst case for our protocol is two to three times larger than the throughput in various adversarial strategies allowed by prior work.
1	    We implemented our protocols in C/C++ and Java, as well as incorporated them on the Android platform (Nexus One).
2	    Our evaluation shows that our protocols impose modest overhead.


# 237
### http://arxiv.org/abs/1111.5189v1
## A Frame Rate Optimization Framework For Improving Continuity In Video Streaming


0	    This paper aims to reduce the prebuffering requirements, while maintaining continuity, for video streaming.
0	    Current approaches do this by making use of adaptive media playout (AMP) to reduce the playout rate.
0	    However, this introduces playout distortion to the viewers and increases the viewing latency.
1	    We approach this by proposing a frame rate optimization framework that adjusts both the encoder frame generation rate and the decoder playout frame rate.
1	    Firstly, we model this problem as the joint adjustment of the encoder frame generation interval and the decoder playout frame interval.
1	    This model is used with a discontinuity penalty virtual buffer to track the accumulated difference between the receiving frame interval and the playout frame interval.
1	    We then apply Lyapunov optimization to the model to systematically derive a pair of decoupled optimization policies.
2	    We show that the occupancy of the discontinuity penalty virtual buffer is correlated to the video discontinuity and that this framework produces a very low playout distortion in addition to a significant reduction in the prebuffering requirements compared to existing approaches.
1	    Secondly, we introduced a delay constraint into the framework by using a delay accumulator virtual buffer.
2	    Simulation results show that the the delay constrained framework provides a superior tradeoff between the video quality and the delay introduced compared to the existing approach.
1	    Finally, we analyzed the impact of delayed feedback between the receiver and the sender on the optimization policies.
2	    We show that the delayed feedbacks have a minimal impact on the optimization policies.


# 238
### http://arxiv.org/abs/1203.3323v1
## IDPS: An Integrated Intrusion Handling Model for Cloud


0	    Today, many organizations are moving their computing services towards the Cloud.
2	    This makes their computer processing available much more conveniently to users.
2	    However, it also brings new security threats and challenges about safety and reliability.
0	    In fact, Cloud Computing is an attractive and cost-saving service for buyers as it provides accessibility and reliability options for users and scalable sales for providers.
0	    In spite of being attractive, Cloud feature poses various new security threats and challenges when it comes to deploying Intrusion Detection System (IDS) in Cloud environments.
0	    Most Intrusion Detection Systems (IDSs) are designed to handle specific types of attacks.
2	    It is evident that no single technique can guarantee protection against future attacks.
2	    Hence, there is a need for an integrated scheme which can provide robust protection against a complete spectrum of threats.
2	    On the other hand, there is great need for technology that enables the network and its hosts to defend themselves with some level of intelligence in order to accurately identify and block malicious traffic and activities.
1	    In this case, it is called Intrusion prevention system (IPS).
2	    Therefore, in this paper, we emphasize on recent implementations of IDS on Cloud Computing environments in terms of security and privacy.
1	    We propose an effective and efficient model termed as the Integrated Intrusion Detection and Prevention System (IDPS) which combines both IDS and IPS in a single mechanism.
1	    Our mechanism also integrates two techniques namely, Anomaly Detection (AD) and Signature Detection (SD) that can work in cooperation to detect various numbers of attacks and stop them through the capability of IPS.


# 239
### http://arxiv.org/abs/1207.2867v1
## Distributed and Big Data Storage Management in Grid Computing


0	    Big data storage management is one of the most challenging issues for Grid computing environments, since large amount of data intensive applications frequently involve a high degree of data access locality.
0	    Grid applications typically deal with large amounts of data.
1	    In traditional approaches high-performance computing consists dedicated servers that are used to data storage and data replication.
1	    In this paper we present a new mechanism for distributed and big data storage and resource discovery services.
1	    Here we proposed an architecture named Dynamic and Scalable Storage Management (DSSM) architecture in grid environments.
2	    This allows in grid computing not only sharing the computational cycles, but also share the storage space.
2	    The storage can be transparently accessed from any grid machine, allowing easy data sharing among grid users and applications.
1	    The concept of virtual ids that, allows the creation of virtual spaces has been introduced and used.
1	    The DSSM divides all Grid Oriented Storage devices (nodes) into multiple geographically distributed domains and to facilitate the locality and simplify the intra-domain storage management.
1	    Grid service based storage resources are adopted to stack simple modular service piece by piece as demand grows.
1	    To this end, we propose four axes that define: DSSM architecture and algorithms description, Storage resources and resource discovery into Grid service, Evaluate purpose prototype system, dynamically, scalability, and bandwidth, and Discuss results.
1	    Algorithms at bottom and upper level for standardization dynamic and scalable storage management, along with higher bandwidths have been designed.


# 240
### http://arxiv.org/abs/1208.1982v1
## Determination Of Optimal Number Of Clusters In Wireless Sensor Networks


0	    Prolonged network lifetime, scalability and efficient load balancing are essential for optimal performance of a wireless sensor network.
2	    Clustering provides an effective way of extending the lifetime of a sensor network.
1	    Clustering is the process that divides sensor networks into smaller localized group (called clusters) of members with a cluster head.
1	    Clustering protocols need to elect optimal number of clusters in hierarchically structured wireless sensor networks.
1	    Any clustering scheme that elects clusters uniformly (irrespective of the distance from Base Station) incurs excessive energy usage on clusters proximal and distant to Base Station.
2	    In single hop networks a gradual increment in the energy depletion rate is observed as the distance from the cluster head increases.
2	    This work focuses on the analysis of wasteful energy consumption within a uniform cluster head election model (EPEM) and provides an analytic solution to reduce the overall consumption of energy usage amongst the clusters elected in a wireless sensor network.
1	    A circular model of sensor network is considered, where the sensor nodes are deployed around a centrally located Base Station.
1	    The sensor network is divided into several concentric rings centred at the Base Station.
1	    A model, Unequal Probability Election Model (UEPEM), which elects cluster heads non-uniformly is proposed.
1	    The probability of cluster head election depends on the distance from the Base Station.
2	    UEPEM reduces the overall energy usage by about 21% over EPEM.
2	    The performance of UEPEM improves as the number of rings is increased.


# 241
### http://arxiv.org/abs/1211.2946v2
## ATDSR: Trusted On-Demand Routing Protocol based on Agents for Mobile Ad-hoc Networks


0	    The routing performance in Mobile Ad-hoc Networks (MANETs) relies on the co-operation of the individual nodes that constitute the network.
0	    The existence of misbehaving nodes may paralyze the routing operation in MANETs.
1	    To overcome this behavior, the trustworthiness of the network nodes should be considered in the route selection process combined with the hop count.
1	    The trustworthiness is achieved by measuring the trust value for each node in the network.
1	    In this paper, a new protocol based on self monitoring (agent-based) and following the dynamic source routing (DSR) algorithm is presented.
1	    This protocol is called Agent-Based Trusted Dynamic Source Routing (ATDSR) Protocol for MANETs.
1	    The objective of this protocol is to manage trust information locally with minimal overhead in terms of extra messages and time delay.
1	    This objective is achieved through installing in each participated node in the network a multi-agent system (MAS).
1	    MAS consists of two types of agents: monitoring agent (MOA) and routing agent (ROA).
1	    A new mathematical and more realistic objective model for measuring the trust value is introduced.
1	    This model is weighted by both number and size of routed packets to reflect the selective forwarding behavior of a node.
2	    The performance evaluation via simulation shows that our protocol is better than standard and trusted DSR.
2	    The simulation is done over a variety of environmental conditions such as number of malicious nodes, host density and movement rates.


# 242
### http://arxiv.org/abs/1211.5857v1
## Hierarchic Power Allocation for Spectrum Sharing in OFDM-Based Cognitive Radio Networks


1	    In this paper, a Stackelberg game is built to model the hierarchic power allocation of primary user (PU) network and secondary user (SU) network in OFDM-based cognitive radio (CR) networks.
1	    We formulate the PU and the SUs as the leader and the followers, respectively.
1	    We consider two constraints: the total power constraint and the interference-to-signal ratio (ISR) constraint, in which the ratio between the accumulated interference and the received signal power at each PU should not exceed certain threshold.
1	    Firstly, we focus on the single-PU and multi-SU scenario.
1	    Based on the analysis of the Stackelberg Equilibrium (SE) for the proposed Stackelberg game, an analytical hierarchic power allocation method is proposed when the PU can acquire the additional information to anticipate SUs' reaction.
1	    The analytical algorithm has two steps: 1) The PU optimizes its power allocation with considering the reaction of SUs to its action.
1	    In the power optimization of the PU, there is a sub-game for power allocation of SUs given fixed transmit power of the PU.
1	    The existence and uniqueness for the Nash Equilibrium (NE) of the sub-game are investigated.
1	    We also propose an iterative algorithm to obtain the NE, and derive the closed-form solutions of NE for the perfectly symmetric channel.
1	    2) The SUs allocate the power according to the NE of the sub-game given PU's optimal power allocation.
1	    Furthermore, we design two distributed iterative algorithms for the general channel even when private information of the SUs is unavailable at the PU.
1	    The first iterative algorithm has a guaranteed convergence performance, and the second iterative algorithm employs asynchronous power update to improve time efficiency.
1	    Finally, we extend to the multi-PU and multi-SU scenario, and a distributed iterative algorithm is presented.


# 243
### http://arxiv.org/abs/1301.4204v1
## DSAT-MAC : Dynamic Slot Allocation based TDMA MAC protocol for Cognitive Radio Networks


0	    Cognitive Radio Networks (CRN) have enabled us to efficiently reuse the underutilized radio spectrum.
0	    The MAC protocol in CRN defines the spectrum usage by sharing the channels efficiently among users.
1	    In this paper we propose a novel TDMA based MAC protocol with dynamically allocated slots.
0	    Most of the MAC protocols proposed in the literature employ Common Control Channel (CCC) to manage the resources among Cognitive Radio (CR) users.
0	    Control channel saturation in case of large number of CR users is one of the main drawbacks of the CCC based MAC protocols.
0	    In contrast with CCC based MAC protocols, DSAT-MAC protocol is based on the TDMA mechanism, without using any CCC for control information exchange.
0	    The channels are divided into time slots and CR users send their control or data packets over their designated slot.
1	    The protocol ensures that no slot is left vacant.
1	    This guarantees full use of the available spectrum.
2	    The protocol includes the provision for Quality of Service, where real-time and safety critical data is transmitted with highest priority and least delay.
2	    The protocol also ensures a fair sharing of available spectrum among the CR users, with the mechanism to regulate the transmission of malicious nodes.
0	    Energy saving techniques are also presented for longer life of battery operated CR nodes.
2	    Theoretical analysis and simulations over ns-2 of the proposed protocol reveal that the protocol performs better in various CR adhoc network applications.


# 244
### http://arxiv.org/abs/1301.4691v1
## Cross-layer Optimization for Next Generation Wi-Fi


0	    From the initial 1997 specification to the undergoing IEEE 802.11ac standardization, a leap in throughput has been observed with every new generation.
2	    The expectations for next generations on issues like throughput, range, reliability, and power consumption are even higher.
2	    This is quite a challenge considering all the work already done.
1	    Cross-layer optimization of physical (PHY) and medium access control (MAC) layers can be an interesting exploration path for further enhancement.
1	    During this thesis we have studied cross-layer optimization techniques, with a focus on the IEEE 802.11ac standard.
1	    A new multichannel aggregation scheme involving cross-knowledge between PHY and MAC layers has been proposed to improve performance in collision-prone environments.
0	    We have shown that some functionalities directly involved PHY and MAC layers.
0	    An accurate modeling of both PHY and MAC mechanisms is thus needed to have a realistic characterization of such functionalities.
1	    A cross-layer simulator, compliant with IEEE 802.11ac specifications, has thus been implemented.
1	    To the best of our knowledge, this is the first simulator incorporating detailed PHY and MAC functionalities for the IEEE 802.11ac standard.
2	    The multiple-user multiple-input, multiple-output (MU-MIMO) technique, which is one of the main innovations of the IEEE 802.11ac, needs both PHY and MAC layer considerations.
2	    We have thus used the implemented cross-layer simulator to evaluate the performance of MU-MIMO and compared it with the single-user MIMO (SU-MIMO).
0	    The aim of these studies was to evaluate the 'real' gains of MU-MIMO solutions (accounting for PHY+MAC) over SU-MIMO solutions and not the generally accepted ones.
0	    The impact of the channel sounding interval has particularly been studied.
2	    Finally, we have proposed a short PHY layer version of acknowledgment frames for overhead reduction in IEEE 802.11ah communications.


# 245
### http://arxiv.org/abs/1309.0195v1
## Online Regenerator Placement


0	    Connections between nodes in optical networks are realized by lightpaths.
0	    Due to the decay of the signal, a regenerator has to be placed on every lightpath after at most $d$ hops, for some given positive integer $d$. A regenerator can serve only one lightpath.
0	    The placement of regenerators has become an active area of research during recent years, and various optimization problems have been studied.
1	    The first such problem is the Regeneration Location Problem ($\prb$), where the goal is to place the regenerators so as to minimize the total number of nodes containing them.
1	    We consider two extreme cases of online $\prb$ regarding the value of $d$ and the number $k$ of regenerators that can be used in any single node. (
1	    1) $d$ is arbitrary and $k$ unbounded.
1	    In this case a feasible solution always exists.
1	    We show an $O(\log \abs{X} \cdot \log d)$-competitive randomized algorithm for any network topology, where $X$ is the set of paths of length $d$. The algorithm can be made deterministic in some cases.
1	    We show a deterministic lower bound of $\Omega \lb$, where $E$ is the edge set. (
1	    2) $d=2$ and $k=1$. In this case there is not necessarily a solution for a given input.
1	    We distinguish between feasible inputs (for which there is a solution) and infeasible ones.
1	    In the latter case, the objective is to satisfy the maximum number of lightpaths.
2	    For a path topology we show a lower bound of $\sqrt{l}/2$ for the competitive ratio (where $l$ is the number of internal nodes of the longest lightpath) on infeasible inputs, and a tight bound of 3 for the competitive ratio on feasible inputs.


# 246
### http://arxiv.org/abs/1310.3990v1
## Distributed Algorithm for Dynamic Data-Gathering in Sensor Network


0	    In WSN, each sensor is responsible for sensing environmental conditions and sending them to the one or more base stations.
0	    Battery-operated sensors are severely constrained by the amount of energy that can be spend for transmitting these sensed data.
0	    However, aggregation of data (including removal of redundant data) at intermediate sensors and forwarding of aggregate data reduce overall energy consumptions in WSN.
0	    In general, data gathering refers to the process of periodic collection of sensed data from various sensors to one or more base stations (BS).
2	    Energy efficient data gathering scheduling is essential for improving the lifetime of WSN.
1	    In this paper, we propose a distributed algorithm to compute data-gathering schedule that aim to improve the lifetime of WSN by suitably selecting energy-efficient data-flow paths from various sensors to the base station.
1	    For a multihop WSN with $n$ sensors, the proposed algorithm first computes a schedule in $O(n^2)$ time steps, and then this schedule is periodically updated based the residual energy and the feedback received from the BS.
1	    The system performs approximately $\log(\mathcal{L})$ schedule updates where $\mathcal{L}$ is the expected lifetime of the system in number of data-gathering rounds.
1	    Moreover, each updation process uses the existing active schedule (data-flow path) - thus consuming only a small fraction of a single data gathering round activity.
0	    Such an algorithm thus could precisely incorporate the energy consumptions due to updates and related activities.
2	    Moreover, our algorithm does not assume any global knowledge of the topology or the positions of various sensors.
2	    Through simulation study, we found that our proposed algorithm achieves significantly higher network lifetime compared to existing data-flow schedules based on the Minimum Spanning Tree (MST), the Shortest Path Tree (SPT), the Weighted Rooted Tree (WRT).


# 247
### http://arxiv.org/abs/1310.4577v1
## A highly optimized flow-correlation attack


0	    Deciding that two network flows are essentially the same is an important problem in intrusion detection and in tracing anonymous connections.
0	    A stepping stone or an anonymity network may try to prevent flow correlation by adding chaff traffic, splitting the flow in several subflows or adding random delays.
0	    A well-known attack for these types of systems is active watermarking.
0	    However, active watermarking systems can be detected and an attacker can modify the flow in such a way that the watermark is removed and can no longer be decoded.
1	    This leads to the two basic features of our scheme: a highlyoptimized algorithm that achieves very good performance and a passive analysis that is undetectable.
1	    We propose a new passive analysis technique where detection is based on Neyman-Pearson lemma.
1	    We correlate the inter-packet delays (IPDs) from both flows.
1	    Then, we derive a modification to deal with stronger adversary models that add chaff traffic, split the flows or add random delays.
1	    We empirically validate the detectors with a simulator.
1	    Afterwards, we create a watermarkbased version of our scheme to study the trade-off between performance and detectability.
1	    Then, we compare the results with other state-of-the-art traffic watermarking schemes in several scenarios concluding that our scheme outperforms the rest.
2	    Finally, we present results using an implementation of our method on live networks, showing that the conclusions can be extended to real-world scenarios.
2	    Our scheme needs only tens of packets under normal network interference and a few hundreds of packets when a number of countermeasures are taken.


# 248
### http://arxiv.org/abs/1311.1018v1
## Resource Management for Device-to-Device Underlay Communication


0	    Device-to-Device (D2D) communication is a technology component for LTE-A. The existing researches allow D2D as an underlay to the cellular network to increase the spectral efficiency.
0	    In this book, D2D communication underlaying cellular networks is studied.
0	    Some physical-layer techniques and cross-layer optimization methods on resource management and interference avoidance are proposed and discussed.
2	    WINNER II channel models is applied to be the signal and interference model and simulation results show that the performance of D2D link is closely related to the distance between D2D transmitter and receiver and that between interference source and the receiver.
0	    Besides, by power control, D2D SINR degrades, which will naturally contribute to low interference to cellular communication.
1	    A simple mode selection method of D2D communication is introduced.
2	    Based on path-loss (PL) mode selection criterion, D2D gives better performance than traditional cellular system.
2	    When D2D pair is farther away from the BS, a better results can be obtained.
0	    Game theory, which offers a wide variety of analytical tools to study the complex interactions of players and predict their choices, can be used for power and radio resource management in D2D communication.
0	    A reverse iterative combinatorial auction is formulated as a mechanism to allocate the spectrum resources for D2D communications with multiple user pairs sharing the same channel.
1	    In addition, a game theoretic approach is developed to implement joint scheduling, power control and channel allocation for D2D communication.
1	    Finally, joint power and spectrum resource allocation method is studied under consideration of battery lifetime, which is an important application of D2D communication on increasing user's energy efficiency.
2	    The simulation results show that all these methods have beneficial effects on improving the system performance.


# 249
### http://arxiv.org/abs/1311.1446v1
## Cluster Based Cost Efficient Intrusion Detection System For Manet


0	    Mobile ad-hoc networks are temporary wireless networks.
0	    Network resources are abnormally consumed by intruders.
1	    Anomaly and signature based techniques are used for intrusion detection.
0	    Classification techniques are used in anomaly based techniques.
0	    Intrusion detection techniques are used for the network attack detection process.
0	    Two types of intrusion detection systems are available.
0	    They are anomaly detection and signature based detection model.
1	    The anomaly detection model uses the historical transactions with attack labels.
1	    The signature database is used in the signature based IDS schemes.
0	    The mobile ad-hoc networks are infrastructure less environment.
1	    The intrusion detection applications are placed in a set of nodes under the mobile ad-hoc network environment.
1	    The nodes are grouped into clusters.
1	    The leader nodes are assigned for the clusters.
1	    The leader node is assigned for the intrusion detection process.
1	    Leader nodes are used to initiate the intrusion detection process.
1	    Resource sharing and lifetime management factors are considered in the leader election process.
1	    The system optimizes the leader election and intrusion detection process.
1	    The system is designed to handle leader election and intrusion detection process.
1	    The clustering scheme is optimized with coverage and traffic level.
1	    Cost and resource utilization is controlled under the clusters.
2	    Node mobility is managed by the system.


# 250
### http://arxiv.org/abs/1312.7645v1
## A Process Algebra for Wireless Mesh Networks used for Modelling, Verifying and Analysing AODV


1	    We propose AWN (Algebra for Wireless Networks), a process algebra tailored to the modelling of Mobile Ad hoc Network (MANET) and Wireless Mesh Network (WMN) protocols.
1	    It combines novel treatments of local broadcast, conditional unicast and data structures.
1	    In this framework we present a rigorous analysis of the Ad hoc On-Demand Distance Vector (AODV) protocol, a popular routing protocol designed for MANETs and WMNs, and one of the four protocols currently standardised by the IETF MANET working group.
1	    We give a complete and unambiguous specification of this protocol, thereby formalising the RFC of AODV, the de facto standard specification, given in English prose.
1	    In doing so, we had to make non-evident assumptions to resolve ambiguities occurring in that specification.
1	    Our formalisation models the exact details of the core functionality of AODV, such as route maintenance and error handling, and only omits timing aspects.
2	    The process algebra allows us to formalise and (dis)prove crucial properties of mesh network routing protocols such as loop freedom and packet delivery.
2	    We are the first to provide a detailed proof of loop freedom of AODV.
2	    In contrast to evaluations using simulation or model checking, our proof is generic and holds for any possible network scenario in terms of network topology, node mobility, etc.
2	    Due to ambiguities and contradictions the RFC specification allows several interpretations; we show for more than 5000 of them whether they are loop free or not, thereby demonstrating how the reasoning and proofs can relatively easily be adapted to protocol variants.
2	    Using our formal and unambiguous specification, we find shortcomings of AODV that affect performance, e.g. the establishment of non-optimal routes, and some routes not being found at all.
2	    We formalise improvements in the same process algebra; carrying over the proofs is again easy.


# 251
### http://arxiv.org/abs/1007.1611v2
## A Constant-Factor Approximation for Wireless Capacity Maximization with Power Control in the SINR Model


0	    In modern wireless networks, devices are able to set the power for each transmission carried out.
2	    Experimental but also theoretical results indicate that such power control can improve the network capacity significantly.
1	    We study this problem in the physical interference model using SINR constraints.
1	    In the SINR capacity maximization problem, we are given n pairs of senders and receivers, located in a metric space (usually a so-called fading metric).
1	    The algorithm shall select a subset of these pairs and choose a power level for each of them with the objective of maximizing the number of simultaneous communications.
1	    This is, the selected pairs have to satisfy the SINR constraints with respect to the chosen powers.
1	    We present the first algorithm achieving a constant-factor approximation in fading metrics.
2	    The best previous results depend on further network parameters such as the ratio of the maximum and the minimum distance between a sender and its receiver.
2	    Expressed only in terms of n, they are (trivial) Omega(n) approximations.
2	    Our algorithm still achieves an O(log n) approximation if we only assume to have a general metric space rather than a fading metric.
2	    Furthermore, by using standard techniques the algorithm can also be used in single-hop and multi-hop scheduling scenarios.
2	    Here, we also get polylog(n) approximations.


# 252
### http://arxiv.org/abs/1212.6354v1
## LNOS - Live Network Operating System


0	    Operating Systems exists since existence of computers, and have been evolving continuously from time to time.
1	    In this paper we have reviewed a relatively new or unexplored topic of Live OS.
1	    From networking perspective, Live OS is used for establishing Clusters, Firewalls and as Network security assessment tool etc.
2	    Our proposed concept is that a Live OS can be established or configured for an organizations specific network requirements with respect to their servers.
0	    An important server failure due to hardware or software could take time for remedy of the problem, so for that situation a preconfigured server in the form of Live OS on CD/DVD/USB can be used as an immediate solution.
1	    In a network of ten nodes, we stopped the server machine and with necessary adjustments, Live OS replaced the server in less than five minutes.
0	    Live OS in a network environment is a quick replacement of the services that are failed due to server failure (hardware or software).
1	    It is a cost effective solution for low budget networks.
2	    The life of Live OS starts when we boot it from CD/DVD/USB and remains in action for that session.
1	    As soon as the machine is rebooted, any work done for that session is gone, (in case we do not store any information on permanent storage media).
0	    Live CD/DVD/USB is normally used on systems where we do not have Operating Systems installed.
0	    A Live OS can also be used on systems where we already have an installed OS.
0	    On the basis of functionality a Live OS can be used for many purposes and has some typical advantages that are not available on other operating systems.
0	    Vendors are releasing different distributions of Live OS and is becoming their sole identity in a particular domain like Networks, Security, Education or Entertainment etc.
0	    There can be many aspects of Live OS, but Linux based Live OS and their use in the field of networks is the main focus of this paper.


# 253
### http://arxiv.org/abs/1407.2041v1
## ImpNet: Programming Software-Defied Networks Using Imperative Techniques


0	    Software and hardware components are basic parts of modern networks.
0	    However the software compo- nent is typical sealed and function-oriented.
0	    Therefore it is very difficult to modify these components.
0	    This badly affected networking innovations.
2	    Moreover, this resulted in network policies having complex interfaces that are not user-friendly and hence resulted in huge and complicated flow tables on physical switches of networks.
0	    This greatly degrades the network performance in many cases.
0	    Software-Defined Networks (SDNs) is a modern architecture of networks to overcome issues mentioned above.
1	    The idea of SDN is to add to the network a controller device that manages all the other devices on the network including physical switches of the network.
1	    One of the main tasks of the managing process is switch learning; achieved via programming physical switches of the network by adding or removing rules for packet-processing to/from switches, more specifically to/from their flow tables.
1	    A high-level imperative network programming language, called ImpNet, is presented in this paper.
2	    ImpNet enables writing efficient, yet simple, and powerful programs to run on the controller to control all other network devices including switches.
2	    ImpNet is compositional, simply-structured, expressive, and more importantly imperative.
1	    The syntax of ImpNet together two types of operational semantics to contracts of ImpNet are presented in the paper.
1	    The proposed semantics are of the static and dynamic types.
0	    Two modern application programmed using ImpNet are shown in the paper as well.
0	    The semantics of the applications are shown in the paper also.


# 254
### http://arxiv.org/abs/1407.4149v1
## Hybrid Communication Architecture HCA


0	    The beginning of the 21st century has seen many projects on distributed hash tables, both research and commercial.
1	    One of their aims has been to replace the first generation of file sharing software with scalable peer-to-peer architectures.
1	    On other fronts, the same techniques are applied, for example, to content delivery networks, streaming networks, cooperative caches, distributed file systems, and grid computing architectures for scientific use.
1	    This trend has emerged because with cooperative peers it is possible to asymptotically enhance the use of resouces in sharing of data compared to the basic client-server architecture.
0	    The need for distribution of data is wide and one could argue that it is as fundamental a building block as the message passing of the Internet.
0	    As an answer to this need a new scalable architecture is introduced: Hybrid Communication Architecture (HCA), which provides both data sharing and message passing as communication primitives for applications.
1	    HCA can be regarded as an abstraction layer for communication which is further encapsulated by a higher-level middleware.
1	    HCA is aimed at general use, and it is not designed for any particular application.
1	    One key idea is to combine data sharing with streaming since together they enable many applications not easily implementable with only one of these features.
1	    For example, a game application could share the game world state between clients and modify it by using streaming.
2	    The other distinctive feature of the system is the use of knowledge of the physical network topology in the optimization of the communication.
2	    With a feasible business model, fault-tolerance, and security features, HCA is aimed eventually for real-life adoption.
2	    This thesis presents the specification of the C++ client interface of HCA and the architecture and protocol of the distributed nodes forming the implementation.


# 255
### http://arxiv.org/abs/1407.4355v1
## Pricing for local and global WiFi markets


0	    This paper analyzes two pricing schemes commonly used in WiFi markets: the flat-rate and the usage-based pricing.
2	    The flat-rate pricing encourages the maximum usage, while the usage-based pricing can flexibly attract more users especially those with low valuations in mobile Internet access.
1	    First, we use theoretical analysis to compare the two schemes and show that for a single provider in a market, as long as the WiFi capacity is abundant, the flat-rate pricing leads to more revenue.
1	    Second, we study how a global provider (e.g., Skype) collaborates with this monopolist in each local market to provide a global WiFi service.
1	    We formulate {the interactions between the global and local providers as a dynamic game.
0	    In Stage I, the global provider bargains with the local provider in each market to determine the global WiFi service price and revenue sharing agreement.
1	    In Stage II, local users and travelers choose local or global WiFi services.
1	    We analytically show that the global provider prefers to use the usage-based pricing to avoid a severe competition with the local provider.
2	    At the equilibrium, the global provider always shares the majority of his revenue with the local provider to incentivize the cooperation.
1	    Finally, we analytically study how the interaction changes if the local market has more than one local provider.
1	    In this case, the global provider can integrate the coverages of multiple local providers and provide a better service.
1	    Compared to the local monopoly case, local market competition enables the global provider to share less revenue with each of the local providers.
2	    However, we numerically show that the global provider's revenue could decrease, as he shares his revenue with more providers and can only charge a lower price.


# 256
### http://arxiv.org/abs/1407.5320v1
## An Optimum Scheduling Approach for Creating Optimal Priority of Jobs with Business Values in Cloud Computing


0	    Realizing an optimal task scheduling by taking into account the business importance of jobs has become a matter of interest in pay and use model of Cloud computing.
2	    Introduction of an appropriate model for an efficient task scheduling technique could derive benefit to the service providers as well as clients.
2	    In this paper, we have addressed two major challenges which has implications on the performance of the Cloud system.
2	    One of the major issues is handling technical aspects of distributing the tasks for targeted gains and the second issue is related to the handling of the business priority for concurrently resolving business complexity related to cloud consumers.
2	    A coordinated scheduling can be achieved by considering the weightage of both aspects viz.
2	    technical requirements and business requirements appropriately.
2	    It can be done in such a way that it meets the QoS requirements of technical domain as well as business domain.
2	    Along with the technical priority a business Bp is required in creating a resultant priority which could be given to stages of further processing, like task allocation and arbitration schemes.
1	    Here we consider a technical priority Tp that is governed by a semi-adaptive scheduling algorithm whereas the resultant priority is derived in which a Business Priority Bp layer encapsulates the Technical Priority Tp to achieve the overall priority of the incoming tasks.
2	    It results in a Hybrid priority creation, which is a combination of both technical priority Tp and business priority Bp.
2	    By taking into account the business priority of the jobs it is possible to achieve a higher service level satisfaction for the tasks which are submitted with their native technical priority.
2	    With this approach the waiting time of the tasks tends to get reduced and it gives a better service level satisfaction.


# 257
### http://arxiv.org/abs/1407.7464v1
## An Optimal Game Theoretical Framework for Mobility Aware Routing in Mobile Ad hoc Networks


0	    Selfish behaviors are common in self-organized Mobile Ad hoc Networks (MANETs) where nodes belong to different authorities.
0	    Since cooperation of nodes is essential for routing protocols, various methods have been proposed to stimulate cooperation among selfish nodes.
0	    In order to provide sufficient incentives, most of these methods pay nodes a premium over their actual costs of participation.
0	    However, they lead to considerably large overpayments.
0	    Moreover, existing methods ignore mobility of nodes, for simplicity.
0	    However, owing to the mobile nature of MANETs, this assumption seems unrealistic.
1	    In this paper, we propose an optimal game theoretical framework to ensure the proper cooperation in mobility aware routing for MANETs.
1	    The proposed method is based on the multi-dimensional optimal auctions which allows us to consider path durations, in addition to the route costs.
0	    Path duration is a metric that best reflects changes in topology caused by mobility of nodes and, it is widely used in mobility aware routing protocols.
2	    Furthermore, the proposed mechanism is optimal in that it minimizes the total expected payments.
2	    We provide theoretical analysis to support our claims.
2	    In addition, simulation results show significant improvements in terms of payments compared to the most popular existing methods.


# 258
### http://arxiv.org/abs/1201.2288v1
## Nimble@ITCEcnoGrid: A Grid in Research Domain for Weather Forecasting


0	    Computer Technology has Revolutionized Science.
0	    This has motivated scientists to develop mathematical model to simulate salient features of Physical universe.
2	    These models can approximate reality at many levels of scale such as atomic nucleus, Earth's biosphere & weather/climate assessment.
2	    If the computer power is greater, the greater will be the accuracy in approximation i.e. close will be the approximation to the reality.
1	    The speed of the computer required for solution of such problems require computers with processing power of teraflops to Pets flops speed.. The way to speed up the computation is to "parallelize" it.
1	    One of the approach is to use multimillion dollar Supercomputer or use Computational Grid (which is also called poor man's supercomputer) having geographically distributed resources e.g. SETI@home (Used to detect radio waves emitted by intelligent civilizations outside earth) has 4.6 million participants computers.
0	    There are many alternatives tools available to achieve this goal like Globus Toolkit, Entropia, Legion, BOINC etc but they are mainly based on Linux platform.
0	    As majority of the computers available are windows based, so it will be easy to develop a larger network of computers which will use the free cycles of the computer to solve the complex problem at window platform.
1	    Nimble@ITCEcnoGrid has been developed.
1	    It includes the feature of Inter Thread Communication which is missing in any of the toolkits available.
1	    Nimble@ITCEcnoGrid Framework (A Fast Grid with Inter-thread communication with Economic Based Policy) was tested for computation of 'PI' up to 120 decimal points.
1	    Encouraged by the speed the same system has been utilized to computes the Momentum, Thermodynamics and Continuity equations for the Weather Forecasting using the Windows based Desktop computers.


# 259
### http://arxiv.org/abs/1201.2575v2
## Joint Approximation of Information and Distributed Link-Scheduling Decisions in Wireless Networks


0	    For a large multi-hop wireless network, nodes are preferable to make distributed and localized link-scheduling decisions with only interactions among a small number of neighbors.
0	    However, for a slowly decaying channel and densely populated interferers, a small size neighborhood often results in nontrivial link outages and is thus insufficient for making optimal scheduling decisions.
0	    A question arises how to deal with the information outside a neighborhood in distributed link-scheduling.
1	    In this work, we develop joint approximation of information and distributed link scheduling.
1	    We first apply machine learning approaches to model distributed link-scheduling with complete information.
1	    We then characterize the information outside a neighborhood in form of residual interference as a random loss variable.
1	    The loss variable is further characterized by either a Mean Field approximation or a normal distribution based on the Lyapunov central limit theorem.
1	    The approximated information outside a neighborhood is incorporated in a factor graph.
1	    This results in joint approximation and distributed link-scheduling in an iterative fashion.
1	    Link-scheduling decisions are first made at each individual node based on the approximated loss variables.
1	    Loss variables are then updated and used for next link-scheduling decisions.
1	    The algorithm repeats between these two phases until convergence.
1	    Interactive iterations among these variables are implemented with a message-passing algorithm over a factor graph.
2	    Simulation results show that using learned information outside a neighborhood jointly with distributed link-scheduling reduces the outage probability close to zero even for a small neighborhood.


# 260
### http://arxiv.org/abs/1205.1331v1
## Approximation Algorithms for Wireless Link Scheduling with Flexible Data Rates


0	    We consider scheduling problems in wireless networks with respect to flexible data rates.
1	    That is, more or less data can be transmitted per time depending on the signal quality, which is determined by the signal-to-interference-plus-noise ratio (SINR).
1	    Each wireless link has a utility function mapping SINR values to the respective data rates.
0	    We have to decide which transmissions are performed simultaneously and (depending on the problem variant) also which transmission powers are used.
0	    In the capacity-maximization problem, one strives to maximize the overall network throughput, i.e., the summed utility of all links.
1	    For arbitrary utility functions (not necessarily continuous ones), we present an O(log n)-approximation when having n communication requests.
1	    This algorithm is built on a constant-factor approximation for the special case of the respective problem where utility functions only consist of a single step.
1	    In other words, each link has an individual threshold and we aim at maximizing the number of links whose threshold is satisfied.
2	    On the way, this improves the result in [Kesselheim, SODA 2011] by not only extending it to individual thresholds but also showing a constant approximation factor independent of assumptions on the underlying metric space or the network parameters.
1	    In addition, we consider the latency-minimization problem.
1	    Here, each link has a demand, e.g., representing an amount of data.
1	    We have to compute a schedule of shortest possible length such that for each link the demand is fulfilled, that is the overall summed utility (or data transferred) is at least as large as its demand.
1	    Based on the capacity-maximization algorithm, we show an O(log^2 n)-approximation for this problem.


# 261
### http://arxiv.org/abs/1206.7111v3
## Data Minimisation in Communication Protocols: A Formal Analysis Framework and Application to Identity Management


0	    With the growing amount of personal information exchanged over the Internet, privacy is becoming more and more a concern for users.
0	    One of the key principles in protecting privacy is data minimisation.
0	    This principle requires that only the minimum amount of information necessary to accomplish a certain goal is collected and processed. "
0	    Privacy-enhancing" communication protocols have been proposed to guarantee data minimisation in a wide range of applications.
0	    However, currently there is no satisfactory way to assess and compare the privacy they offer in a precise way: existing analyses are either too informal and high-level, or specific for one particular system.
1	    In this work, we propose a general formal framework to analyse and compare communication protocols with respect to privacy by data minimisation.
0	    Privacy requirements are formalised independent of a particular protocol in terms of the knowledge of (coalitions of) actors in a three-layer model of personal information.
0	    These requirements are then verified automatically for particular protocols by computing this knowledge from a description of their communication.
1	    We validate our framework in an identity management (IdM) case study.
0	    As IdM systems are used more and more to satisfy the increasing need for reliable on-line identification and authentication, privacy is becoming an increasingly critical issue.
1	    We use our framework to analyse and compare four identity management systems.
2	    Finally, we discuss the completeness and (re)usability of the proposed framework.


# 262
### http://arxiv.org/abs/1408.2813v1
## BSRone: Binary Search with Routing of O(1); A Scalable Circular Design for Distributed Networks


0	    Peer-to-Peer (P2P) networks as distributed solutions are used in a variety of applications.
1	    Based on the type of routing for queries among their nodes, they are classified into three groups: structured, unstructured and small-world P2P networks.
1	    Each of these categories has its own applications and benefits.
1	    Structured networks by using Distributed Hash Tables (DHT) can forward request search queries more efficiency.
0	    These networks usually organize a specific topology and make a geometrical shape.
1	    A circular topology is a prevalent design which was first introduced by Chord.
1	    In this paper, we propose BSROne, a circular structured P2P design which attempts to consider several shortcomings in the current networks.
1	    In our proposed method, we want to achieve O(1) routing time without requiring all of the nodes to know about each other.
2	    By removing the real connections between nodes and tying all of them with super-nodes, we gave the network an ability to scale up by introducing one layer above super-nodes.
1	    We achieved this by emulating the design of binary search algorithm for supreme-nodes.
1	    In this paper, at first we introduce a design where fixed super-nodes with unlimited resources are given to the distributed network.
1	    In the next step, we explain how it can manage to work as a P2P application.
2	    We finally discuss the possibility of removing the scalability issue in a P2P environment for our design.


# 263
### http://arxiv.org/abs/1411.6749v1
## Analyzing DISH for Multi-Channel MAC Protocols in Wireless Networks


0	    For long, node cooperation has been exploited as a data relaying mechanism.
0	    However, the wireless channel allows for much richer interaction between nodes.
0	    One such scenario is in a multi-channel environment, where transmitter-receiver pairs may make incorrect decisions (e.g., in selecting channels) but idle neighbors could help by sharing information to prevent undesirable consequences (e.g., data collisions).
0	    This represents a Distributed Information SHaring (DISH) mechanism for cooperation and suggests new ways of designing cooperative protocols.
0	    However, what is lacking is a theoretical understanding of this new notion of cooperation.
1	    In this paper, we view cooperation as a network resource and evaluate the availability of cooperation via a metric, $p_{co}$, the probability of obtaining cooperation.
1	    First, we analytically evaluate $p_{co}$ in the context of multi-channel multi-hop wireless networks.
1	    Second, we verify our analysis via simulations and the results show that our analysis accurately characterizes the behavior of $p_{co}$ as a function of underlying network parameters.
2	    This step also yields important insights into DISH with respect to network dynamics.
1	    Third, we investigate the correlation between $p_{co}$ and network performance in terms of collision rate, packet delay, and throughput.
2	    The results indicate a near-linear relationship, which may significantly simplify performance analysis for cooperative networks and suggests that $p_{co}$ be used as an appropriate performance indicator itself.
2	    Throughout this work, we utilize, as appropriate, three different DISH contexts --- model-based DISH, ideal DISH, and real DISH --- to explore $p_{co}$.


# 264
### http://arxiv.org/abs/1504.02324v1
## Designing Installations for Verification of the Model of Active Queue Management Discipline RED in the GNS3


0	    The problem of RED-module mathematical model results verification, based on GNS3 experimental stand, is discussed in this article.
0	    The experimental stand consists of virtual Cisco router, traffic generator D-ITG and traffic receiver.
1	    The process of construction of such stand is presented.
1	    Also, the interaction between experimental stand and a computer of investigation in order to obtain and analyze data from stand is revised.
1	    A stochastic model of the traffic management RED type module was built.
1	    Verification of the model was carried out on the NS-2 basis.
0	    However, we would like to conduct verification on a real router.
1	    As a result was the task of designing an experimental stand.
1	    It was decided to verify the clean RED algorithm based on Cisco router.
1	    For the construction of the stand software package GNS3 (Graphical Network Simulator) was chosen.
1	    Thus, the purpose of the study is to build on the GNS3 basis a virtual stand consisting of a Cisco router, a traffic generator and a receiver.
1	    A traffic generator D-ITG (Distributed Internet Traffic Generator) is used as.


# 265
### http://arxiv.org/abs/1601.01419v1
## Absolute Trust: Algorithm for Aggregation of Trust in Peer-to- Peer Networks


0	    To mitigate the attacks by malicious peers and to motivate the peers to share the resources in peer-to-peer networks, several reputation systems have been proposed in the past.
0	    In most of them, the peers evaluate other peers based on their past interactions and then aggregate this information in the whole network.
0	    However such an aggregation process requires approximations in order to converge at some global consensus.
0	    It may not be the true reflection of past behavior of the peers.
2	    Moreover such type of aggregation gives only the relative ranking of peers without any absolute evaluation of their past.
2	    This is more significant when all the peers responding to a query, are malicious.
2	    In such a situation, we can only know that who is better among them without knowing their rank in the whole network.
1	    In this paper, we are proposing a new algorithm which accounts for the past behavior of the peers and will estimate the absolute value of the trust of peers.
1	    Consequently, we can suitably identify them as a good peers or malicious peers.
2	    Our algorithm converges at some global consensus much faster by choosing suitable parameters.
2	    Because of its absolute nature it will equally load all the peers in network.
2	    It will also reduce the inauthentic download in the network which was not possible in existing algorithms.


# 266
### http://arxiv.org/abs/1601.02117v1
## LAPPS: Location Aware Password Protection System


0	    Location Aware Password Protection System (LAPPS) is designed to strengthen the security of traditional password protection systems.
2	    This is achieved by adding several layers of protection to the passwords that most traditional password protection systems generate.
1	    The current implementation looks at the Password/Pin numbers of Credit/Debit cards that are used on Automated Teller Machine (ATM),though the underlying design of the system can be used in many other scenarios.
1	    A password that is generated will be allocated to a particular user and to the ATM that is nearest to the user.
1	    LAPPS ensures the following qualities of the passwords that it generates.
1	    Location Awareness: The passwords are generated according to the users' geographical area, that they request their passwords from.
1	    So a password will only be active in just one location.
2	    Time Awareness: A password will only be valid for five minutes.
2	    The unused passwords will be discarded.
1	    Dynamic: The user has to have a new password each time he/she logs in.
1	    A password is generated to be used only once.
1	    User Oriented/Specific: The received password can only be used by the requester, and can only be used on its allocated ATM.
1	    Two Factor Authenticity: The confidential information will be secured using two-factor authentication.
1	    For extra security, a Pin generating device has been introduced.
1	    This will produce an eight digit number that the user has to supply to the mobile application, before requesting for a password.
1	    The user can obtain a pin number by inserting his/her Debit/Credit card and the fixed password that has been allocated when the user registers with the system.


# 267
### http://arxiv.org/abs/1601.04314v1
## How Good is Bargained Routing?


0	    In the context of networking, research has focused on non-cooperative games, where the selfish agents cannot reach a binding agreement on the way they would share the infrastructure.
0	    Many approaches have been proposed for mitigating the typically inefficient operating points.
0	    However, in a growing number of networking scenarios selfish agents are able to communicate and reach an agreement.
0	    Hence, the degradation of performance should be considered at an operating point of a cooperative game.
0	    Accordingly, our goal is to lay foundations for the application of cooperative game theory to fundamental problems in networking.
1	    We explain our choice of the Nash Bargaining Scheme (NBS) as the solution concept, and introduce the Price of Selfishness (PoS), which considers the degradation of performance at the worst NBS.
1	    We focus on the fundamental load balancing game of routing over parallel links.
1	    First, we consider agents with identical performance objectives.
2	    We show that, while the PoA here can be large, through bargaining, all agents, and the system, strictly improve their performance.
2	    Interestingly, in a two-agent system or when all agents have identical demands, we establish that they reach social optimality.
1	    We then consider agents with different performance objectives and demonstrate that the PoS and PoA can be unbounded, yet we explain why both measures are unsuitable.
1	    Accordingly, we introduce the Price of Heterogeneity (PoH), as an extension of the PoA. We establish an upper-bound on the PoH and indicate its further motivation for bargaining.
2	    Finally, we discuss network design guidelines that follow from our findings


# 268
### http://arxiv.org/abs/1402.5003v1
## Beyond Geometry : Towards Fully Realistic Wireless Models


0	    Signal-strength models of wireless communications capture the gradual fading of signals and the additivity of interference.
0	    As such, they are closer to reality than other models.
2	    However, nearly all theoretic work in the SINR model depends on the assumption of smooth geometric decay, one that is true in free space but is far off in actual environments.
1	    The challenge is to model realistic environments, including walls, obstacles, reflections and anisotropic antennas, without making the models algorithmically impractical or analytically intractable.
1	    We present a simple solution that allows the modeling of arbitrary static situations by moving from geometry to arbitrary decay spaces.
1	    The complexity of a setting is captured by a metricity parameter Z that indicates how far the decay space is from satisfying the triangular inequality.
2	    All results that hold in the SINR model in general metrics carry over to decay spaces, with the resulting time complexity and approximation depending on Z in the same way that the original results depends on the path loss term alpha.
2	    For distributed algorithms, that to date have appeared to necessarily depend on the planarity, we indicate how they can be adapted to arbitrary decay spaces.
2	    Finally, we explore the dependence on Z in the approximability of core problems.
2	    In particular, we observe that the capacity maximization problem has exponential upper and lower bounds in terms of Z in general decay spaces.
1	    In Euclidean metrics and related growth-bounded decay spaces, the performance depends on the exact metricity definition, with a polynomial upper bound in terms of Z, but an exponential lower bound in terms of a variant parameter phi.
2	    On the plane, the upper bound result actually yields the first approximation of a capacity-type SINR problem that is subexponential in alpha.


# 269
### http://arxiv.org/abs/1404.2387v1
## Fast Structuring of Radio Networks for Multi-Message Communications


1	    We introduce collision free layerings as a powerful way to structure radio networks.
2	    These layerings can replace hard-to-compute BFS-trees in many contexts while having an efficient randomized distributed construction.
1	    We demonstrate their versatility by using them to provide near optimal distributed algorithms for several multi-message communication primitives.
0	    Designing efficient communication primitives for radio networks has a rich history that began 25 years ago when Bar-Yehuda et al.
1	    introduced fast randomized algorithms for broadcasting and for constructing BFS-trees.
1	    Their BFS-tree construction time was $O(D \log^2 n)$ rounds, where $D$ is the network diameter and $n$ is the number of nodes.
1	    Since then, the complexity of a broadcast has been resolved to be $T_{BC} = \Theta(D \log \frac{n}{D} + \log^2 n)$ rounds.
1	    On the other hand, BFS-trees have been used as a crucial building block for many communication primitives and their construction time remained a bottleneck for these primitives.
1	    We introduce collision free layerings that can be used in place of BFS-trees and we give a randomized construction of these layerings that runs in nearly broadcast time, that is, w.h.p.
1	    in $T_{Lay} = O(D \log \frac{n}{D} + \log^{2+\epsilon} n)$ rounds for any constant $\epsilon>0$. We then use these layerings to obtain: (1) A randomized algorithm for gathering $k$ messages running w.h.p.
1	    in $O(T_{Lay} + k)$ rounds. (
1	    2) A randomized $k$-message broadcast algorithm running w.h.p.
1	    in $O(T_{Lay} + k \log n)$ rounds.
1	    These algorithms are optimal up to the small difference in the additive poly-logarithmic term between $T_{BC}$ and $T_{Lay}$. Moreover, they imply the first optimal $O(n \log n)$ round randomized gossip algorithm.


# 270
### http://arxiv.org/abs/1404.6766v3
## Quality Sensitive Price Competition in Spectrum Oligopoly: Part II


0	    We investigate a spectrum oligopoly market where each primary seeks to sell secondary access to its channel at multiple locations.
1	    Transmission qualities of a channel evolve randomly.
1	    Each primary needs to select a price and a set of non-interfering locations (which is an independent set in the conflict graph of the region) at which to offer its channel without knowing the transmission qualities of the channels of its competitors.
1	    We formulate the above problem as a non-cooperative game.
1	    We consider two scenarios-i) when the region is small, ii) when the region is large.
1	    In the first setting, we focus on a class of conflict graphs, known as mean valid graphs which commonly arise when the region is small.
1	    We explicitly compute a symmetric Nash equilibrium (NE); the NE is threshold type in that primaries only choose independent set whose cardinality is greater than a certain threshold.
2	    The threshold on the cardinality increases with increase in quality of the channel on sale.
2	    We show that the symmetric NE strategy profile is unique in a special class of conflict graphs (linear graph).
1	    In the second setting, we consider node symmetric conflict graphs which arises when the number of locations is large (potentially, infinite).
1	    We explicitly compute a symmetric NE that randomizes equally among the maximum independent sets at a given channel state vector.
1	    In the NE a primary only selects the maximum independent set at a given channel state vector.
2	    We show that the two symmetric NEs computed in two settings exhibit important structural difference.


# 271
### http://arxiv.org/abs/1405.6216v1
## NDTAODV: Neighbor Defense Technique for Ad Hoc On-Demand Distance Vector(AODV) to mitigate flood attack in MANETS


0	    Mobile Ad Hoc Networks (MANETs) are collections of mobile nodes that can communicate with one another using multihop wireless links.
0	    MANETs are often deployed in the environments, where there is no fixed infrastructure and centralized management.
0	    The nodes of mobile ad hoc networks are susceptible to compromise.
0	    In such a scenario, designing an efficient, reliable and secure routing protocol has been a major challengesue over the last many years.
0	    The routing protocol Ad hoc On-demand Distance Vector (AODV) has no security measures in-built in it.
0	    It is vulnerable to many types of routing attacks.
0	    The flood attack is one of them.
1	    In this paper, we propose a simple and effective technique to secure Ad hoc Ondemand Distance Vector (AODV) routing protocol against flood attacks.
1	    To deal with a flood attack, we have proposed Neighbor Defense Technique for Ad hoc On-demand Distance Vector (NDTAODV).
2	    This makes AODV more robust.
1	    The proposed technique has been designed to isolate the flood attacker with the use of timers, peak value and hello alarm technique.
1	    We have simulated our work in Network Simulator NS-2.33 (NS-2) with different pause times by way of different number of malicious nodes.
1	    We have compared the performance of NDTAODV with the AODV in normal situation as well as in the presence of malicious attacks.
1	    We have considered Packet Delivery Fraction (PDF), Average Throughput (AT) and Normalized Routing Load (NRL) for comparing the performance of NDTAODV and AODV.


# 272
### http://arxiv.org/abs/1503.02955v3
## Low-Delay Adaptive Video Streaming Based on Short-Term TCP Throughput Prediction


0	    Recently, HTTP-Based Adaptive Streaming has become the de facto standard for video streaming over the Internet.
0	    It allows the client to adapt media characteristics to varying network conditions in order to maximize Quality of Experience (QoE).
2	    In the case of live streaming this task becomes particularly challenging.
0	    An important factor than might help improving performance is the capability to correctly predict network throughput dynamics on short to medium timescales.
0	    It becomes notably difficult in wireless networks that are often subject to continuous throughput fluctuations.
1	    In the present work, we develop an adaptation algorithm for HTTP-Based Adaptive Live Streaming that, for each adaptation decision, maximizes a QoE-based utility function depending on the probability of playback interruptions, average video quality, and the amount of video quality fluctuations.
1	    To compute the utility function the algorithm leverages throughput predictions, and dynamically estimated prediction accuracy.
1	    We are trying to close the gap created by the lack of studies analyzing TCP throughput on short to medium timescales.
1	    We study several time series prediction methods and their error distributions.
2	    We observe that Simple Moving Average performs best in most cases.
2	    We also observe that the relative underestimation error is best represented by a truncated normal distribution, while the relative overestimation error is best represented by a Lomax distribution.
2	    Moreover, underestimations and overestimations exhibit a temporal correlation that we use to further improve prediction accuracy.
1	    We compare the proposed algorithm with a baseline approach that uses a fixed margin between past throughput and selected media bit rate, and an oracle-based approach that has perfect knowledge over future throughput for a certain time horizon.


# 273
### http://arxiv.org/abs/1506.01414v1
## Network investigation methodology for BitTorrent Sync: A Peer-to-Peer based file synchronisation service


0	    High availability is no longer just a business continuity concern.
0	    Users are increasingly dependant on devices that consume and produce data in ever increasing volumes.
1	    A popular solution is to have a central repository which each device accesses after centrally managed authentication.
1	    This model of use is facilitated by cloud based file synchronisation services such as Dropbox, OneDrive, Google Drive and Apple iCloud.
2	    Cloud architecture allows the provisioning of storage space with "always-on" access.
0	    Recent concerns over unauthorised access to third party systems and large scale exposure of private data have made an alternative solution desirable.
0	    These events have caused users to assess their own security practices and the level of trust placed in third party storage services.
1	    One option is BitTorrent Sync, a cloudless synchronisation utility provides data availability and redundancy.
1	    This utility replicates files stored in shares to remote peers with access controlled by keys and permissions.
1	    While lacking the economies brought about by scale, complete control over data access has made this a popular solution.
2	    The ability to replicate data without oversight introduces risk of abuse by users as well as difficulties for forensic investigators.
2	    This paper suggests a methodology for investigation and analysis of the protocol to assist in the control of data flow across security perimeters.


# 274
### http://arxiv.org/abs/1506.04657v1
## A Non-stationary Service Curve Model for Performance Analysis of Transient Phases


0	    Steady-state solutions for a variety of relevant queueing systems are known today, e.g., from queueing theory, effective bandwidths, and network calculus.
0	    The behavior during transient phases, on the other hand, is understood to a much lesser extent as its analysis poses significant challenges.
0	    Considering the majority of short-lived flows, transient effects that have diverse causes, such as TCP slow start, sleep scheduling in wireless networks, or signalling in cellular networks, are, however, predominant.
0	    This paper contributes a general model of regenerative service processes to characterize the transient behavior of systems.
1	    The model leads to a notion of non-stationary service curves that can be conveniently integrated into the framework of the stochastic network calculus.
1	    We derive respective models of sleep scheduling and show the significant impact of transient phases on backlogs and delays.
1	    We also consider measurement methods that estimate the service of an unknown system from observations of selected probe traffic.
2	    We find that the prevailing rate scanning method does not recover the service during transient phases well.
2	    This limitation is fundamental as it is explained by the non-convexity of non-stationary service curves.
0	    A second key difficulty is proven to be due to the super-additivity of network service processes.
1	    We devise a novel two-phase probing technique that first determines a minimal pattern of probe traffic.
1	    This probe is used to obtain an accurate estimate of the unknown transient service.


# 275
### http://arxiv.org/abs/1508.05411v1
## On the use of homomorphic encryption to secure cloud computing, services, and routing protocols


0	    The trend towards delegating data processing to a remote party raises major concerns related to privacy violations for both end-users and service providers.
0	    These concerns have attracted the attention of the research community, and several techniques have been proposed to protect against malicious parties by providing secure communication protocols.
0	    Most of the proposed techniques, however, require the involvement of a third party, and this by itself can be viewed as another security concern.
0	    These security breaches can be avoided by following a new approach that depends on data sorted, managed, and stored in encrypted form at the remote servers.
0	    To realize such an approach, the encryption cryptosystem must support algebraic operations over encrypted data.
2	    This cryptosystem can be effective in protecting data and supporting the construction of programs that can process encrypted input and produce encrypted output.
2	    In fact, the latter programs do not decrypt the input, and therefore, they can be run by an un-trusted party without revealing their data and internal states.
2	    Furthermore, such programs prove to be practical in situations where we need to outsource private computations, especially in the context of cloud computing.
1	    Homomorphic cryptosystems are perfectly aligned with these objectives as they are a strong foundation for schemes that allow a blind processing of encrypted data without the need to decrypt them.
1	    In this dissertation we rely on homomorphic encryption schemes to secure cloud computing, services and routing protocols.
1	    We design several circuits that allow for the blind processing and management of data such that malicious parties are denied access to sensitive information.
1	    We select five areas to apply our models to.
0	    These models are easily customized for many other areas.
2	    We also provide prototypes that we use to study the performance and robustness of our models.


# 276
### http://arxiv.org/abs/0707.3936v2
## Closed form solutions for symmetric water filling games


1	    We study power control in optimization and game frameworks.
1	    In the optimization framework there is a single decision maker who assigns network resources and in the game framework users share the network resources according to Nash equilibrium.
1	    The solution of these problems is based on so-called water-filling technique, which in turn uses bisection method for solution of non-linear equations for Lagrange multiplies.
1	    Here we provide a closed form solution to the water-filling problem, which allows us to solve it in a finite number of operations.
1	    Also, we produce a closed form solution for the Nash equilibrium in symmetric Gaussian interference game with an arbitrary number of users.
1	    Even though the game is symmetric, there is an intrinsic hierarchical structure induced by the quantity of the resources available to the users.
1	    We use this hierarchical structure to perform a successive reduction of the game.
1	    In addition, to its mathematical beauty, the explicit solution allows one to study limiting cases when the crosstalk coefficient is either small or large.
2	    We provide an alternative simple proof of the convergence of the Iterative Water Filling Algorithm.
2	    Furthermore, it turns out that the convergence of Iterative Water Filling Algorithm slows down when the crosstalk coefficient is large.
2	    Using the closed form solution, we can avoid this problem.
2	    Finally, we compare the non-cooperative approach with the cooperative approach and show that the non-cooperative approach results in a more fair resource distribution.


# 277
### http://arxiv.org/abs/1011.0792v1
## An Empirical Study of Spam and Spam Vulnerable email Accounts


0	    Spam messages muddle up users inbox, consume network resources, and build up DDoS attacks, spread malware.
0	    Our goal is to present a definite figure about the characteristics of spam and spam vulnerable email accounts.
1	    These evaluations help us to enhance the existing technology to combat spam effectively.
1	    We collected 400 thousand spam mails from a spam trap set up in a corporate mail server for a period of 14 months form January 2006 to February 2007.
1	    Spammers use common techniques to spam end users regardless of corporate server and public mail server.
1	    So we believe that our spam collection is a sample of world wide spam traffic.
1	    Studying the characteristics of this sample helps us to better understand the features of spam and spam vulnerable e-mail accounts.
2	    We believe that this analysis is highly useful to develop more efficient anti spam techniques.
1	    In our analysis we classified spam based on attachment and contents.
1	    According to our study the four years old heavy users email accounts attract more spam than four years oldlight users mail accounts.
1	    The 14 months old relatively new email accounts don't receive spam.
1	    In some special cases like DDoS attacks, the new email accounts receive spam.
1	    During DDoS attack 14 months old heavy users email accounts have attracted more number of spam than 14 months old light users mail accounts.


# 278
### http://arxiv.org/abs/1011.3115v1
## Cyber-Physical Control over Wireless Sensor and Actuator Networks with Packet Loss


0	    There is a growing interest in design and implementation of cyber-physical control systems over wireless sensor and actuator networks (WSANs).
0	    Thanks to the use of wireless communications and distributed architectures, these systems encompass many advantages as compared to traditional networked control systems using hard wirelines.
1	    While WSANs are enabling a new generation of control systems, they also introduce considerable challenges for quality-of-service (QoS) provisioning.
1	    In this chapter we examine some of the major QoS challenges raised by WSANs, including resource constraints, platform heterogeneity, dynamic network topology, and mixed traffic.
0	    These challenges make it difficult to fulfill the requirements of cyber-physical control in terms of reliability and real-time.
0	    The focus of this chapter is on addressing the problem of network reliability.
1	    Specifically, we analyze the behavior of wireless channels via simulations based on a realistic link-layer model.
1	    Packet loss rate (PLR) is taken as a major metric for the analysis.
2	    The results confirm the unreliability of wireless communications and the uncertainty of packet loss over WSANs.
1	    To tackle packet loss, we present a simple solution that can take advantage of existing prediction algorithms.
1	    Simulations are conducted to evaluate the performance of several classical prediction algorithms used for packet loss compensation.
2	    The results give some insights into how to deal with packet loss in cyber-physical control systems over unreliable WSANs.


# 279
### http://arxiv.org/abs/1107.1089v3
## Node Sampling using Random Centrifugal Walks


0	    Sampling a network with a given probability distribution has been identified as a useful operation.
1	    In this paper we propose distributed algorithms for sampling networks, so that nodes are selected by a special node, called the \emph{source}, with a given probability distribution.
1	    All these algorithms are based on a new class of random walks, that we call Random Centrifugal Walks (RCW).
1	    A RCW is a random walk that starts at the source and always moves away from it.
1	    Firstly, an algorithm to sample any connected network using RCW is proposed.
1	    The algorithm assumes that each node has a weight, so that the sampling process must select a node with a probability proportional to its weight.
1	    This algorithm requires a preprocessing phase before the sampling of nodes.
1	    In particular, a minimum diameter spanning tree (MDST) is created in the network, and then nodes' weights are efficiently aggregated using the tree.
1	    The good news are that the preprocessing is done only once, regardless of the number of sources and the number of samples taken from the network.
1	    After that, every sample is done with a RCW whose length is bounded by the network diameter.
1	    Secondly, RCW algorithms that do not require preprocessing are proposed for grids and networks with regular concentric connectivity, for the case when the probability of selecting a node is a function of its distance to the source.
1	    The key features of the RCW algorithms (unlike previous Markovian approaches) are that (1) they do not need to warm-up (stabilize), (2) the sampling always finishes in a number of hops bounded by the network diameter, and (3) it selects a node with the exact probability distribution.


# 280
### http://arxiv.org/abs/1107.3682v1
## Context-Capture Multi-Valued Decision Fusion With Fault Tolerant Capability For Wireless Sensor Networks


0	    Wireless sensor networks (WSNs) are usually utilized to perform decision fusion of event detection.
0	    Current decision fusion schemes are based on binary valued decision and do not consider bursty contextcapture.
0	    However, bursty context and multi-valued data are important characteristics of WSNs.
0	    One on hand, the local decisions from sensors usually have bursty and contextual characteristics.
0	    Fusion center must capture the bursty context information from the sensors.
0	    On the other hand, in practice, many applications need to process multi-valued data, such as temperature and reflection level used for lightening prediction.
1	    To address these challenges, the Markov modulated Poisson process (MMPP) and multi-valued logic are introduced into WSNs to perform context-capture multi-valued decision fusion.
1	    The overall decision fusion is decomposed into two parts.
1	    The first part is the context-capture model for WSNs using superposition MMPP.
2	    Through this procedure, the fusion center has a higher probability to get useful local decisions from sensors.
1	    The second one is focused on multi-valued decision fusion.
1	    Fault detection can also be performed based on MVL.
1	    Once the fusion center detects the faulty nodes, all their local decisions are removed from the computation of the likelihood ratios.
1	    Finally, we evaluate the capability of context-capture and fault tolerant.
2	    The result supports the usefulness of our scheme.


# 281
### http://arxiv.org/abs/1107.5559v2
## You Share, I Share: Network Effects and Economic Incentives in P2P File-Sharing Systems


1	    We study the interaction between network effects and external incentives on file sharing behavior in Peer-to-Peer (P2P) networks.
1	    Many current or envisioned P2P networks reward individuals for sharing files, via financial incentives or social recognition.
1	    Peers weigh this reward against the cost of sharing incurred when others download the shared file.
2	    As a result, if other nearby nodes share files as well, the cost to an individual node decreases.
1	    Such positive network sharing effects can be expected to increase the rate of peers who share files.
1	    In this paper, we formulate a natural model for the network effects of sharing behavior, which we term the "demand model."
2	    We prove that the model has desirable diminishing returns properties, meaning that the network benefit of increasing payments decreases when the payments are already high.
2	    This result holds quite generally, for submodular objective functions on the part of the network operator.
0	    In fact, we show a stronger result: the demand model leads to a "coverage process," meaning that there is a distribution over graphs such that reachability under this distribution exactly captures the joint distribution of nodes which end up sharing.
0	    The existence of such distributions has advantages in simulating and estimating the performance of the system.
1	    We establish this result via a general theorem characterizing which types of models lead to coverage processes, and also show that all coverage processes possess the desirable submodular properties.
1	    We complement our theoretical results with experiments on several real-world P2P topologies.
1	    We compare our model quantitatively against more na\"ive models ignoring network effects.
2	    A main outcome of the experiments is that a good incentive scheme should make the reward dependent on a node's degree in the network.


# 282
### http://arxiv.org/abs/1209.1803v1
## Secure and Privacy-Preserving Authentication Protocols for Wireless Mesh Networks


0	    Wireless mesh networks (WMNs) have emerged as a promising concept to meet the challenges in next-generation wireless networks such as providing flexible, adaptive, and reconfigurable architecture while offering cost-effective solutions to service providers.
0	    As WMNs become an increasingly popular replacement technology for last-mile connectivity to the home networking, community and neighborhood networking, it is imperative to design efficient and secure communication protocols for these networks.
0	    However, several vulnerabilities exist in currently existing protocols for WMNs.
0	    These security loopholes can be exploited by potential attackers to launch attack on WMNs.
0	    The absence of a central point of administration makes securing WMNs even more challenging.
1	    The broadcast nature of transmission and the dependency on the intermediate nodes for multi-hop communications lead to several security vulnerabilities in WMNs.
0	    The attacks can be external as well as internal in nature.
0	    External attacks are launched by intruders who are not authorized users of the network.
0	    For example, an intruding node may eavesdrop on the packets and replay those packets at a later point of time to gain access to the network resources.
1	    On the other hand, the internal attacks are launched by the nodes that are part of the WMN.
1	    On example of such attack is an intermediate node dropping packets which it was supposed to forward.
1	    This chapter presents a comprehensive discussion on the current authentication and privacy protection schemes for WMN.
1	    In addition, it proposes a novel security protocol for node authentication and message confidentiality and an anonymization scheme for privacy protection of users in WMNs.


# 283
### http://arxiv.org/abs/1409.0887v1
## Signaling for Decentralized Routing in a Queueing Network


1	    A discrete-time decentralized routing problem in a service system consisting of two service stations and two controllers is investigated.
1	    Each controller is affiliated with one station.
1	    Each station has an infinite size buffer.
1	    Exogenous customer arrivals at each station occur with rate $\lambda$. Service times at each station have rate $\mu$. At any time, a controller can route one of the customers waiting in its own station to the other station.
1	    Each controller knows perfectly the queue length in its own station and observes the exogenous arrivals to its own station as well as the arrivals of customers sent from the other station.
1	    At the beginning, each controller has a probability mass function (PMF) on the number of customers in the other station.
0	    These PMFs are common knowledge between the two controllers.
1	    At each time a holding cost is incurred at each station due to the customers waiting at that station.
1	    The objective is to determine routing policies for the two controllers that minimize either the total expected holding cost over a finite horizon or the average cost per unit time over an infinite horizon.
1	    In this problem there is implicit communication between the two controllers; whenever a controller decides to send or not to send a customer from its own station to the other station it communicates information about its queue length to the other station.
1	    This implicit communication through control actions is referred to as signaling in decentralized control.
2	    Signaling results in complex communication and decision problems.
1	    In spite of the complexity of signaling involved, it is shown that an optimal signaling strategy is described by a threshold policy which depends on the common information between the two controllers; this threshold policy is explicitly determined.


# 284
### http://arxiv.org/abs/1502.07790v2
## Exploiting Coplanar Clusters to Enhance 3D Localization in Wireless Sensor Networks


0	    This thesis studies range-based WSN localization problem in 3D environments that induce coplanarity.
0	    In most real-world applications, even though the environment is 3D, the grounded sensor nodes are usually deployed on 2D planar surfaces.
1	    Examples of these surfaces include structures seen in both indoor (e.g. floors, doors, walls, tables etc.)
0	    and outdoor (e.g. mountains, valleys, hills etc.)
0	    In such environments, sensor nodes typically appear as coplanar node clusters.
1	    We refer to this type of a deployment as a planar deployment.
1	    When there is a planar deployment, the coplanarity causes difficulties to the traditional range-based multilateration algorithms because a node cannot be unambiguously localized if the distance measurements to that node are from coplanar nodes.
0	    Thus, many already localized groups of nodes are rendered ineffective in the process just because they are coplanar.
1	    We, therefore propose an algorithm called Coplanarity Based Localization (CBL) that can be used as an extension of any localization algorithm to avoid most flips caused by coplanarity.
2	    CBL first performs a 2D localization among the nodes that are clustered on the same surface, and then finds the positions of these clusters in 3D. We have carried out experiments using trilateration for 2D localization, and quadrilateration for 3D localization, and experimentally verified that exploiting the clustering information leads to a more precise localization than mere quadrilateration.
1	    We also propose a heuristic to extract the clustering information in case it is not available, which is yet to be improved in the future.


# 285
### http://arxiv.org/abs/1511.03524v1
## MAINT: Localization of Mobile Sensors with Energy Control


0	    Localization is an important issue for Wireless Sensor Networks (WSN).
0	    A mobile sensor may change its position rapidly and thus require localization calls frequently.
0	    A localization may require network wide information and increase traffic over the network.
0	    It dissipates valuable energy for message communication.
2	    Thus localization is very costly.
0	    The control of the number of localization calls may save energy consumption, as it is rather expensive.
1	    To reduce the frequency of localization calls for a mobile sensor, we propose a technique that involves \textit{Mobility Aware Interpolation} (MAINT) for position estimation.
1	    It controls the number of localizations which gives much better result than the existing localization control schemes using mobility aware extrapolation.
1	    The proposed method involves very low arithmetic computation overheads.
1	    We find analytical expressions for the expected error in position estimation.
1	    A parameter, the time interval, has been introduced to externally control the energy dissipation.
1	    Simulation studies are carried out to compare the performances of the proposed method with some existing localization control schemes as well as the theoretical results.
2	    The simulation results shows that the expected error at any point of time may be computed from this expression.
2	    We have seen that constant error limit can be maintained increasing the time period of localization proportional to rate of change of direction of its motion.
2	    Increasing time period, the energy may be saved with a stable error limit.


# 286
### http://arxiv.org/abs/1603.00859v2
## QoE-Based Low-Delay Live Streaming Using Throughput Predictions


0	    Recently, HTTP-based adaptive streaming has become the de facto standard for video streaming over the Internet.
0	    It allows clients to dynamically adapt media characteristics to network conditions in order to ensure a high quality of experience, that is, minimize playback interruptions, while maximizing video quality at a reasonable level of quality changes.
0	    In the case of live streaming, this task becomes particularly challenging due to the latency constraints.
2	    The challenge further increases if a client uses a wireless network, where the throughput is subject to considerable fluctuations.
0	    Consequently, live streams often exhibit latencies of up to 30 seconds.
1	    In the present work, we introduce an adaptation algorithm for HTTP-based live streaming called LOLYPOP (Low-Latency Prediction-Based Adaptation) that is designed to operate with a transport latency of few seconds.
1	    To reach this goal, LOLYPOP leverages TCP throughput predictions on multiple time scales, from 1 to 10 seconds, along with an estimate of the prediction error distribution.
1	    In addition to satisfying the latency constraint, the algorithm heuristically maximizes the quality of experience by maximizing the average video quality as a function of the number of skipped segments and quality transitions.
1	    In order to select an efficient prediction method, we studied the performance of several time series prediction methods in IEEE 802.11 wireless access networks.
1	    We evaluated LOLYPOP under a large set of experimental conditions limiting the transport latency to 3 seconds, against a state-of-the-art adaptation algorithm from the literature, called FESTIVE.
2	    We observed that the average video quality is by up to a factor of 3 higher than with FESTIVE.
2	    We also observed that LOLYPOP is able to reach a broader region in the quality of experience space, and thus it is better adjustable to the user profile or service provider requirements.


# 287
### http://arxiv.org/abs/1603.03409v3
## Security, Privacy, and Access Control in Information-Centric Networking: A Survey


0	    Information-Centric Networking (ICN) is a new networking paradigm, which replaces the widely used host-centric networking paradigm in communication networks (e.g., Internet, mobile ad hoc networks) with an information-centric paradigm, which prioritizes the delivery of named content, oblivious of the contents origin.
0	    Content and client security are more intrinsic in the ICN paradigm versus the current host centric paradigm where they have been instrumented as an after thought.
2	    By design, the ICN paradigm inherently supports several security and privacy features, such as provenance and identity privacy, which are still not effectively available in the host-centric paradigm.
0	    However, given its nascency, the ICN paradigm has several open security and privacy concerns, some that existed in the old paradigm, and some new and unique.
1	    In this article, we survey the existing literature in security and privacy research sub-space in ICN.
2	    More specifically, we explore three broad areas: security threats, privacy risks, and access control enforcement mechanisms.
1	    We present the underlying principle of the existing works, discuss the drawbacks of the proposed approaches, and explore potential future research directions.
1	    In the broad area of security, we review attack scenarios, such as denial of service, cache pollution, and content poisoning.
2	    In the broad area of privacy, we discuss user privacy and anonymity, name and signature privacy, and content privacy.
0	    ICN's feature of ubiquitous caching introduces a major challenge for access control enforcement that requires special attention.
1	    In this broad area, we review existing access control mechanisms including encryption-based, attribute-based, session-based, and proxy re-encryption-based access control schemes.
2	    We conclude the survey with lessons learned and scope for future work.


# 288
### http://arxiv.org/abs/1605.07524v2
## Hijacking Bitcoin: Routing Attacks on Cryptocurrencies


0	    As the most successful cryptocurrency to date, Bitcoin constitutes a target of choice for attackers.
0	    While many attack vectors have already been uncovered, one important vector has been left out though: attacking the currency via the Internet routing infrastructure itself.
0	    Indeed, by manipulating routing advertisements (BGP hijacks) or by naturally intercepting traffic, Autonomous Systems (ASes) can intercept and manipulate a large fraction of Bitcoin traffic.
1	    This paper presents the first taxonomy of routing attacks and their impact on Bitcoin, considering both small-scale attacks, targeting individual nodes, and large-scale attacks, targeting the network as a whole.
2	    While challenging, we show that two key properties make routing attacks practical: (i) the efficiency of routing manipulation; and (ii) the significant centralization of Bitcoin in terms of mining and routing.
2	    Specifically, we find that any network attacker can hijack few (<100) BGP prefixes to isolate ~50% of the mining power---even when considering that mining pools are heavily multi-homed.
2	    We also show that on-path network attackers can considerably slow down block propagation by interfering with few key Bitcoin messages.
1	    We demonstrate the feasibility of each attack against the deployed Bitcoin software.
1	    We also quantify their effectiveness on the current Bitcoin topology using data collected from a Bitcoin supernode combined with BGP routing data.
1	    The potential damage to Bitcoin is worrying.
0	    By isolating parts of the network or delaying block propagation, attackers can cause a significant amount of mining power to be wasted, leading to revenue losses and enabling a wide range of exploits such as double spending.
0	    To prevent such effects in practice, we provide both short and long-term countermeasures, some of which can be deployed immediately.


# 289
### http://arxiv.org/abs/1607.00096v1
## HEAP: Reliable Assessment of BGP Hijacking Attacks


0	    The detection of BGP prefix hijacking attacks has been the focus of research for more than a decade.
0	    However, state-of-the-art techniques fall short of detecting more elaborate types of attack.
1	    To study such attacks, we devise a novel formalization of Internet routing, and apply this model to routing anomalies in order to establish a comprehensive attacker model.
1	    We use this model to precisely classify attacks and to evaluate their impact and detectability.
1	    We analyze the eligibility of attack tactics that suit an attacker's goals and demonstrate that related work mostly focuses on less impactful kinds of attacks.
1	    We further propose, implement and test the Hijacking Event Analysis Program (HEAP), a new approach to investigate hijacking alarms.
1	    Our approachis designed to seamlessly integrate with previous work in order to reduce the high rates of false alarms inherent to these techniques.
1	    We leverage several unique data sources that can reliably disprove malicious intent.
1	    First, we make use of an Internet Routing Registry to derive business or organisational relationships between the parties involved in an event.
1	    Second, we use a topology-based reasoning algorithm to rule out events caused by legitimate operational practice.
1	    Finally, we use Internet-wide network scans to identify SSL/TLS-enabled hosts, which helps to identify non-malicious events by comparing public keys prior to and during an event.
2	    In our evaluation, we prove the effectiveness of our approach, and show that day-to-day routing anomalies are harmless for the most part.
2	    More importantly, we use HEAP to assess the validity of publicly reported alarms.
1	    We invite researchers to interface with HEAP in order to cross-check and narrow down their hijacking alerts.


# 290
### http://arxiv.org/abs/1607.06884v1
## Searching for the Internet of Things on the Web: Where It Is and What It Looks Like


0	    The Internet of Things (IoT), in general, is a compelling paradigm that aims to connect everyday objects to the Internet.
1	    Nowadays, IoT is considered as one of the main technologies which contribute towards reshaping our daily lives in the next decade.
0	    IoT unlocks many exciting new opportunities in a variety of applications in research and industry domains.
0	    However, many have complained about the absence of the real-world IoT data.
0	    Unsurprisingly, a common question that arises regularly nowadays is "Does the IoT already exist?".
0	    So far, little has been known about the real-world situation on IoT, its attributes, the presentation of data and user interests.
1	    To answer this question, in this work, we conduct an in-depth analytical investigation on real IoT data.
1	    More specifically, we identify IoT data sources over the Web and develop a crawler engine to collect large-scale real-world IoT data for the first time.
1	    We make the results of our work available to the public in order to assist the community in the future research.
1	    In particular, we collect the data of nearly two million Internet connected objects and study trends in IoT using a real-world query set from an IoT search engine.
1	    Based on the collected data and our analysis, we identify the typical characteristics of IoT data.
2	    The most intriguing finding of our study is that IoT data is mainly disseminated using Web Mapping while the emerging IoT solutions such as the Web of Things, are currently not well adopted.
2	    On top of our findings, we further discuss future challenges and open research problems in the IoT area.


# 291
### http://arxiv.org/abs/1608.05308v1
## A Distributed Satisfactory Content Delivery Scheme for QoS Provisioning in Delay Tolerant Networks


0	    We deal in this paper with the content forwarding problem in Delay Tolerant Networks (DTNs).
1	    We first formulate the content delivery interaction as a non-cooperative satisfaction game.
1	    On one hand, the source node seeks to ensure a delivery probability above some given threshold.
0	    On the other hand, the relay nodes seek to maximize their own payoffs.
1	    The source node offers a reward (virtual coins) to the relay which caches and forwards the file to the final destination.
1	    Each relay faces the dilemma of accepting/rejecting to cache the source's file.
1	    Cooperation incurs energy cost due to caching, carrying and forwarding the source's file.
0	    Yet, when a relay accepts to cooperate, it may receive some reward if it succeeds to be the first relay to forward the content to the destination.
0	    Otherwise, the relay may receive some penalty in the form of a constant regret; the latter parameter is introduced to make incentive for cooperation.
1	    Next, we introduce the concept of Satisfaction Equilibrium (SE) as a solution concept to the induced game.
1	    Now, the source node is solely interested in reaching a file delivery probability greater than some given threshold, while the relays behave rationally to maximize their respective payoffs.
0	    Full characterizations of the SEs for both pure and mixed strategies are derived.
1	    Furthermore, we propose two learning algorithms allowing the players (source/relays) to reach the SE strategies.
2	    Finally, extensive numerical investigations and some learning simulations are carried out to illustrate the behaviour of the interacting nodes.


# 292
### http://arxiv.org/abs/1610.04919v1
## Power Control for Packet Streaming with Head-of-Line Deadlines


1	    We consider a mathematical model for streaming media packets (as the motivating key example) from a transmitter buffer to a receiver over a wireless link while controlling the transmitter power (hence, the packet/job processing rate).
1	    When each packet comes to the head-of-line (HOL) in the buffer, it is given a deadline $D$ which is the maximum number of times the transmitter can attempt retransmission in order to successfully transmit the packet.
1	    If this number of transmission attempts is exhausted, the packet is ejected from the buffer and the next packet comes to the HOL.
0	    Costs are incurred in each time slot for holding packets in the buffer, expending transmitter power, and ejecting packets which exceed their deadlines.
1	    We investigate how transmission power should be chosen so as to minimize the total cost of transmitting the items in the buffer.
1	    We formulate the optimal power control problem in a dynamic programming framework and then hone in on the special case of fixed interference.
2	    For this special case, we are able to provide a precise analytic characterization of how the power control should vary with the backlog and how the power control should react to approaching deadlines.
2	    In particular, we show monotonicity results for how the transmitter should adapt power levels to the backlog and approaching deadlines.
1	    We leverage these analytic results from the special case to build a power control scheme for the general case.
1	    Monte Carlo simulations are used to evaluate the performance of the resulting power control scheme as compared to the optimal scheme.
2	    The resulting power control scheme is sub-optimal but it provides a low-complexity approximation of the optimal power control.
2	    Simulations show that our proposed schemes outperform benchmark algorithms.
2	    We also discuss applications of the model to other practical operational scenarios.


# 293
### http://arxiv.org/abs/1610.05287v2
## Internet of Things Applications: Animal Monitoring with Unmanned Aerial Vehicle


0	    In animal monitoring applications, both animal detection and their movement prediction are major tasks.
0	    While a variety of animal monitoring strategies exist, most of them rely on mounting devices.
0	    However, in real world, it is difficult to find these animals and install mounting devices.
1	    In this paper, we propose an animal monitoring application by utilizing wireless sensor networks (WSNs) and unmanned aerial vehicle (UAV).
0	    The objective of the application is to detect locations of endangered species in large-scale wildlife areas and monitor movement of animals without any attached devices.
0	    In this application, sensors deployed throughout the observation area are responsible for gathering animal information.
1	    The UAV flies above the observation area and collects the information from sensors.
1	    To achieve the information efficiently, we propose a path planning approach for the UAV based on a Markov decision process (MDP) model.
1	    The UAV receives a certain amount of reward from an area if some animals are detected at that location.
1	    We solve the MDP using Q-learning such that the UAV prefers going to those areas that animals are detected before.
1	    Meanwhile, the UAV explores other areas as well to cover the entire network and detects changes in the animal positions.
1	    We first define the mathematical model underlying the animal monitoring problem in terms of the value of information (VoI) and rewards.
1	    We propose a network model including clusters of sensor nodes and a single UAV that acts as a mobile sink and visits the clusters.
1	    Then, one MDP-based path planning approach is designed to maximize the VoI while reducing message delays.
1	    The effectiveness of the proposed approach is evaluated using two real-world movement datasets of zebras and leopard.
2	    Simulation results show that our approach outperforms greedy, random heuristics and the path planning based on the traveling salesman problem.


# 294
### http://arxiv.org/abs/1611.06078v1
## Fast and reconfigurable packet classification engine in FPGA-based firewall


0	    In data communication via internet, security is becoming one of the most influential aspects.
0	    One way to support it is by classifying and filtering ethernet packets within network devices.
0	    Packet classification is a fundamental task for network devices such as routers, firewalls, and intrusion detection systems.
1	    In this paper we present architecture of fast and reconfigurable Packet Classification Engine (PCE).
1	    This engine is used in FPGA-based firewall.
1	    Our PCE inspects multi-dimensional field of packet header sequentially based on tree-based algorithm.
1	    This algorithm simplifies overall system to a lower scale and leads to a more secure system.
1	    The PCE works with an adaptation of single cycle processor architecture in the system.
1	    Ethernet packet is examined with PCE based on Source IP Address, Destination IP Address, Source Port, Destination Port, and Protocol fields of the packet header.
0	    These are basic fields to know whether it is a dangerous or normal packet before inspecting the content.
1	    Using implementation of tree-based algorithm in the architecture, firewall rules are rebuilt into 24-bit sub-rules which are read as processor instruction in the inspection process.
1	    The inspection process is comparing one sub-rule with input field of header every clock cycle.
1	    The proposed PCE shows 91 MHz clock frequency in Cyclone II EP2C70F896C6 with 13 clocks throughput average from input to output generation.
1	    The use of tree-based algorithm simplifies the multidimensional packet inspection and gives us reconfigurable as well as scalable system.
2	    The architecture is fast, reliable, and adaptable and also can maximize the advantages of the algorithm very well.
0	    Although the PCE has high frequency and little amount of clock, filtering speed of a firewall also depends on the other components, such as packet FIFO buffer.
2	    Fast and reliable FIFO buffer is needed to support the PCE.
2	    This PCE also is not completed with rule update mechanism yet.
1	    This proposed PCE is tested as a component of FPGA-based firewall to filter Ethernet packet with FPGA DE2 Board using NIOS II platform.


# 295
### http://arxiv.org/abs/1612.01593v1
## Competitive Caching of Contents in 5G Edge Cloud Networks


0	    The surge of mobile data traffic forces network operators to cope with capacity shortage.
0	    The deployment of small cells in 5G networks is meant to reduce latency, backhaul traffic and increase radio access capacity.
0	    In this context, mobile edge computing technology will be used to manage dedicated cache space in the radio access network.
1	    Thus, mobile network operators will be able to provision OTT content providers with new caching services to enhance the quality of experience of their customers on the move.
1	    In turn, the cache memory in the mobile edge network will become a shared resource.
1	    Hence, we study a competitive caching scheme where contents are stored at given price set by the mobile network operator.
1	    We first formulate a resource allocation problem for a tagged content provider seeking to minimize the expected missed cache rate.
1	    The optimal caching policy is derived accounting for popularity and availability of contents, the spatial distribution of small cells, and the caching strategies of competing content providers.
1	    It is showed to induce a specific order on contents to be cached based on their popularity and availability.
1	    Next, we study a game among content providers in the form of a generalized Kelly mechanism with bounded strategy sets and heterogeneous players.
2	    Existence and uniqueness of the Nash equilibrium are proved.
2	    Finally, extensive numerical results validate and characterize the performance of the model.


# 296
### http://arxiv.org/abs/1702.01018v1
## On Robustness in Multilayer Interdependent Network


0	    Critical Infrastructures like power and communication networks are highly interdependent on each other for their full functionality.
0	    Many significant research have been pursued to model the interdependency and failure analysis of these interdependent networks.
0	    However, most of these models fail to capture the complex interdependencies that might actually exist between the infrastructures.
1	    The \emph{Implicative Interdependency Model} that utilizes Boolean Logic to capture complex interdependencies was recently proposed which overcome the limitations of the existing models.
1	    A number of problems were studies based on this model.
1	    In this paper we study the \textit{Robustness} problem in Interdependent Power and Communication Network.
1	    The robustness is defined with respect to two parameters $K \in I^{+} \cup \{0\}$ and $\rho \in (0,1]$. We utilized the \emph{Implicative Interdependency Model} model to capture the complex interdependency between the two networks.
1	    The model classifies the interdependency relations into four cases.
1	    Computational complexity of the problem is analyzed for each of these cases.
1	    A polynomial time algorithm is designed for the first case that outputs the optimal solution.
2	    All the other cases are proved to be NP-complete.
1	    An in-approximability bound is provided for the third case.
1	    For the general case we formulate an Integer Linear Program to get the optimal solution and a polynomial time heuristic.
1	    The applicability of the heuristic is evaluated using power and communication network data of Maricopa County, Arizona.
2	    The experimental results showed that the heuristic almost always produced near optimal value of parameter $K$ for $\rho < 0.42$.


# 297
### http://arxiv.org/abs/1703.03225v1
## Anomaly Detection and Redundancy Elimination of Big Sensor Data in Internet of Things


0	    In the era of big data and Internet of things, massive sensor data are gathered with Internet of things.
0	    Quantity of data captured by sensor networks are considered to contain highly useful and valuable information.
0	    However, for a variety of reasons, received sensor data often appear abnormal.
0	    Therefore, effective anomaly detection methods are required to guarantee the quality of data collected by those sensor nodes.
0	    Since sensor data are usually correlated in time and space, not all the gathered data are valuable for further data processing and analysis.
0	    Preprocessing is necessary for eliminating the redundancy in gathered massive sensor data.
1	    In this paper, the proposed work defines a sensor data preprocessing framework.
1	    It is mainly composed of two parts, i.e., sensor data anomaly detection and sensor data redundancy elimination.
1	    In the first part, methods based on principal statistic analysis and Bayesian network is proposed for sensor data anomaly detection.
1	    Then, approaches based on static Bayesian network (SBN) and dynamic Bayesian networks (DBNs) are proposed for sensor data redundancy elimination.
0	    Static sensor data redundancy detection algorithm (SSDRDA) for eliminating redundant data in static datasets and real-time sensor data redundancy detection algorithm (RSDRDA) for eliminating redundant sensor data in real-time are proposed.
2	    The efficiency and effectiveness of the proposed methods are validated using real-world gathered sensor datasets.


# 298
### http://arxiv.org/abs/1704.07905v1
## The Role of Cloud of Things in Smart Cities


0	    The recent demographic trends indicate towards a rapidly increasing population growth and a significant portion of this increased population now prefer to live mostly in cities.
0	    In connection with this, it has become the responsibility of the government to ensure a quality standard of living in the cities and also make sure that these facilities trickle down to the next generation.
1	    A program named Smart City Mission has been started for this purpose.
2	    With an extremely diverse population, that is only second to China in the world in terms of size, the Indian government has engaged in serious thinking for a better city planning and providing numerous opportunities for the citizenry.
1	    It was, therefore, planned that the Smart City Mission program will be able to provide a highly responsive infrastructure, network security, a good living environment and the like.
0	    Internet of things (IoT) application in smart cities turns out to be the most challenging in this phase.
0	    The information available in the internet has made accessible to many devices through IoT and it also aware the citizen in many aspects.
0	    But with the increasing number of devices and information, it is now becoming increasingly difficult to depend on IoT to manage things in the internet space with a similar degree of ease.
0	    As a result, cloud-based technologies have given preferences over the existing one and IoT has been replaced by the newly introduced Cloud of Things (CoT) paradigm.
1	    This paper intends to connect different smart city applications for the betterment of city life with the Cloud of Things (CoT).
1	    Our proposed smart city architecture is based on Cloud of Things, and the focus is also given to identify the existing as well as the forthcoming challenges for the concerned program of the government.
2	    By identifying the difficulties it is expected that the project will be materialized with a great success.


# 299
### http://arxiv.org/abs/1705.00582v3
## Statistical Multiplexing and Traffic Shaping Games for Network Slicing


1	    Next generation wireless architectures are expected to enable slices of shared wireless infrastructure which are customized to specific mobile operators/services.
2	    Given infrastructure costs and the stochastic nature of mobile services' spatial loads, it is highly desirable to achieve efficient statistical multiplexing amongst such slices.
1	    We study a simple dynamic resource sharing policy which allocates a 'share' of a pool of (distributed) resources to each slice-Share Constrained Proportionally Fair (SCPF).
2	    We give a characterization of SCPF's performance gains over static slicing and general processor sharing.
2	    We show that higher gains are obtained when a slice's spatial load is more 'imbalanced' than, and/or 'orthogonal' to, the aggregate network load, and that the overall gain across slices is positive.
1	    We then address the associated dimensioning problem.
1	    Under SCPF, traditional network dimensioning translates to a coupled share dimensioning problem, which characterizes the existence of a feasible share allocation given slices' expected loads and performance requirements.
1	    We provide a solution to robust share dimensioning for SCPF-based network slicing.
1	    Slices may wish to unilaterally manage their users' performance via admission control which maximizes their carried loads subject to performance requirements.
2	    We show this can be modeled as a 'traffic shaping' game with an achievable Nash equilibrium.
2	    Under high loads, the equilibrium is explicitly characterized, as are the gains in the carried load under SCPF vs. static slicing.
1	    Detailed simulations of a wireless infrastructure supporting multiple slices with heterogeneous mobile loads show the fidelity of our models and range of validity of our high load equilibrium analysis.


# 300
### http://arxiv.org/abs/1705.00764v1
## An Authentication Protocol for Future Sensor Networks


0	    Authentication is one of the essential security services in Wireless Sensor Networks (WSNs) for ensuring secure data sessions.
0	    Sensor node authentication ensures the confidentiality and validity of data collected by the sensor node, whereas user authentication guarantees that only legitimate users can access the sensor data.
1	    In a mobile WSN, sensor and user nodes move across the network and exchange data with multiple nodes, thus experiencing the authentication process multiple times.
1	    The integration of WSNs with Internet of Things (IoT) brings forth a new kind of WSN architecture along with stricter security requirements; for instance, a sensor node or a user node may need to establish multiple concurrent secure data sessions.
1	    With concurrent data sessions, the frequency of the re-authentication process increases in proportion to the number of concurrent connections, which makes the security issue even more challenging.
1	    The currently available authentication protocols were designed for the autonomous WSN and do not account for the above requirements.
1	    In this paper, we present a novel, lightweight and efficient key exchange and authentication protocol suite called the Secure Mobile Sensor Network (SMSN) Authentication Protocol.
1	    In the SMSN a mobile node goes through an initial authentication procedure and receives a re-authentication ticket from the base station.
1	    Later a mobile node can use this re-authentication ticket when establishing multiple data exchange sessions and/or when moving across the network.
2	    This scheme reduces the communication and computational complexity of the authentication process.
1	    We proved the strength of our protocol with rigorous security analysis and simulated the SMSN and previously proposed schemes in an automated protocol verifier tool.
1	    Finally, we compared the computational complexity and communication cost against well-known authentication protocols.


# 301
### http://arxiv.org/abs/1706.00333v1
## Achieveing reliable UDP transmission at 10 Gb/s using BSD socket for data acquisition systems


0	    User Datagram Protocol (UDP) is a commonly used protocol for data transmission in small embedded systems.
0	    UDP as such is unreliable and packet losses can occur.
0	    The achievable data rates can suffer if optimal packet sizes are not used.
1	    The alternative, Transmission Control Protocol (TCP) guarantees the ordered delivery of data and automatically adjusts transmission to match the capability of the transmission link.
0	    Nevertheless UDP is often favored over TCP due to its simplicity, small memory and instruction footprints.
1	    Both UDP and TCP are implemented in all larger operating systems and commercial embedded frameworks.
1	    In addition UDP also supported on a variety of small hardware platforms such as Digital Signal Processors (DSP) Field Programmable Gate Arrays (FPGA).
0	    This is not so common for TCP.
1	    This paper describes how high speed UDP based data transmission with very low packet error ratios was achieved.
1	    The near-reliable communications link is used in a data acquisition (DAQ) system for the next generation of extremely intense neutron source, European Spallation Source.
1	    This paper presents measurements of UDP performance and reliability as achieved by employing several optimizations.
1	    The measurements were performed on Xeon E5 based CentOS (Linux) servers.
2	    The measured data rates are very close to the 10 Gb/s line rate, and zero packet loss was achieved.
2	    The performance was obtained utilizing a single processor core as transmitter and a single core as receiver.
2	    The results show that support for transmitting large data packets is a key parameter for good performance.
1	    Optimizations for throughput are: MTU, packet sizes, tuning Linux kernel parameters, thread affinity, core locality and efficient timers.


# 302
### http://arxiv.org/abs/1709.04226v1
## Slick: Secure Middleboxes using Shielded Execution


0	    Cloud computing offers the economies of scale for computational resources with the ease of management, elasticity, and fault tolerance.
0	    To take advantage of these benefits, many enterprises are contemplating to outsource the middlebox processing services in the cloud.
0	    However, middleboxes that process confidential and private data cannot be securely deployed in the untrusted environment of the cloud.
0	    To securely outsource middleboxes to the cloud, the state-of-the-art systems advocate network processing over the encrypted traffic.
0	    Unfortunately, these systems support only restrictive middlebox functionalities, and incur prohibitively high overheads due to the complex computations involved over the encrypted traffic.
1	    This motivated the design of Slick --- a secure middlebox framework for deploying high-performance Network Functions (NFs) on untrusted commodity servers.
1	    Slick exposes a generic interface based on Click to design and implement a wide-range of NFs using its out-of-the box elements and C++ extensions.
1	    Slick leverages SCONE (a shielded execution framework based on Intel SGX) and DPDK to securely process confidential data at line rate.
2	    More specifically, Slick provides hardware-assisted memory protection, and configuration and attestation service for seamless and verifiable deployment of middleboxes.
1	    We have also added several new features for commonly required functionalities: new specialized Click elements for secure packet processing, secure shared memory packet transfer for NFs chaining, secure state persistence, an efficient on-NIC timer for SGX enclaves, and memory safety against DPDK-specific Iago attacks.
2	    Furthermore, we have implemented several SGX-specific optimizations in Slick.
2	    Our evaluation shows that Slick achieves near-native throughput and latency.


# 303
### http://arxiv.org/abs/1709.08096v1
## Formal Black-Box Analysis of Routing Protocol Implementations


0	    The Internet infrastructure relies entirely on open standards for its routing protocols.
0	    However, the majority of routers on the Internet are closed-source.
0	    Hence, there is no straightforward way to analyze them.
0	    Specifically, one cannot easily identify deviations of a router's routing functionality from the routing protocol's standard.
0	    Such deviations (either deliberate or inadvertent) are particularly important to identify since they may degrade the security or resiliency of the network.
1	    A model-based testing procedure is a technique that allows to systematically generate tests based on a model of the system to be tested; thereby finding deviations in the system compared to the model.
1	    However, applying such an approach to a complex multi-party routing protocol requires a prohibitively high number of tests to cover the desired functionality.
1	    We propose efficient and practical optimizations to the model-based testing procedure that are tailored to the analysis of routing protocols.
1	    These optimizations allow to devise a formal black-box method to unearth deviations in closed-source routing protocols' implementations.
2	    The method relies only on the ability to test the targeted protocol implementation and observe its output.
2	    Identification of the deviations is fully automatic.
1	    We evaluate our method against one of the complex and widely used routing protocols on the Internet -- OSPF.
1	    We search for deviations in the OSPF implementation of Cisco.
2	    Our evaluation identified numerous significant deviations that can be abused to compromise the security of a network.
2	    The deviations were confirmed by Cisco.
1	    We further employed our method to analyze the OSPF implementation of the Quagga Routing Suite.
2	    The analysis revealed one significant deviation.
2	    Subsequent to the disclosure of the deviations some of them were also identified by IBM, Lenovo and Huawei in their own products.


# 304
### http://arxiv.org/abs/1709.08317v1
## Non-Cash Auction for Spectrum Trading in Cognitive Radio Networks: A Contract Theoretical Model with Joint Adverse Selection and Moral Hazard


0	    In cognitive radio networks (CRNs), spectrum trading is an efficient way for secondary users (SUs) to achieve dynamic spectrum access and to bring economic benefits for the primary users (PUs).
0	    Existing methods requires full payment from SU, which blocked many potential "buyers", and thus limited the PU's expected income.
1	    To better improve PUs' revenue from spectrum trading in a CRN, we introduce a financing contract, which is similar to a sealed non-cash auction that allows SU to do a financing.
1	    Unlike previous mechanism designs in CRN, the financing contract allows the SU to only pay part of the total amount when the contract is signed, known as the down payment.
1	    Then, after the spectrum is released and utilized, the SU pays the rest of payment, known as the installment payment, from the revenue generated by utilizing the spectrum.
1	    The way the financing contract carries out and the sealed non-cash auction works similarly.
1	    Thus, contract theory is employed here as the mathematical framework to solve the non-cash auction problem and form mutually beneficial relationships between PUs and SUs.
2	    As the PU may not have the full acknowledgement of the SU's financial status, nor the SU's capability in making revenue, the problems of adverse selection and moral hazard arise in the two scenarios, respectively.
1	    Therefore, a joint adverse selection and moral hazard model is considered here.
2	    In particular, we present three situations when either or both adverse selection and moral hazard are present during the trading.
2	    Furthermore, both discrete and continuous models are provided in this paper.
2	    Through extensive simulations, we show that the adverse selection and moral hazard cases serve as the upper and lower bounds of the general case where both problems are present.


# 305
### http://arxiv.org/abs/1710.03788v2
## Link Quality Aware Channel Allocation for Multichannel Body Sensor Networks


0	    Body Sensor Network (BSN) is a typical Internet-of-Things (IoT) application for personalized health care.
0	    It consists of economically powered, wireless and implanted medical monitoring sensor nodes, which are designed to continually collect the medical information of the target patients.
0	    Multichannel is often used in BSNs to reduce the spectrum competition of the tremendous sensor nodes and the problem of channel assignment has attracted much research attention.
0	    The health sensing data in BSNs is often required to be delivered to a sink node (or server) before a certain deadline for real time monitoring or health emergency alarm.
0	    Therefore, deadline is of significant importance for multichannel allocation and scheduling.
0	    The existing works, though designed to meet the deadline, often overlook the impact of the unreliable wireless links.
0	    As a result, the health sensing data can still be overdue because of the scheduled lossy links.
0	    Besides, potential collisions in the schedules also incur considerable delay in delivering the sensing data.
1	    In this paper, we propose a novel deadline- driven Link quality Aware Channel Assignment scheme (LACA), where link quality, deadlines and collisions are jointly considered.
1	    LACA prioritizes links with urgent deadlines and heavy collisions.
2	    Besides, LACA allows the exploition of the spare slots for retransmissions on lossy links, which can further reduce the retransmission delay.
2	    Extensive simulation experiments show that compared to the existing approaches, LACA can better utilize the wireless spectrum and achieve higher packet delivery ratio before the deadline.


# 306
### http://arxiv.org/abs/1712.03038v3
## Shrewd Selection Speeds Surfing: Use Smart EXP3!


1	    In this paper, we explore the use of multi-armed bandit online learning techniques to solve distributed resource selection problems.
0	    As an example, we focus on the problem of network selection.
0	    Mobile devices often have several wireless networks at their disposal.
2	    While choosing the right network is vital for good performance, a decentralized solution remains a challenge.
2	    The impressive theoretical properties of multi-armed bandit algorithms, like EXP3, suggest that it should work well for this type of problem.
0	    Yet, its real-word performance lags far behind.
0	    The main reasons are the hidden cost of switching networks and its slow rate of convergence.
1	    We propose Smart EXP3, a novel bandit-style algorithm that (a) retains the good theoretical properties of EXP3, (b) bounds the number of switches, and (c) yields significantly better performance in practice.
1	    We evaluate Smart EXP3 using simulations, controlled experiments, and real-world experiments.
2	    Results show that it stabilizes at the optimal state, achieves fairness among devices and gracefully deals with transient behaviors.
2	    In real world experiments, it can achieve 18% faster download over alternate strategies.
2	    We conclude that multi-armed bandit algorithms can play an important role in distributed resource selection problems, when practical concerns, such as switching costs and convergence time, are addressed.


# 307
### http://arxiv.org/abs/1801.01980v2
## Optimized Preference-Aware Multi-path Video Streaming with Scalable Video Coding


0	    Most client hosts are equipped with multiple network interfaces (e.g., WiFi and cellular networks).
2	    Simultaneous access of multiple interfaces can significantly improve the users' quality of experience (QoE) in video streaming.
2	    An intuitive approach to achieve it is to use Multi-path TCP (MPTCP).
0	    However, the deployment of MPTCP, especially with link preference, requires OS kernel update at both the client and server side, and a vast amount of commercial content providers do not support MPTCP.
1	    Thus, in this paper, we realize a multi-path video streaming algorithm in the application layer instead, by considering Scalable Video Coding (SVC), where each layer of every chunk can be fetched from only one of the orthogonal paths.
1	    We formulate the quality decisions of video chunks subject to the available bandwidth of the different paths, chunk deadlines, and link preferences as an optimization problem.
1	    The objective is to to optimize a QoE metric that maintains a tradeoff between maximizing the playback rate of every chunk and ensuring fairness among chunks.
1	    The QoE is a weighted some of the following metrics: skip/stall duration, average playback rate, and quality switching rate.
2	    However, the weights are chosen such that pushing more chunks to the same quality level is more preferable over any other choice.
1	    Even though the formulation is a non-convex discrete optimization, we show that the problem can be solved optimally with a polynomial complexity in some special cases.
1	    We further propose an online algorithm where several challenges including bandwidth prediction errors, are addressed.
2	    Extensive emulated experiments in a real testbed with real traces of public dataset reveal the robustness of our scheme and demonstrate its significant performance improvement compared to other multi-path algorithms.


# 308
### http://arxiv.org/abs/1801.06326v1
## Some aspects of physical prototyping in Pervasive Computing


2	    This document summarises the results of several research campaigns over the past seven years.
0	    The main connecting theme is the physical layer of widely deployed sensors in Pervasive Computing domains.
0	    In particular, we have focused on the RF-channel or on ambient audio.
1	    The initial problem from which we started this work was that of distributed adaptive transmit beamforming.
1	    We have been looking for a simple method to align the phases of jointly transmitting nodes (e.g. sensor or IoT nodes).
1	    The algorithmic solution to this problem was to implement a distributed random optimisation method on the participating nodes in which the transmitters and the receiver follow an iterative question-and-answer scheme.
1	    We have been able to derive sharp asymptotic bounds on the expected optimisation time of an evolutionary random optimiser and presented an asymptotically optimal approach.
1	    One thing that we have learned from the work on these physical layer algorithms was that the signals we work on are fragile and perceptive to physical environmental changes.
2	    These could be obstacles such as furniture, opened or closed windows or doors as well as movement of individuals.
2	    This observation motivated us to view the wireless interface as a sensor for environmental changes in Pervasive Computing environments.
0	    Another use of physical layer RF-signals is for security applications.
1	    We are currently working to further push these mentioned directions and novel fields of physical prototyping.
2	    In particular, the calculation of mathematical operations on the wireless channel at the time of transmission appears to contain good potential for gains in efficiency for communication and computation in Pervasive Computing domains.


# 309
### http://arxiv.org/abs/1801.09011v1
## Linking Received Packet to the Transmitter Through Physical-Fingerprinting of Controller Area Network


0	    The Controller Area Network (CAN) bus serves as a legacy protocol for in-vehicle data communication.
0	    Simplicity, robustness, and suitability for real-time systems are the salient features of the CAN bus protocol.
0	    However, it lacks the basic security features such as massage authentication, which makes it vulnerable to the spoofing attacks.
0	    In a CAN network, linking CAN packet to the sender node is a challenging task.
0	    This paper aims to address this issue by developing a framework to link each CAN packet to its source.
0	    Physical signal attributes of the received packet consisting of channel and node (or device) which contains specific unique artifacts are considered to achieve this goal.
0	    Material and design imperfections in the physical channel and digital device, which are the main contributing factors behind the device-channel specific unique artifacts, are leveraged to link the received electrical signal to the transmitter.
0	    Generally, the inimitable patterns of signals from each ECUs exist over the course of time that can manifest the stability of the proposed method.
1	    Uniqueness of the channel-device specific attributes are also investigated for time- and frequency-domain.
1	    Feature vector is made up of both time and frequency domain physical attributes and then employed to train a neural network-based classifier.
2	    Performance of the proposed fingerprinting method is evaluated by using a dataset collected from 16 different channels and four identical ECUs transmitting same message.
2	    Experimental results indicate that the proposed method achieves correct detection rates of 95.2% and 98.3% for channel and ECU classification, respectively.


# 310
### http://arxiv.org/abs/1802.01415v1
## Big Data Analytics for Wireless and Wired Network Design: A Survey


0	    Currently, the world is witnessing a mounting avalanche of data due to the increasing number of mobile network subscribers, Internet websites, and online services.
2	    This trend is continuing to develop in a quick and diverse manner in the form of big data.
2	    Big data analytics can process large amounts of raw data and extract useful, smaller-sized information, which can be used by different parties to make reliable decisions.
1	    In this paper, we conduct a survey on the role that big data analytics can play in the design of data communication networks.
1	    Integrating the latest advances that employ big data analytics with the networks control/traffic layers might be the best way to build robust data communication networks with refined performance and intelligent features.
1	    First, the survey starts with the introduction of the big data basic concepts, framework, and characteristics.
1	    Second, we illustrate the main network design cycle employing big data analytics.
1	    This cycle represents the umbrella concept that unifies the surveyed topics.
1	    Third, there is a detailed review of the current academic and industrial efforts toward network design using big data analytics.
1	    Forth, we identify the challenges confronting the utilization of big data analytics in network design.
2	    Finally, we highlight several future research directions.
2	    To the best of our knowledge, this is the first survey that addresses the use of big data analytics techniques for the design of a broad range of networks.


# 311
### http://arxiv.org/abs/1803.03622v2
## Virtual Network Embedding Approximations: Leveraging Randomized Rounding


0	    The Virtual Network Embedding Problem (VNEP) captures the essence of many resource allocation problems of today's infrastructure providers, which offer their physical computation and networking resources to customers.
0	    Customers request resources in the form of Virtual Networks, i.e. as a directed graph which specifies computational requirements at the nodes and communication requirements on the edges.
1	    An embedding of a Virtual Network on the shared physical infrastructure is the joint mapping of (virtual) nodes to physical servers together with the mapping of (virtual) edges onto paths in the physical network connecting the respective servers.
1	    This work initiates the study of approximation algorithms for the VNEP.
1	    Concretely, we study the offline setting with admission control: given multiple request graphs the task is to embed the most profitable subset while not exceeding resource capacities.
1	    Our approximation is based on the randomized rounding of Linear Programming (LP) solutions.
2	    Interestingly, we uncover that the standard LP formulation for the VNEP exhibits an inherent structural deficit when considering general virtual network topologies: its solutions cannot be decomposed into valid embeddings.
1	    In turn, focusing on the class of cactus request graphs, we devise a novel LP formulation, whose solutions can be decomposed into convex combinations of valid embedding.
1	    Proving performance guarantees of our rounding scheme, we obtain the first approximation algorithm for the VNEP in the resource augmentation model.
1	    We propose two types of rounding heuristics and evaluate their performance in an extensive computational study.
2	    Our results indicate that randomized rounding can yield good solutions (even without augmentations).
2	    Specifically, heuristic rounding achieves 73.8% of the baseline's profit, while not exceeding capacities.


# 312
### http://arxiv.org/abs/1803.04452v1
## (FPT-)Approximation Algorithms for the Virtual Network Embedding Problem


1	    Many resource allocation problems in the cloud can be described as a basic Virtual Network Embedding Problem (VNEP): finding mappings of request graphs (describing the workloads) onto a substrate graph (describing the physical infrastructure).
1	    In the offline setting, the two natural objectives are profit maximization, i.e., embedding a maximal number of request graphs subject to the resource constraints, and cost minimization, i.e., embedding all requests at minimal overall cost.
1	    The VNEP can be seen as a generalization of classic routing and call admission problems, in which requests are arbitrary graphs whose communication endpoints are not fixed.
0	    Due to its applications, the problem has been studied intensively in the networking community.
0	    However, the underlying algorithmic problem is hardly understood.
1	    This paper presents the first fixed-parameter tractable approximation algorithms for the VNEP.
1	    Our algorithms are based on randomized rounding.
1	    Due to the flexible mapping options and the arbitrary request graph topologies, we show that a novel linear program formulation is required.
2	    Only using this novel formulation the computation of convex combinations of valid mappings is enabled, as the formulation needs to account for the structure of the request graphs.
1	    Accordingly, to capture the structure of request graphs, we introduce the graph-theoretic notion of extraction orders and extraction width and show that our algorithms have exponential runtime in the request graphs' maximal width.
1	    Hence, for request graphs of fixed extraction width, we obtain the first polynomial-time approximations.
1	    Studying the new notion of extraction orders we show that (i) computing extraction orders of minimal width is NP-hard and (ii) that computing decomposable LP solutions is in general NP-hard, even when restricting request graphs to planar ones.


# 313
### http://arxiv.org/abs/1804.03986v1
## Dynamic Sensor Subset Selection for Centralized Tracking a Time-Varying Stochastic Process


0	    Motivated by the Internet-of-things and sensor networks for cyberphysical systems, the problem of dynamic sensor activation for the centralized tracking of an i.i.d.
1	    The tradeoff is between energy efficiency, which decreases with the number of active sensors, and fidelity, which increases with the number of active sensors.
1	    The problem of minimizing the time-averaged mean-squared error over infinite horizon is examined under the constraint of the mean number of active sensors.
1	    The proposed methods artfully combine Gibbs sampling and stochastic approximation for learning, in order to create a high performance, energy efficient tracking mechanisms with active sensor selection.
1	    Centralized tracking of i.i.d.
1	    process with known distribution as well as an unknown parametric distribution are considered.
0	    For an i.i.d.
1	    process with known distribution, convergence to the global optimal solution with high probability is proved.
2	    The main challenge of the i.i.d.
1	    case is that the process has a distribution parameterized by a known or unknown parameter which must be learned; one key theoretical result proves that the proposed algorithm for tracking an i.i.d.
1	    process with unknown parametric distribution converges to local optima.
2	    Numerical results show the efficacy of the proposed algorithms and also suggest that global optimality is in fact achieved in some cases.


# 314
### http://arxiv.org/abs/1804.04794v2
## EMPIOT: An Energy Measurement Platform for Wireless IoT Devices


0	    Profiling and minimizing the energy consumption of resource-constrained devices is an essential step towards employing IoT in various application domains.
0	    Due to the large size and high cost of commercial energy measurement platforms, alternative solutions have been proposed by the research community.
0	    However, the three main shortcomings of existing tools are complexity, limited measurement range, and low accuracy.
2	    Specifically, these tools are not suitable for the energy measurement of new IoT devices such as those supporting the 802.11 technology.
1	    In this paper we propose EMPIOT, an accurate, low-cost, easy to build, and flexible power measurement platform.
1	    We present the hardware and software components of this platform and study the effect of various design parameters on accuracy and overhead.
1	    In particular, we analyze the effects of driver, bus speed, input voltage, and buffering mechanism on sampling rate, measurement accuracy and processing demand.
2	    These extensive experimental studies enable us to configure the system in order to achieve its highest performance.
1	    We also propose a novel calibration technique and report the calibration parameters under various settings.
1	    Using five different IoT devices performing four types of workloads, we evaluate the performance of EMPIOT against the ground truth obtained from a high-accuracy industrial-grade power measurement tool.
2	    Our results show that, for very low-power devices that utilize 802.15.4 wireless standard, the measurement error is less than 3.5%.
2	    In addition, for 802.11-based devices that generate short and high power spikes, the error is less than 2.5%.


# 315
### http://arxiv.org/abs/1804.06733v2
## NHAD: Neuro-Fuzzy Based Horizontal Anomaly Detection In Online Social Networks


0	    Use of social network is the basic functionality of today's life.
0	    With the advent of more and more online social media, the information available and its utilization have come under the threat of several anomalies.
1	    Anomalies are the major cause of online frauds which allow information access by unauthorized users as well as information forging.
1	    One of the anomalies that act as a silent attacker is the horizontal anomaly.
2	    These are the anomalies caused by a user because of his/her variable behaviour towards different sources.
0	    Horizontal anomalies are difficult to detect and hazardous for any network.
1	    In this paper, a self-healing neuro-fuzzy approach (NHAD) is used for the detection, recovery, and removal of horizontal anomalies efficiently and accurately.
2	    The proposed approach operates over the five paradigms, namely, missing links, reputation gain, significant difference, trust properties, and trust score.
2	    The proposed approach is evaluated with three datasets: DARPA'98 benchmark dataset, synthetic dataset, and real-time traffic.
2	    Results show that the accuracy of the proposed NHAD model for 10% to 30% anomalies in synthetic dataset ranges between 98.08% and 99.88%.
2	    The evaluation over DARPA'98 dataset demonstrates that the proposed approach is better than the existing solutions as it provides 99.97% detection rate for anomalous class.
2	    For real-time traffic, the proposed NHAD model operates with an average accuracy of 99.42% at 99.90% detection rate.


# 316
### http://arxiv.org/abs/1805.05026v1
## A Systematic Approach to Constructing Families of Incremental Topology Control Algorithms Using Graph Transformation


0	    In the communication systems domain, constructing and maintaining network topologies via topology control (TC) algorithms is an important cross-cutting research area.
0	    Network topologies are usually modeled using attributed graphs whose nodes and edges represent the network nodes and their interconnecting links.
1	    A key requirement of TC algorithms is to fulfill certain consistency and optimization properties to ensure a high quality of service.
1	    Still, few attempts have been made to constructively integrate these properties into the development process of TC algorithms.
2	    Furthermore, even though many TC algorithms share substantial parts (such as structural patterns or tie-breaking strategies), few works constructively leverage these commonalities and differences of TC algorithms systematically.
1	    In previous work, we addressed the constructive integration of consistency properties into the development process.
1	    We outlined a constructive, model-driven methodology for designing individual TC algorithms.
1	    Valid and high-quality topologies are characterized using declarative graph constraints; TC algorithms are specified using programmed graph transformation.
1	    We applied a well-known static analysis technique to refine a given TC algorithm in a way that the resulting algorithm preserves the specified graph constraints.
1	    In this paper, we extend our constructive methodology by generalizing it to support the specification of families of TC algorithms.
1	    To show the feasibility of our approach, we reneging six existing TC algorithms and develop e-kTC, a novel energy-efficient variant of the TC algorithm kTC.
1	    Finally, we evaluate a subset of the specified TC algorithms using a new tool integration of the graph transformation tool eMoflon and the Simonstrator network simulation framework.


# 317
### http://arxiv.org/abs/1805.08429v3
## Correctness and Fairness of Tendermint-core Blockchains


0	    Tendermint-core blockchains (e.g. Cosmos) are considered today one of the most viable alternatives for the highly energy consuming proof-of-work blockchains such as Bitcoin and Ethereum.
1	    Their particularity is that they aim at offering strong consistency (no forks) in an open system combining two ingredients (i) a set of validators that generate blocks via a variant of Practical Byzantine Fault Tolerant (PBFT) consensus protocol and (ii) a selection strategy that dynamically selects nodes to be validators for the next block via a proof-of-stake mechanism.
1	    However,the exact assumptions on the system model under which Tendermint underlying algorithms are correct and the exact properties Tendermint verifies have never been formally analyzed.
1	    The contribution of this paper is two-fold.
1	    First, while formalizing Tendermint algorithms we precisely characterize the system model and the exact problem solved by Tendermint.
1	    We prove that in eventual synchronous systems a modified version of Tendermint solves (i) under additional assumptions, a variant of one-shot consensus for the validation of one single block and (ii) a variant of the repeated consensus problem for multiple blocks.
2	    These results hold even if the set of validators is hit by Byzantine failures, provided that for each one-shot consensus instance less than one third of the validators is Byzantine.
1	    Our second contribution relates to the fairness of the rewarding mechanism.
1	    It is common knowledge that in permisionless blockchain systems the main threat is the tragedy of commons that may yield the system to collapse if the rewarding mechanism is not adequate.
2	    Ad minimum the rewarding mechanism must be fair, i.e.distributing the rewards in proportion to the merit of participants.
2	    We prove, for the first time in blockchain systems, that in repeated-consensus based blockchains there exists an (eventual) fair rewarding mechanism if and only if the system is (eventual) synchronous.
2	    We also show that the original Tendermint rewarding is not fair, however, a modification of the original protocol makes it eventually fair.


# 318
### http://arxiv.org/abs/1805.09246v1
## Memory efficient distributed sliding super point cardinality estimation by GPU


0	    Super point is a kind of special host in the network which contacts with huge of other hosts.
1	    Estimating its cardinality, the number of other hosts contacting with it, plays important roles in network management.
1	    But all of existing works focus on discrete time window super point cardinality estimation which has great latency and ignores many measuring periods.
2	    Sliding time window measures super point cardinality in a finer granularity than that of discrete time window but also more complex.
1	    This paper firstly introduces an algorithm to estimate super point cardinality under sliding time window from distributed edge routers.
1	    This algorithm's ability of sliding super point cardinality estimating comes from a novel method proposed in this paper which can record the time that a host appears.
1	    Based on this method, two sliding cardinality estimators, sliding rough estimator and sliding linear estimator, are devised for super points detection and their cardinalities estimation separately.
2	    When using these two estimators together, the algorithm consumes the smallest memory with the highest accuracy.
1	    This sliding super point cardinality algorithm can be deployed in distributed environment and acquire the global super points' cardinality by merging estimators of distributed nodes.
2	    Both of these estimators could process packets parallel which makes it becom possible to deal with high speed network in real time by GPU.
2	    Experiments on a real world traffic show that this algorithm have the highest accuracy and the smallest memory comparing with others when running under discrete time window.
2	    Under sliding time window, this algorithm also has the same performance as under discrete time window.


# 319
### http://arxiv.org/abs/1806.06507v1
## A Hierarchical Approach to Encrypted Data Packet Classification in Smart Home Gateways


0	    With the pervasive network based services in smart homes, traditional network management cannot guarantee end-user quality-of-experience (QoE) for all applications.
0	    End-user QoE must be supported by efficient network quality-of-service (QoS) measurement and efficient network resource allocation.
2	    With the software-defined network technology, the core network may be controlled more efficiently by a network service provider.
0	    However, end-to-end network QoS can hardly be improved the managing the core network only.
1	    In this paper, we propose an encrypted packet classification scheme for smart home gateways to improve end-to-end QoS measurement from the network operator side.
2	    Furthermore, other services such as statistical data collecting, billing to service providers, etc.,
2	    can be provided without compromising end-user privacy nor security of a network.
2	    The proposed encrypted packet classification scheme has a two-level hierarchical structure.
1	    One is the service level, which is based on applications that have the same network QoS requirements.
1	    A faster classification scheme based on deep learning is proposed to achieve real-time classification with high accuracy.
1	    The other one is the application level, which is based on fine-grained applications.
1	    A non-real-time classifier can be applied to provide high accuracy.
2	    Evaluation is conducted on both level classifiers to demonstrate the efficiency and accuracy of the two types of classifiers.


# 320
### http://arxiv.org/abs/1807.08426v1
## Context-aware Group Buying in Ultra-dense Small Cell Networks: Unity is Strength


0	    The ultra-dense small cell networks (SCNs) have been regarded as a promising technology to solve the data traffic explosion in future.
0	    However, the complicated relationships among large scale users and cells practically demand a cooperative grouping mechanism to account for the shortage of resources in SCNs.
1	    Then, a group buying market mechanism provides a win-win situation and an effective resource allocation in the view of economics.
2	    With additional decision information being provided, the context awareness enhances and improves the group buying mechanism.
1	    In this article, we propose a Context-Aware Group Buying (CAGB) mechanism to allocate the resources in ultra-dense SCNs.
1	    The feasibility, necessity, and effectiveness of CAGB are analyzed first.
1	    Then, we introduce the group buying mechanism and some common context awareness.
1	    The relationship between context awareness and group buying is also analyzed.
0	    Some important technologies in SCNs are discussed in the view of CAGB, such as load balancing, spectrum management, and cooperative caching.
1	    Then, the graphical coalition formation games (CFGs) of CAGB are also presented to match the complicated network topologies in SCNs.
1	    Two CAGB-based use cases about spectrum market and cooperative caching are presented.
2	    Finally, future research issues about context awareness, grouping mechanism, and buying mechanism are discussed.


# 321
### http://arxiv.org/abs/1807.10528v1
## An experiment in distributed Internet address management using blockchains


0	    The current system to manage the global pool of IP addresses is centralized in five transnational organizations, the Regional Internet Registries (RIRs).
1	    Each of these RIRs manage the address pool for a large number of countries.
1	    Because the RIRs are private organizations, they are subject to the legal framework of the country where they are based.
1	    This configuration results in a jurisdictional overflow from the legal framework of the countries where the RIR is based to all the countries that the RIRs are serving (the countries served by the RIRs de facto become subjects of the legal system of the country where the RIR is hosted).
0	    The situation is aggravated by the deployment of new security techniques such as the RPKI and BGPsec, that enable enforcement of allocations by the RIRs.
0	    In this paper we present InBlock, a blockchain-based distributed governance body aimed to provide de-centralized management of IP addresses.
1	    InBlock also aims to fulfil the same objectives as the current IP address allocation system, namely, uniqueness, fairness, conservation, aggregation, registration and minimized overhead.
1	    InBlock is implemented as a Decentralized Autonomous Organization, i.e., as a set of blockchain's smart contracts in Ethereum.
1	    Any entity may request an allocation of addresses to the InBlock registry by solely performing a (crypto)currency transfer to the InBlock.
2	    The fee required, along with the annual renewal fee, serves as a mechanism to deter stockpiling and other wasteful practices.
1	    As with any novel technology, there are many open questions about the usage of blockchains to build an IP address registry.
0	    For this reason, we believe that practical experimentation is required in order to have hands-on experiences about such a system.
1	    We propose to conduct an experiment on distributed address management using InBlock as a starting point to inform future directions in this area.


# 322
### http://arxiv.org/abs/1808.01039v2
## An Energy Efficient Routing Protocol for Wireless Internet-of-Things Sensor Networks


0	    Internet of Things (IoT) are increasingly being adopted into practical applications such as security systems, smart infrastructure, traffic management, weather systems, among others.
0	    While the scale of these applications is enormous, device capabilities, particularly in terms of battery life and energy efficiency are limited.
0	    Despite research being done to ameliorate these shortcomings, wireless IoT networks still cannot guarantee satisfactory network lifetimes and prolonged sensing coverage.
0	    Moreover, proposed schemes in literature are convoluted and cannot be easily implemented in real-world scenarios.
0	    This necessitates the development of a simple yet energy efficient routing scheme for wireless IoT sensor networks.
0	    This paper models the energy constraint problem of devices in IoT applications as an optimization problem.
1	    To conserve the energy of device nodes, the routing protocol first aggregates devices into clusters based on a number of different features such as distance from base station, data/message length and data sensed from the environment in the current epoch.
1	    Then, a cluster head is elected for each cluster and a directed acyclic graph (DAG) is generated with all the cluster heads as nodes.
1	    Edges represent communication intent from transmitter to receiver and the edge weights are computed using a formulated equation.
1	    The minimum cost path to the base station is computed to allow for efficient real-time routing.
1	    Sleep scheduling is also optionally used to further boost network energy efficiency.
1	    The proposed routing protocol has been simulated and outperforms existing routing protocols in terms of metrics such as number of active nodes, energy dynamics and network coverage.


# 323
### http://arxiv.org/abs/1808.06175v1
## Sharing within limits: Partial resource pooling in loss systems


0	    Fragmentation of expensive resources, e.g., spectrum for wireless services, between providers can introduce inefficiencies in resource utilisation and worsen overall system performance.
0	    In such cases, resource pooling between independent service providers can be used to improve performance.
0	    However, for providers to agree to pool their resources, the arrangement has to be mutually beneficial.
0	    The traditional notion of resource pooling, which implies complete sharing, need not have this property.
0	    For example, under full pooling, one of the providers may be worse off and hence have no incentive to participate.
1	    In this paper, we propose partial resource sharing models as a generalization of full pooling, which can be configured to be beneficial to all participants.
1	    We formally define and analyze two partial sharing models between two service providers, each of which is an Erlang-B loss system with the blocking probabilities as the performance measure.
2	    We show that there always exist partial sharing configurations that are beneficial to both providers, irrespective of the load and the number of circuits of each of the providers.
2	    A key result is that the Pareto frontier has at least one of the providers sharing all its resources with the other.
0	    Furthermore, full pooling may not lie inside this Pareto set.
1	    The choice of the sharing configurations within the Pareto set is formalized based on bargaining theory.
2	    Finally, large system approximations of the blocking probabilities in the quality-efficiency-driven regime are presented.


# 324
### http://arxiv.org/abs/1808.06254v1
## SABRE: Protecting Bitcoin against Routing Attacks


0	    Routing attacks remain practically effective in the Internet today as existing countermeasures either fail to provide protection guarantees or are not easily deployable.
0	    Blockchain systems are particularly vulnerable to such attacks as they rely on Internet-wide communication to reach consensus.
1	    In particular, Bitcoin -the most widely-used cryptocurrency- can be split in half by any AS-level adversary using BGP hijacking.
1	    In this paper, we present SABRE, a secure and scalable Bitcoin relay network which relays blocks worldwide through a set of connections that are resilient to routing attacks.
0	    SABRE runs alongside the existing peer-to-peer network and is easily deployable.
1	    As a critical system, SABRE design is highly resilient and can efficiently handle high bandwidth loads, including Denial of Service attacks.
1	    We built SABRE around two key technical insights.
1	    First, we leverage fundamental properties of inter-domain routing (BGP) policies to host relay nodes: (i) in locations that are inherently protected against routing attacks; and (ii) on paths that are economically preferred by the majority of Bitcoin clients.
0	    These properties are generic and can be used to protect other Blockchain-based systems.
1	    Second, we leverage the fact that relaying blocks is communication-heavy, not computation-heavy.
1	    This enables us to offload most of the relay operations to programmable network hardware (using the P4 programming language).
1	    Thanks to this hardware/software co-design, SABRE nodes operate seamlessly under high load while mitigating the effects of malicious clients.
1	    We present a complete implementation of SABRE together with an extensive evaluation.
2	    Our results demonstrate that SABRE is effective at securing Bitcoin against routing attacks, even with deployments as small as 6 nodes.


# 325
### http://arxiv.org/abs/1809.01896v1
## Efficient Loop Detection in Forwarding Networks and Representing Atoms in a Field of Sets


0	    The problem of detecting loops in a forwarding network is known to be NP-complete when general rules such as wildcard expressions are used.
0	    Yet, network analyzer tools such as Netplumber (Kazemian et al.,
1	    NSDI'13) or Veriflow (Khurshid et al.,
0	    NSDI'13) efficiently solve this problem in networks with thousands of forwarding rules.
1	    In this paper, we complement such experimental validation of practical heuristics with the first provably efficient algorithm in the context of general rules.
1	    Our main tool is a canonical representation of the atoms (i.e. the minimal non-empty sets) of the field of sets generated by a collection of sets.
2	    This tool is particularly suited when the intersection of two sets can be efficiently computed and represented.
1	    In the case of forwarding networks, each forwarding rule is associated with the set of packet headers it matches.
1	    The atoms then correspond to classes of headers with same behavior in the network.
1	    We propose an algorithm for atom computation and provide the first polynomial time algorithm for loop detection in terms of number of classes (which can be exponential in general).
1	    This contrasts with previous methods that can be exponential, even in simple cases with linear number of classes.
1	    Second, we introduce a notion of network dimension captured by the overlapping degree of forwarding rules.
1	    The values of this measure appear to be very low in practice and constant overlapping degree ensures polynomial number of header classes.
2	    Forwarding loop detection is thus polynomial in forwarding networks with constant overlapping degree.


# 326
### http://arxiv.org/abs/1810.03162v1
## Competitive Online Virtual Cluster Embedding Algorithms


0	    In the conventional cloud service model, computing resources are allocated for tenants on a pay-per-use basis.
0	    However, the performance of applications that communicate inside this network is unpredictable because network resources are not guaranteed.
1	    To mitigate this issue, the virtual cluster (VC) model has been developed in which network and compute units are guaranteed.
1	    Thereon, many algorithms have been developed that are based on novel extensions of the VC model in order to solve the online virtual cluster embedding problem (VCE) with additional parameters.
1	    In the online VCE, the resource footprint is greedily minimized per request which is connected with maximizing the profit for the provider per request.
2	    However, this does not imply that a global maximization of the profit over the whole sequence of requests is guaranteed.
2	    In fact, these algorithms do not even provide a worst case guarantee on a fraction of the maximum achievable profit of a certain sequence of requests.
2	    Thus, these online algorithms do not provide a competitive ratio on the profit.
1	    In this thesis, two competitive online VCE algorithms and two heuristic algorithms are presented.
1	    The competitive online VCE algorithms have different competitive ratios on the objective function and the capacity constraints whereas the heuristic algorithms do not violate the capacity constraints.
1	    The worst case competitive ratios are analyzed.
1	    After that, the evaluation shows the advantages and disadvantages of these algorithms in several scenarios with different request patterns and profit metrics on the fat-tree and MDCube datacenter topologies.
2	    The results show that for different scenarios, different algorithms have the best performance with respect to certain metrics.


# 327
### http://arxiv.org/abs/1810.09843v1
## Blockchain-based Supply Chain Traceability: Token Recipes model Manufacturing Processes


0	    Growing consumer awareness as well as manufacturers' internal quality requirements lead to novel demands on supply chain traceability.
0	    Existing centralized solutions suffer from isolated data storage and lacking trust when multiple parties are involved.
0	    Decentralized blockchain-based approaches attempt to overcome these shortcomings by creating digital representations of physical goods to facilitate tracking across multiple entities.
0	    However, they currently do not capture the transformation of goods in manufacturing processes.
0	    Therefore, the relation between ingredients and product is lost, limiting the ability to trace a product's provenance.
1	    We propose a blockchain-based supply chain traceability system using smart contracts.
0	    In such contracts, manufacturers define the composition of products in the form of recipes.
1	    Each ingredient of the recipe is a non-fungible token that corresponds to a batch of physical goods.
1	    When the recipe is applied, its ingredients are consumed and a new token is produced.
2	    This mechanism preserves the traceability of product transformations.
1	    The system is implemented for the Ethereum Virtual Machine and is applicable to any blockchain configuration that supports it.
2	    Our evaluation reveals that the gas costs scale linearly with the number of products considered in the system.
2	    This leads to the conclusion that the solution can handle complex use cases.


# 328
### http://arxiv.org/abs/1810.13132v1
## Cardinalities estimation under sliding time window by sharing HyperLogLog Counter


0	    Cardinalities estimation is an important research topic in network management and security.
0	    How to solve this problem under sliding time window is a hot topic.
0	    HyperLogLog is a memory efficient algorithm work under a fixed time window.
1	    A sliding version of HyperLogLog can work under sliding time window by replacing every counter of HyperLogLog with a list of feature possible maxim (LFPM).
1	    But LFPM is a dynamic structure whose size is variable at running time.
1	    This paper proposes a novel counter for HyperLogLog which consumes smaller size of memory than that of LFPM.
1	    Our counter is called bit distance recorder BDR, because it maintains the distance of every left most "1" bit position.
1	    The size of BDR is fixed.
1	    Based on BDR, we design a multi hosts' cardinalities estimation algorithm under sliding time window, virtual bit distance recorder VBDR.
1	    VBDR allocate a virtual vector of BDR for every host and every physical BDR is shared by several hosts to improve the memory usage.
1	    After a small modifcation, we propose another two parallel versions of VBDR which can run on GPU to handle high speed traffic.
1	    One of these parallel VBDR is fast in IP pair scanning and the other one is memory efficient.
1	    BDR is also suitable for other cardinality estimation algorithms such as PCSA, LogLog.


# 329
### http://arxiv.org/abs/1811.02367v1
## Scalable Application- and User-aware Resource Allocation in Enterprise Networks Using End-host Pacing


0	    Scalable user- and application-aware resource allocation for heterogeneous applications sharing an enterprise network is still an unresolved problem.
0	    The main challenges are: (i) How to define user- and application-aware shares of resources? (
0	    ii) How to determine an allocation of shares of network resources to applications? (
0	    iii) How to allocate the shares per application in heterogeneous networks at scale?
1	    In this paper we propose solutions to the three challenges and introduce a system design for enterprise deployment.
1	    Defining the necessary resource shares per application is hard, as the intended use case and user's preferences influence the resource demand.
1	    Utility functions based on user experience enable a mapping of network resources in terms of throughput and latency budget to a common user-level utility scale.
1	    A multi-objective MILP is formulated to solve the throughput- and delay-aware embedding of each utility function for a max-min fairness criteria.
0	    The allocation of resources in traditional networks with policing and scheduling cannot distinguish large numbers of classes.
1	    We propose a resource allocation system design for enterprise networks based on Software-Defined Networking principles to achieve delay-constrained routing in the network and application pacing at the end-hosts.
1	    The system design is evaluated against best effort networks with applications competing for the throughput of a constrained link.
1	    The competing applications belong to the five application classes web browsing, file download, remote terminal work, video streaming, and Voice-over-IP.
2	    The results show that the proposed methodology improves the minimum and total utility, minimizes packet loss and queuing delay at bottlenecks, establishes fairness in terms of utility between applications, and achieves predictable application performance at high link utilization.


# 330
### http://arxiv.org/abs/1811.08954v1
## Fuzzy Rule Interpolation and SNMP-MIB for Emerging Network Abnormality


0	    It is difficult to implement an efficient detection approach for Intrusion Detection Systems (IDS) and many factors contribute to this challenge.
0	    One such challenge concerns establishing adequate boundaries and finding a proper data source.
0	    Typical IDS detection approaches deal with raw traffics.
0	    These traffics need to be studied in depth and thoroughly investigated in order to extract the required knowledge base.
0	    Another challenge involves implementing the binary decision.
0	    This is because there are no reasonable limits between normal and attack traffics patterns.
1	    In this paper, we introduce a novel idea capable of supporting the proper data source while avoiding the issues associated with the binary decision.
1	    This paper aims to introduce a detection approach for defining abnormality by using the Fuzzy Rule Interpolation (FRI) with Simple Network Management Protocol (SNMP) Management Information Base (MIB) parameters.
1	    The strength of the proposed detection approach is based on adapting the SNMP-MIB parameters with the FRI.
2	    This proposed method eliminates the raw traffic processing component which is time consuming and requires extensive computational measures.
1	    It also eliminates the need for a complete fuzzy rule based intrusion definition.
1	    The proposed approach was tested and evaluated using an open source SNMP-MIB dataset and obtained a 93% detection rate.
1	    Additionally, when compared to other literature in which the same test-bed environment was employed along with the same number of parameters, the proposed detection approach outperformed the support vector machine and neural network.
0	    Therefore, combining the SNMP-MIB parameters with the FRI based reasoning could be beneficial for detecting intrusions, even in the case if the fuzzy rule based intrusion definition is incomplete (not fully defined).


# 331
### http://arxiv.org/abs/1812.01126v1
## Wideband Full-Duplex Wireless via Frequency-Domain Equalization: Design and Experimentation


0	    Full-duplex (FD) wireless can significantly enhance spectrum efficiency but requires tremendous amount of self-interference (SI) cancellation.
1	    Recent advances in the RFIC community enabled wideband RF SI cancellation (SIC) in integrated circuits (ICs) via frequency-domain equalization (FDE), where RF filters channelize the SI signal path.
0	    Unlike other FD implementations, that mostly rely on delay lines, FDE-based cancellers can be realized in small-form-factor devices.
0	    However, the fundamental limits and higher layer challenges associated with these cancellers were not explored yet.
1	    Therefore, and in order to support the integration with a software-defined radio (SDR) and to facilitate experimentation in a testbed with several nodes, we design and implement an FDE-based RF canceller on a printed circuit board (PCB).
1	    We derive and experimentally validate the PCB canceller model and present a canceller configuration scheme based on an optimization problem.
1	    We then extensively evaluate the performance of the FDE-based FD radio in the SDR testbed.
2	    Experiments show that it achieves 95dB overall SIC (52dB from RF SIC) across 20MHz bandwidth, and an average link-level FD gain of 1.87x.
2	    We also conduct experiments in: (i) uplink-downlink networks with inter-user interference, and (ii) heterogeneous networks with half-duplex and FD users.
2	    The experimental FD gains in the two types of networks confirm previous analytical results.
2	    They depend on the users' SNR values and the number of FD users, and are 1.14x1.25x and 1.25x1.73x, respectively.
1	    Finally, we numerically evaluate and compare the RFIC and PCB implementations and study various design tradeoffs.


# 332
### http://arxiv.org/abs/1901.00204v1
## Augmentation Scheme for Dealing with Imbalanced Network Traffic Classification Using Deep Learning


0	    One of the most important tasks in network management is identifying different types of traffic flows.
0	    As a result, a type of management service, called Network Traffic Classifier (NTC), has been introduced.
0	    One type of NTCs that has gained huge attention in recent years applies deep learning on packets in order to classify flows.
0	    Internet is an imbalanced environment i.e., some classes of applications are a lot more populated than others e.g., HTTP.
2	    Additionally, one of the challenges in deep learning methods is that they do not perform well in imbalanced environments in terms of evaluation metrics such as precision, recall, and $\mathrm{F_1}$ measure.
2	    In order to solve this problem, we recommend the use of augmentation methods to balance the dataset.
1	    In this paper, we propose a novel data augmentation approach based on the use of Long Short Term Memory (LSTM) networks for generating traffic flow patterns and Kernel Density Estimation (KDE) for replicating the numerical features of each class.
1	    First, we use the LSTM network in order to learn and generate the sequence of packets in a flow for classes with less population.
1	    Then, we complete the features of the sequence with generating random values based on the distribution of a certain feature, which will be estimated using KDE.
1	    Finally, we compare the training of a Convolutional Recurrent Neural Network (CRNN) in large-scale imbalanced, sampled, and augmented datasets.
1	    The contribution of our augmentation scheme is then evaluated on all of the datasets through measurements of precision, recall, and F1 measure for every class of application.
2	    The results demonstrate that our scheme is well suited for network traffic flow datasets and improves the performance of deep learning algorithms when it comes to above-mentioned metrics.


# 333
### http://arxiv.org/abs/1901.05741v1
## RepChain: A Reputation based Secure, Fast and High Incentive Blockchain System via Sharding


1	    In today's blockchain system, designing a secure and high throughput on par with centralized payment system is a difficulty task.
0	    Sharding is one of the most worth expecting technologies to improve the system throughput when maintain high security level.
0	    However, the previous works have two main limitations: Firstly, the throughput of their random-based sharding system is not high enough due to not leveraging the heterogeneity among validators.
0	    Secondly, the incentive mechanism can be a huge overhead on their system without an appropriate scheme.
1	    We propose RepChain, a reputation-based secure, high incentive and fast blockchain system via sharding.
1	    RepChain utilizes reputation to explicitly characterize the heterogeneity among the validators and lay the foundation for the incentive mechanism.
1	    We novelly propose the double-chain architecture that including transaction chain and reputation chain.
1	    For transaction chain, a Raft-based Byzantine fault tolerant synchronous consensus with high resiliency and high throughput has been presented.
1	    For reputation chain, the collective signing has been utilized to achieve consensus on the reputation score and support the high throughput transaction chain with moderate generation speed.
1	    Moreover, we propose a reputation based sharding and leader selection scheme.
1	    To analyze the security of RepChain, we propose a recursive formula to calculate the epoch security within only O(km^2) time.
1	    Further more, we implement and evaluate RepChain on Amazon Web Service platform.
2	    The results show our solution can enhance both throughout and security level of the existing sharding-based blockchain system.


# 334
### http://arxiv.org/abs/1901.07768v1
## Cooperation Speeds Surfing: Use Co-Bandit!


0	    In this paper, we explore the benefit of cooperation in adversarial bandit settings.
0	    As a motivating example, we consider the problem of wireless network selection.
0	    Mobile devices are often required to choose the right network to associate with for optimal performance, which is non-trivial.
2	    The excellent theoretical properties of EXP3, a leading multi-armed bandit algorithm, suggest that it should work well for this type of problem.
0	    Yet, it performs poorly in practice.
0	    A major limitation is its slow rate of stabilization.
1	    Bandit-style algorithms perform better when global knowledge is available, i.e., when devices receive feedback about all networks after each selection.
0	    But, unfortunately, communicating full information to all devices is expensive.
0	    Therefore, we address the question of how much information is adequate to achieve better performance.
1	    We propose Co-Bandit, a novel cooperative bandit approach, that allows devices to occasionally share their observations and forward feedback received from neighbors; hence, feedback may be received with a delay.
1	    Devices perform network selection based on their own observation and feedback from neighbors.
1	    As such, they speed up each other's rate of learning.
2	    We prove that Co-Bandit is regret-minimizing and retains the convergence property of multiplicative weight update algorithms with full information.
2	    Through simulation, we show that a very small amount of information, even with a delay, is adequate to nudge each other to select the right network and yield significantly faster stabilization at the optimal state (about 630x faster than EXP3).


# 335
### http://arxiv.org/abs/1901.08326v1
## A stack-vector routing protocol for automatic tunneling


0	    In a network, a tunnel is a part of a path where a protocol is encapsulated in another one.
1	    A tunnel starts with an encapsulation and ends with the corresponding decapsulation.
0	    Several tunnels can be nested at some stage, forming a protocol stack.
0	    Tunneling is very important nowadays and it is involved in several tasks: IPv4/IPv6 transition, VPNs, security (IPsec, onion routing), etc.
0	    However, tunnel establishment is mainly performed manually or by script, which present obvious scalability issues.
0	    Some works attempt to automate a part of the process (e.g., TSP, ISATAP, etc.).
0	    However, the determination of the tunnel(s) endpoints is not fully automated, especially in the case of an arbitrary number of nested tunnels.
0	    The lack of routing protocols performing automatic tunneling is due to the unavailability of path computation algorithms taking into account encapsulations and decapsulations.
1	    There is a polynomial centralized algorithm to perform the task.
0	    However, to the best of our knowledge, no fully distributed path computation algorithm is known.
1	    Here, we propose the first fully distributed algorithm for path computation with automatic tunneling, i.e., taking into account encapsulation, decapsulation and conversion of protocols.
1	    Our algorithm is a generalization of the distributed Bellman-Ford algorithm, where the distance vector is replaced by a protocol stack vector.
0	    This allows to know how to route a packet with some protocol stack.
2	    We prove that the messages size of our algorithm is polynomial, even if the shortest path can be of exponential length.
2	    We also prove that the algorithm converges after a polynomial number of steps in a synchronized setting.
1	    We adapt our algorithm into a proto-protocol for routing with automatic tunneling and we show its efficiency through simulations.


# 336
### http://arxiv.org/abs/1901.09418v1
## Double-Auction Mechanisms for Resource Trading Market


1	    We consider a double-auction mechanism, which was recently proposed in the context of a mobile data-offloading market.
1	    It is also applicable in a network slicing market.
1	    Network operators (users) derive benefit from offloading their traffic to third party WiFi or femtocell networks (link-suppliers).
0	    Link-suppliers experience costs for the additional capacity that they provide.
1	    Users and link-suppliers (collectively referred to as agents) have their pay-offs and cost functions as private knowledge.
1	    A system-designer decomposes the problem into a network problem and agent problems.
1	    The surrogate pay-offs and cost functions are modulated by the agents' bids.
1	    Agents' payoffs and costs are then determined by the allocations and prices set by the system designer.
1	    Under this design, so long as the agents do not anticipate the effect of their actions, a competitive equilibrium exists as a solution to the network and agent problems, and this equilibrium optimizes the system utility.
0	    However, this design fails when the agents are strategic (price-anticipating).
2	    The presence of strategic supplying agents drives the system to an undesirable equilibrium with zero participation resulting in an efficiency loss of 100%.
2	    This is in stark contrast to the setting when link-suppliers are not strategic: the efficiency loss is at most 34% when the users alone are strategic.
1	    The paper then proposes a Stackelberg game modification with asymmetric information structures for suppliers and users in order to alleviate the efficiency loss problem.
1	    The system designer first announces the allocation and payment functions.
1	    He then invites the supplying agents to announce their bids, following which the users are invited to respond to the suppliers' bids.
2	    The resulting Stackelberg games' efficiency losses can be characterized in terms of the suppliers' cost functions when the user pay-off functions are linear.


# 337
### http://arxiv.org/abs/1902.03649v1
## Physical Layer Identification based on Spatial-temporal Beam Features for Millimeter Wave Wireless Networks


0	    With millimeter wave (mmWave) wireless communication envisioned to be the key enabler of next generation high data rate wireless networks, security is of paramount importance.
0	    While conventional security measures in wireless networks operate at a higher layer of the protocol stack, physical layer security utilizes unique device dependent hardware features to identify and authenticate legitimate devices.
1	    In this work, we identify that the manufacturing tolerances in the antenna arrays used in mmWave devices contribute to a beam pattern that is unique to each device, and to that end we propose a novel device fingerprinting scheme based on the unique beam patterns used by the mmWave devices.
1	    Specifically, we propose a fingerprinting scheme with multiple access points (APs) to take advantage of the rich spatial-temporal information of the beam pattern.
1	    We perform comprehensive experiments with commercial off-the-shelf mmWave devices to validate the reliability performance of our proposed method under various scenarios.
1	    We also compare our beam pattern feature with a conventional physical layer feature namely power spectral density feature (PSD).
1	    To that end, we implement PSD feature based fingerprinting for mmWave devices.
2	    We show that the proposed multiple APs scheme is able to achieve over 99% identification accuracy for stationary LOS and NLOS scenarios and significantly outperform the PSD based method.
2	    For mobility scenarios, the overall identification accuracy is 96%.
1	    In addition, we perform security analysis of our proposed beam pattern fingerprinting system and PSD fingerprinting system by studying the feasibility of performing impersonation attacks.
1	    We design and implement an impersonation attack mechanism for mmWave wireless networks using state-of-the-art 60 GHz software defined radios.
2	    We discuss our findings and their implications on the security of the mmWave wireless networks.


# 338
### http://arxiv.org/abs/1902.04491v1
## SDN Controllers: Benchmarking & Performance Evaluation


1	    Software Defined Networks offer flexible and intelligent network operations by splitting a traditional network into a centralized control plane and a programmable data plane.
1	    The intelligent control plane is responsible for providing flow paths to switches and optimizes network performance.
1	    The controller in the control plane is the fundamental element used for all operations of data plane management.
0	    Hence, the performance and capabilities of the controller itself are extremely important.
2	    Furthermore, the tools used to benchmark their performance must be accurate and effective in measuring different evaluation parameters.
0	    There are dozens of controller proposals available in existing literature.
0	    However, there is no quantitative comparative analysis for them.
1	    In this article, we present a comprehensive qualitative comparison of different SDN controllers, along with a quantitative analysis of their performance in different network scenarios.
2	    More specifically, we categorize and classify 34 controllers based on their capabilities, and present a qualitative comparison of their properties.
2	    We also discuss in-depth capabilities of benchmarking tools used for SDN controllers, along with best practices for quantitative controller evaluation.
1	    This work uses three benchmarking tools to compare nine controllers against multiple criteria.
2	    Finally, we discuss detailed research findings on the performance, benchmarking criteria, and evaluation testbeds for SDN controllers.


# 339
### http://arxiv.org/abs/1902.05988v1
## DOCSDN: Dynamic and Optimal Configuration of Software-Defined Networks


0	    Networks are designed with functionality, security, performance, and cost in mind.
0	    Tools exist to check or optimize individual properties of a network.
2	    These properties may conflict, so it is not always possible to run these tools in series to find a configuration that meets all requirements.
1	    This leads to network administrators manually searching for a configuration.
1	    This need not be the case.
1	    In this paper, we introduce a layered framework for optimizing network configuration for functional and security requirements.
2	    Our framework is able to output configurations that meet reachability, bandwidth, and risk requirements.
1	    Each layer of our framework optimizes over a single property.
1	    A lower layer can constrain the search problem of a higher layer allowing the framework to converge on a joint solution.
2	    Our approach has the most promise for software-defined networks which can easily reconfigure their logical configuration.
1	    Our approach is validated with experiments over the fat tree topology, which is commonly used in data center networks.
1	    Search terminates in between 1-5 minutes in experiments.
0	    Thus, our solution can propose new configurations for short term events such as defending against a focused network attack.


# 340
### http://arxiv.org/abs/1902.07549v2
## Measurement and Analysis of the Bitcoin Networks: A View from Mining Pools


0	    Mining pools, the main components of the Bitcoin network, dominate the computing resources and play essential roles in network security and performance aspects.
0	    Although many existing measurements of the Bitcoin network are available, little is known about the details of mining pool behaviors (e.g., empty blocks, mining revenue and transaction collection strategies) and their effects on the Bitcoin end users (e.g., transaction fees, transaction delay and transaction acceptance rate).
0	    This paper aims to fill this gap with a systematic study of mining pools.
1	    We traced over 1.56 hundred thousand blocks (including about 257 million historical transactions) from February 2016 to January 2019 and collected over 120.25 million unconfirmed transactions from March 2018 to January 2019.
1	    Then we conducted a board range of measurements on the pool evolutions, labeled transactions (blocks) as well as real-time network traffics, and discovered new interesting observations and features.
2	    Specifically, our measurements show the following.
0	    1) A few mining pools entities continuously control most of the computing resources of the Bitcoin network.
0	    2) Mining pools are caught in a prisoner's dilemma where mining pools compete to increase their computing resources even though the unit profit of the computing resource decreases.
0	    3) Mining pools are stuck in a Malthusian trap where there is a stage at which the Bitcoin incentives are inadequate for feeding the exponential growth of the computing resources.
0	    4) The market price and transaction fees are not sensitive to the event of halving block rewards.
0	    5) The block interval of empty blocks is significantly lower than the block interval of non-empty blocks.
1	    6) Feerate plays a dominating role in transaction collection strategy for the top mining pools.
2	    Our measurements and analysis help to understand and improve the Bitcoin network.


# 341
### http://arxiv.org/abs/1902.10886v1
## An Investigation of Performance versus Security in Cognitive Radio Networks with Supporting Cloud Platforms


0	    The growth of wireless devices affects the availability of limited frequencies or spectrum bands as it has been known that spectrum bands are a natural resource that cannot be added.
0	    Meanwhile, the licensed frequencies are idle most of the time.
0	    Cognitive radio is one of the solutions to solve those problems.
0	    Cognitive radio is a promising technology that allows the unlicensed users, known as secondary users (SUs) to access licensed bands without making interference to licensed users or primary users (PUs).
0	    As cloud computing has become popular in recent years, cognitive radio networks (CRNs) can be integrated with the cloud platform.
0	    One of the important issues in CRNs is security.
0	    It becomes a problem since CRNs use radio frequencies as a medium for transmitting and CRNs share the same issues with wireless communication systems.
0	    Another critical issue in CRNs is performance.
0	    Security has an adverse effect to performance and there are trade-offs between them.
0	    The goal of this paper is to investigate the performance related to security trade-off in CRNs with supporting cloud platforms.
1	    Furthermore, Queuing Network Models with preemptive resume and preemptive repeat identical priority are applied in this project to measure the impact of security on performance in CRNs with or without cloud platform.
1	    The generalized exponential (GE) type distribution is used to reflect the bursty inter-arrival and service times at the servers.
2	    The results show that the best performance is obtained when security is disabled and the cloud platform is enabled.


# 342
### http://arxiv.org/abs/1903.05843v1
## ETGuard: Detecting D2D Attacks using Wireless Evil Twins


0	    In this paper, we demonstrate a realistic variant of wireless Evil Twins (ETs) for launching device to device (D2D) attacks over the network, particularly for Android.
1	    We show an attack where an ET infects an Android device before the relay of network traffic through it, and disappears from the network immediately after inflicting the device.
1	    The attack leverages the captive portal facility of wireless networks to launch D2D attack.
1	    We configure an ET to launch a malicious component of an already installed app in the device on submission of the portal page.
1	    In this paper, we present an online, incremental, automated, fingerprinting based pre-association detection mechanism named as ETGuard which works as a client-server mechanism in real-time.
1	    The fingerprints are constructed from the beacon frames transmitted by the wireless APs periodically to inform client devices of their presence and capabilities in a network.
1	    Once detected, ETGuard continuously transmits deauthentication frames to prevent clients from connecting to an ET.
1	    ETGuard outperforms the existing state-of-the-art techniques from various perspectives.
2	    Our technique does not require any expensive hardware, does not modify any protocols, does not rely on any network specific parameters such as Round Trip Time (RTT), number of hops, etc.,
0	    can be deployed in a real network, is incremental, and operates passively to detect ETs in real-time.
1	    To evaluate the efficiency, we deploy ETGuard in 802.11a/b/g wireless networks.
1	    The experiments are conducted using 12 different attack scenarios where each scenario differs in the source used for introducing an ET.
2	    ETGuard effectively detects ETs introduced either through a hardware, software, or mobile hotspot with high accuracy, only one false positive scenario, and no false negatives.


# 343
### http://arxiv.org/abs/1904.01168v1
## Blockchain-based Lightweight Authentication Mechanism for Vehicular Fog Infrastructure


0	    With the increasing development of advanced communication technologies, vehicles are becoming smarter and more connected.
0	    Due to the tremendous growth of various vehicular applications, a huge amount of data is generated through advanced on-board devices and is deemed critical to improve driving safety and enhance vehicular services.
0	    However, cloud based models often fall short in applications where latency and mobility are critical.
0	    In order to fully realize the potential of vehicular networks, the challenges of efficient communication and computation need to be addressed.
0	    In this direction, vehicular fog computing (VFC) has emerged which extends the concept of fog computing to conventional vehicular networks.
1	    It is a geographically distributed paradigm that has the potential to conduct time-critical and data-intensive tasks by pushing intelligence (i.e. computing resources, storage, and application services) in the vicinity of end vehicles.
0	    However secure and reliable transmission are of significant importance in highly-mobile vehicular networks in order to ensure the optimal Quality of Service (QoS).
0	    In this direction, several authentication mechanisms have been proposed in the literature but most of them are found unfit due to absence of decentralization, anonymity, and trust characteristics.
2	    Thus, an effective cross-datacenter authentication and key-exchange scheme based on blockchain and elliptic curve cryptography (ECC) is proposed in this paper.
1	    Here, the distributed ledger of blockchain is used for maintaining the network information while the highly secure ECC is employed for mutual authentication between vehicles and road side units (RSUs).
1	    Additionally, the proposed scheme is lightweight and scalable for the considered VFC setup.
2	    The performance evaluation results against the existing state-of-the-art reveal that the proposed scheme accomplishes enhanced security features.


# 345
### http://arxiv.org/abs/1708.01927v1
## Emotion Controlled Spectrum Mobility Scheme for Efficient Syntactic Interoperability In Cognitive Radio Based Internet of Vehicles


0	    Blind spots are one of the causes of road accidents in the hilly and flat areas.
0	    These blind spot accidents can be decreased by establishing an Internet of Vehicles (IoV) using Vehicle-2-Vehicle (V2V) and Vehicle-2-Infrastrtructure (V2I) communication systems.
0	    But the problem with these IoV is that most of them are using DSRC or single Radio Access Technology (RAT) as a wireless technology, which has been proven to be failed for efficient communication between vehicles.
0	    Recently, Cognitive Radio (CR) based IoV have to be proven best wireless communication systems for vehicular networks.
0	    However, the spectrum mobility is a challenging task to keep CR based vehicular networks interoperable and has not been addressed sufficiently in existing research.
0	    In our previous research work, the Cognitive Radio Site (CR-Site) has been proposed as in-vehicle CR-device, which can be utilized to establish efficient IoV systems.
1	    H In this paper, we have introduced the Emotions Inspired Cognitive Agent (EIC_Agent) based spectrum mobility mechanism in CR-Site and proposed a novel emotions controlled spectrum mobility scheme for efficient syntactic interoperability between vehicles.
1	    For this purpose, a probabilistic deterministic finite automaton using fear factor is proposed to perform efficient spectrum mobility using fuzzy logic.
1	    In addition, the quantitative computation of different fear intensity levels has been performed with the help of fuzzy logic.
1	    The system has been tested using active data from different GSM service providers on Mangla-Mirpur road.
2	    This is supplemented by extensive simulation experiments which validate the proposed scheme for CR based high-speed vehicular networks.
2	    The qualitative comparison with the existing-state-of the-art has proven the superiority of the proposed emotions controlled syntactic interoperable spectrum mobility scheme within cognitive radio based IoV systems.


# 346
### http://arxiv.org/abs/1709.03488v1
## Energy Harvesting Communications under Explicit and Implicit Temperature Constraints


1	    We consider an energy harvesting communication system where the temperature dynamics is governed by the transmission power policy.
1	    Different from the previous work, we consider a discrete time system where transmission power is kept constant in each slot.
1	    We consider two models that capture different effects of temperature.
1	    In the first model, the temperature is constrained to be below a critical temperature at all time instants; we coin this model as explicit temperature constrained model.
1	    We investigate throughput optimal power allocation for multiple energy arrivals under general, as well as temperature and energy limited regimes.
2	    We show that the optimal power allocation for the temperature limited case is monotone decreasing.
1	    In the second model, we consider the effect of the temperature on the channel quality via its influence on additive noise power; we coin this model as implicit temperature constrained model.
0	    In this model, the change in the variance of the additive noise due to previous transmissions is non-negligible.
2	    In particular, transmitted signals contribute as interference for all subsequent slots and thus affect the signal to interference plus noise ratio (SINR).
1	    In this case, we investigate throughput optimal power allocation under general, as well as low and high SINR regimes.
2	    We show in the low SINR regime that the optimal allocation dictates the transmitter to save its harvested energy till the last slot.
2	    In the high SINR regime, we show that the optimal power sequence is monotone increasing.
2	    Finally, we consider the case in which implicit and explicit temperature constraints are simultaneously active and we show under certain conditions that the optimal power sequence is monotone decreasing.


# 347
### http://arxiv.org/abs/1709.08577v1
## Coverage Analysis of a Vehicular Network Modeled as Cox Process Driven by Poisson Line Process


0	    In this paper, we consider a vehicular network in which the wireless nodes are located on a system of roads.
1	    We model the roadways, which are predominantly straight and randomly oriented, by a Poisson line process (PLP) and the locations of nodes on each road as a homogeneous 1D Poisson point process (PPP).
1	    Assuming that each node transmits independently, the locations of transmitting and receiving nodes are given by two Cox processes driven by the same PLP.
1	    For this setup, we derive the coverage probability of a typical receiver, which is an arbitrarily chosen receiving node, assuming independent Nakagami-$m$ fading over all wireless channels.
1	    Assuming that the typical receiver connects to its closest transmitting node in the network, we first derive the distribution of the distance between the typical receiver and the serving node to characterize the desired signal power.
1	    We then characterize coverage probability for this setup, which involves two key technical challenges.
1	    First, we need to handle several cases as the serving node can possibly be located on any line in the network and the corresponding interference experienced at the typical receiver is different in each case.
1	    Second, conditioning on the serving node imposes constraints on the spatial configuration of lines, which require careful analysis of the conditional distribution of the lines.
1	    We address these challenges in order to accurately characterize the interference experienced at the typical receiver.
1	    We then derive an exact expression for coverage probability in terms of the derivative of Laplace transform of interference power distribution.
1	    We analyze the trends in coverage probability as a function of the network parameters: line density and node density.
1	    We also study the asymptotic behavior of this model and compare the coverage performance with that of a homogeneous 2D PPP model with the same node density.


# 348
### http://arxiv.org/abs/1710.02035v1
## HANDY: A Hybrid Association Rules Mining Approach for Network Layer Discovery of Services for Mobile Ad hoc Network


0	    Mobile Ad hoc Network (MANET) is an infrastructure-less network formed between a set of mobile nodes.
0	    The discovery of services in MANET is a challenging job due to the unique properties of network.
0	    In this paper, a novel service discovery framework called Hybrid Association Rules Based Network Layer Discovery of Services for Ad hoc Networks (HANDY) has been proposed.
0	    HANDY provides three major research contributions.
1	    At first, it adopts a cross-layer optimized design for discovery of services that is based on simultaneous discovery of services and corresponding routes.
0	    Secondly, it provides a multi-level ontology-based approach to describe the services.
0	    This resolves the issue of semantic interoperability among the service consumers in a scalable fashion.
2	    Finally, to further optimize the performance of the discovery process, HANDY recommends exploiting the inherent associations present among the services.
1	    These associations are used in two ways.
1	    First, periodic service advertisements are performed based on these associations.
1	    In addition, when a response of a service discovery request is generated, correlated services are also attached with the response.
1	    The proposed service discovery scheme has been implemented in JIST/SWANS simulator.
2	    The results demonstrate that the proposed modifications give rise to improvement in hit ratio of the service consumers and latency of discovery process.


# 349
### http://arxiv.org/abs/1710.05748v2
## Performance Analysis of a Cooperative Wireless Network with Adaptive Relays: A Network-Level Study


1	    In this work, we investigate the stability region, the throughput performance, and the queueing delay of an asymmetric relay-assisted cooperative random access wireless network with multipacket reception (MPR) capabilities.
1	    We consider a network of $N$ saturated source users that transmit packets to a common destination node with the cooperation of two relay nodes.
1	    The relays are equipped with infinite capacity buffers, and assist the users by forwarding the packets that failed to reach the destination.
2	    Moreover, the relays have also packets of their own to transmit to the destination.
1	    We assume random access of the medium and slotted time.
1	    With the relay-assisted cooperation, the packets originated by each user can be transmitted to the destination through multiple relaying paths formed by the relays.
1	    We assume that the relays employ an adaptive retransmission control mechanism.
1	    In particular, a relay node is aware of the status of the other relay, and accordingly adapts its transmission probability.
0	    Such a protocol is towards self-aware networks and leads to substantial performance gains in terms of delay.
1	    We investigate the stability region and the throughput performance for the full MPR model.
1	    Moreover, for the two-user, two-relay case we derive the generating function of the stationary joint queue-length distribution at the relays by solving a Riemann-Hilbert boundary value problem.
1	    Finally, for the symmetric case we obtain explicit expressions for the average queueing delay in a relay node without the need of solving a boundary value problem.
2	    Numerical examples are presented providing insights on the system performance.


# 350
### http://arxiv.org/abs/1710.05981v1
## SpecWatch: A Framework for Adversarial Spectrum Monitoring with Unknown Statistics


0	    In cognitive radio networks (CRNs), dynamic spectrum access has been proposed to improve the spectrum utilization, but it also generates spectrum misuse problems.
0	    One common solution to these problems is to deploy monitors to detect misbehaviors on certain channel.
0	    However, in multi-channel CRNs, it is very costly to deploy monitors on every channel.
0	    With a limited number of monitors, we have to decide which channels to monitor.
0	    In addition, we need to determine how long to monitor each channel and in which order to monitor, because switching channels incurs costs.
1	    Moreover, the information about the misuse behavior is not available a priori.
1	    To answer those questions, we model the spectrum monitoring problem as an adversarial multi-armed bandit problem with switching costs (MAB-SC), propose an effective framework, and design two online algorithms, SpecWatch-II and SpecWatch-III, based on the same framework.
1	    To evaluate the algorithms, we use weak regret, i.e., the performance difference between the solution of our algorithm and optimal (fixed) solution in hindsight, as the metric.
2	    We prove that the expected weak regret of SpecWatch-II is O(T^{2/3}), where T is the time horizon.
2	    Whereas, the actual weak regret of SpecWatch-III is O(T^{2/3}) with probability 1 - {\delta}, for any {\delta} in (0, 1).
1	    Both algorithms guarantee the upper bounds matching the lower bound of the general adversarial MAB- SC problem.
0	    Therefore, they are all asymptotically optimal.


# 351
### http://arxiv.org/abs/1712.00635v2
## Network Coding Based Evolutionary Network Formation for Dynamic Wireless Networks


1	    In this paper, we aim to find a robust network formation strategy that can adaptively evolve the network topology against network dynamics in a distributed manner.
1	    We consider a network coding deployed wireless ad hoc network where source nodes are connected to terminal nodes with the help of intermediate nodes.
2	    We show that mixing operations in network coding can induce packet anonymity that allows the inter-connections in a network to be decoupled.
1	    This enables each intermediate node to consider complex network inter-connections as a node-environment interaction such that the Markov decision process (MDP) can be employed at each intermediate node.
1	    The optimal policy that can be obtained by solving the MDP provides each node with optimal amount of changes in transmission range given network dynamics (e.g., the number of nodes in the range and channel condition).
0	    Hence, the network can be adaptively and optimally evolved by responding to the network dynamics.
1	    The proposed strategy is used to maximize long-term utility, which is achieved by considering both current network conditions and future network dynamics.
1	    We define the utility of an action to include network throughput gain and the cost of transmission power.
2	    We show that the resulting network of the proposed strategy eventually converges to stationary networks, which maintain the states of the nodes.
1	    Moreover, we propose to determine initial transmission ranges and initial network topology that can expedite the convergence of the proposed algorithm.
2	    Our simulation results confirm that the proposed strategy builds a network which adaptively changes its topology in the presence of network dynamics.
2	    Moreover, the proposed strategy outperforms existing strategies in terms of system goodput and successful connectivity ratio.


# 352
### http://arxiv.org/abs/1712.02617v1
## The Engineering of a Scalable Multi-Site Communications System Utilizing Quantum Key Distribution (QKD)


0	    Quantum Key Distribution (QKD) is a means of generating keys between a pair of computing hosts that is theoretically secure against cryptanalysis, even by a quantum computer.
0	    Although there is much active research into improving the QKD technology itself, there is still significant work to be done to apply engineering methodology and determine how it can be practically built to scale within an enterprise IT environment.
0	    Significant challenges exist in building a practical key management service for use in a metropolitan network.
0	    QKD is generally a point-to-point technique only and is subject to steep performance constraints.
1	    The integration of QKD into enterprise-level computing has been researched, to enable quantum-safe communication.
1	    A novel method for constructing a key management service is presented that allows arbitrary computing hosts on one site to establish multiple secure communication sessions with the hosts of another site.
0	    A key exchange protocol is proposed where symmetric private keys are granted to hosts while satisfying the scalability needs of an enterprise population of users.
1	    The key management service operates within a layered architectural style that is able to interoperate with various underlying QKD implementations.
0	    Variable levels of security for the host population are enforced through a policy engine.
0	    A network layer provides key generation across a network of nodes connected by quantum links.
0	    Scheduling and routing functionality allows quantum key material to be relayed across trusted nodes.
1	    Optimizations are performed to match the real-time host demand for key material with the capacity afforded by the infrastructure.
1	    The result is a flexible and scalable architecture that is suitable for enterprise use and independent of any specific QKD technology.


# 353
### http://arxiv.org/abs/1712.03530v1
## Datacenter Traffic Control: Understanding Techniques and Trade-offs


0	    Datacenters provide cost-effective and flexible access to scalable compute and storage resources necessary for today's cloud computing needs.
1	    A typical datacenter is made up of thousands of servers connected with a large network and usually managed by one operator.
0	    To provide quality access to the variety of applications and services hosted on datacenters and maximize performance, it deems necessary to use datacenter networks effectively and efficiently.
0	    Datacenter traffic is often a mix of several classes with different priorities and requirements.
0	    This includes user-generated interactive traffic, traffic with deadlines, and long-running traffic.
1	    To this end, custom transport protocols and traffic management techniques have been developed to improve datacenter network performance.
1	    In this tutorial paper, we review the general architecture of datacenter networks, various topologies proposed for them, their traffic properties, general traffic control challenges in datacenters and general traffic control objectives.
0	    The purpose of this paper is to bring out the important characteristics of traffic control in datacenters and not to survey all existing solutions (as it is virtually impossible due to massive body of existing research).
0	    We hope to provide readers with a wide range of options and factors while considering a variety of traffic control mechanisms.
1	    We discuss various characteristics of datacenter traffic control including management schemes, transmission control, traffic shaping, prioritization, load balancing, multipathing, and traffic scheduling.
1	    Next, we point to several open challenges as well as new and interesting networking paradigms.
1	    At the end of this paper, we briefly review inter-datacenter networks that connect geographically dispersed datacenters which have been receiving increasing attention recently and pose interesting and novel research problems.


# 354
### http://arxiv.org/abs/1712.04301v2
## Deep Learning for IoT Big Data and Streaming Analytics: A Survey


0	    In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications.
2	    Based on the nature of the application, these devices will result in big or fast/real-time data streams.
2	    Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology.
1	    In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely Deep Learning (DL), to facilitate the analytics and learning in the IoT domain.
1	    We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics.
2	    We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications.
1	    The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced.
1	    We present a comprehensive background on different DL architectures and algorithms.
1	    We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain.
1	    The smart IoT devices that have incorporated DL in their intelligence background are also discussed.
1	    DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed.
1	    Finally, we shed light on some challenges and potential directions for future research.
1	    At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.


# 355
### http://arxiv.org/abs/1712.09623v1
## An empirical evaluation for the intrusion detection features based on machine learning and feature selection methods


0	    Despite the great developments in information technology, particularly the Internet, computer networks, global information exchange, and its positive impact in all areas of daily life, it has also contributed to the development of penetration and intrusion which forms a high risk to the security of information organizations, government agencies, and causes large economic losses.
0	    There are many techniques designed for protection such as firewall and intrusion detection systems (IDS).
1	    IDS is a set of software and/or hardware techniques used to detect hacker's activities in computer systems.
1	    Two types of anomalies are used in IDS to detect intrusive activities different from normal user behavior.
1	    Misuse relies on the knowledge base that contains all known attack techniques and intrusion is discovered through research in this knowledge base.
0	    Artificial intelligence techniques have been introduced to improve the performance of these systems.
1	    The importance of IDS is to identify unauthorized access attempting to compromise confidentiality, integrity or availability of the computer network.
1	    This paper investigates the Intrusion Detection (ID) problem using three machine learning algorithms namely, BayesNet algorithm, Multi-Layer Perceptron (MLP), and Support Vector Machine (SVM).
1	    The algorithms are applied on a real, Management Information Based (MIB) dataset that is collected from real life environment.
1	    To enhance the detection process accuracy, a set of feature selection approaches is used; Infogain (IG), ReleifF (RF), and Genetic Search (GS).
2	    Our experiments show that the three feature selection methods have enhanced the classification performance.
2	    GS with bayesNet, MLP and SVM give high accuracy rates, more specifically the BayesNet with the GS accuracy rate is 99.9%.


# 356
### http://arxiv.org/abs/1803.05290v1
## Optimization of Scheduling in Wireless Ad-Hoc Networks Using Matrix Games


0	    In this paper, we present a novel application of matrix game theory for optimization of link scheduling in wireless ad-hoc networks.
1	    Optimum scheduling is achieved by soft coloring of network graphs.
1	    Conventional coloring schemes are based on assignment of one color to each region or equivalently each link is member of just one partial topology.
1	    These algorithms based on coloring are not optimal when links are not activated with the same rate.
0	    Soft coloring, introduced in this paper, solves this problem and provide optimal solution for any requested link usage rate.
0	    To define the game model for optimum scheduling, first all possible components of the graph are identified.
0	    Components are defined as sets of the wireless links can be activated simultaneously without suffering from mutual interference.
2	    Then by switching between components with appropriate frequencies (usage rate) optimum scheduling is achieved.
1	    We call this kind of scheduling as soft coloring because any links can be member of more than one partial topology, in different time segments.
1	    To simplify this problem, we model relationship between link rates and components selection frequencies by a matrix game which provides a simple and helpful tool to simplify and solve the problem.
1	    This proposed game theoretic model is solved by fictitious playing method.
2	    Simulation results prove the efficiency of the proposed technique compared to conventional scheduling based on coloring


# 357
### http://arxiv.org/abs/1804.09689v2
## Joint Energy and SINR Coverage in Spatially Clustered RF-powered IoT Network


0	    Owing to the ubiquitous availability of radio-frequency (RF) signals, RF energy harvesting is emerging as an appealing solution for powering IoT devices.
1	    In this paper, we model and analyze an IoT network which harvests RF energy and receives information from the same wireless network.
1	    In order to enable this operation, each time slot is partitioned into charging and information reception phases.
1	    For this setup, we characterize two performance metrics: (i) energy coverage and (ii) joint signal-to-interference-plus-noise (SINR) and energy coverage.
1	    The analysis is performed using a realistic spatial model that captures the spatial coupling between the locations of the IoT devices and the nodes of the wireless network (referred henceforth as the IoT gateways), which is often ignored in the literature.
1	    In particular, we model the locations of the IoT devices using a Poisson cluster process (PCP) and assume that some of the clusters have IoT gateways (GWs) deployed at their centers while the other GWs are deployed independently of the IoT devices.
2	    The level of coupling can be controlled by tuning the fraction of total GWs that are deployed at the cluster centers.
1	    Due to the inherent intractability of computing the distribution of shot noise process for this setup, we propose two accurate approximations, using which the aforementioned metrics are characterized.
1	    Multiple system design insights are drawn from our results.
1	    For instance, we demonstrate the existence of optimal slot partitioning that maximizes the system throughput.
1	    In addition, we explore the effect of the level of coupling between the locations of the IoT devices and the GWs on this optimal slot partitioning.
2	    Particularly, our results reveal that the optimal value of time duration for the charging phase increases as the level of coupling decreases.


# 358
### http://arxiv.org/abs/1804.10778v4
## Hidden Vehicles Positioning via Asynchronous V2V Transmission: A Multi-Path-Geometry Approach


0	    Accurate vehicular sensing is a basic and important operation in autonomous driving.
0	    Unfortunately, the existing techniques have their own limitations.
0	    For instance, the GPS-based approach (e.g., transmission of GPS information) has high latency and low reliability while the reflection-based approach (e.g., RADAR) is incapable of detecting hidden vehicles (HVs) without line-of-sight.
0	    This is arguably the reason behind some recent fatal accidents involving autonomous vehicles.
1	    To address this issue, this paper presents a novel HV-sensing technology that exploits multi-path transmission from a HV to a sensing vehicle (SV).
2	    The powerful technology enables the SV to detect multiple HV-state parameters including position, orientation of driving direction, and size.
2	    Its implementation does not even require transmitter-receiver synchronization like the conventional microwave positioning techniques.
1	    Our design approach leverages estimated information on multi-path (namely their AoA, AoD, and ToA) and their geometric relations.
1	    As a result, a complex system of equations or optimization problems, where the desired HV-state parameters are variables, can be formulated for different channel-noise conditions.
1	    The development of intelligent solution methods ranging from least-square estimator to disk/box minimization yields a set of practical HV-sensing techniques.
1	    We study their feasibility conditions in terms of the required number of paths.
1	    Furthermore, practical solutions, including sequential path combining and random directional beamforming, are proposed to enable HV-sensing given insufficient paths.
2	    Last, realistic simulation of driving in both highway and rural scenarios demonstrates the effectiveness of the proposed techniques.
1	    In summary, the proposed technique will enhance the capabilities of existing vehicular sensing technologies (e.g., RADAR and LIDAR) by enabling HV sensing.


# 359
### http://arxiv.org/abs/1806.06185v1
## EdgeChain: An Edge-IoT Framework and Prototype Based on Blockchain and Smart Contracts


0	    The emerging Internet of Things (IoT) is facing significant scalability and security challenges.
0	    On the one hand, IoT devices are "weak" and need external assistance.
0	    Edge computing provides a promising direction addressing the deficiency of centralized cloud computing in scaling massive number of devices.
0	    On the other hand, IoT devices are also relatively "vulnerable" facing malicious hackers due to resource constraints.
1	    The emerging blockchain and smart contracts technologies bring a series of new security features for IoT and edge computing.
1	    In this paper, to address the challenges, we design and prototype an edge-IoT framework named "EdgeChain" based on blockchain and smart contracts.
1	    The core idea is to integrate a permissioned blockchain and the internal currency or "coin" system to link the edge cloud resource pool with each IoT device' account and resource usage, and hence behavior of the IoT devices.
1	    EdgeChain uses a credit-based resource management system to control how much resource IoT devices can obtain from edge servers, based on pre-defined rules on priority, application types and past behaviors.
1	    Smart contracts are used to enforce the rules and policies to regulate the IoT device behavior in a non-deniable and automated manner.
1	    All the IoT activities and transactions are recorded into blockchain for secure data logging and auditing.
1	    We implement an EdgeChain prototype and conduct extensive experiments to evaluate the ideas.
2	    The results show that while gaining the security benefits of blockchain and smart contracts, the cost of integrating them into EdgeChain is within a reasonable and acceptable range.


# 360
### http://arxiv.org/abs/1807.11023v1
## A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security


0	    The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention.
0	    It is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020.
0	    On the one hand, IoT play a crucial role in enhancing several real-life smart applications that can improve life quality.
0	    On the other hand, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems introduced new security challenges.
0	    Implementing security measures, such as encryption, authentication, access control, network security and application security, for IoT devices and their inherent vulnerabilities is ineffective.
2	    Therefore, existing security methods should be enhanced to secure the IoT system effectively.
2	    Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory curiosity to practical machinery in several important applications.
0	    Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems.
0	    The goal of this work is to provide a comprehensive survey of ML /DL methods that can be used to develop enhanced security methods for IoT systems.
1	    IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed.
1	    We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method.
1	    We discuss the opportunities and challenges involved in applying ML/DL to IoT security.
2	    These opportunities and challenges can serve as potential future research directions.


# 361
### http://arxiv.org/abs/1810.09300v3
## RCanopus: Making Canopus Resilient to Failures and Byzantine Faults


0	    Distributed consensus is a key enabler for many distributed systems including distributed databases and blockchains.
1	    Canopus is a scalable distributed consensus protocol that ensures that live nodes in a system agree on an ordered sequence of operations (called transactions).
0	    Unlike most prior consensus protocols, Canopus does not rely on a single leader.
0	    Instead, it uses a virtual tree overlay for message dissemination to limit network traffic across oversubscribed links.
1	    It leverages hardware redundancies, both within a rack and inside the network fabric, to reduce both protocol complexity and communication overhead.
2	    These design decisions enable Canopus to support large deployments without significant performance degradation.
2	    The existing Canopus protocol is resilient in the face of node and communication failures, but its focus is primarily on performance, so does not respond well to other types of failures.
1	    For example, the failure of a single rack of servers causes all live nodes to stall.
1	    The protocol is also open to attack by Byzantine nodes, which can cause different live nodes to conclude the protocol with different transaction orders.
1	    In this paper, we describe RCanopus (`resilent Canopus') which extends Canopus to add liveness, that is, allowing live nodes to make progress, when possible, despite many types of failures.
0	    This requires RCanopus to accurately detect and recover from failure despite using unreliable failure detectors, and tolerance of Byzantine attacks.
1	    Second, RCanopus guarantees safety, that is, agreement amongst live nodes of transaction order, in the presence of Byzantine attacks and network partitioning.


# 362
### http://arxiv.org/abs/1811.02964v1
## Instantly Deployable Expert Knowledge - Networks of Knowledge Engines


0	    Knowledge and information are becoming the primary resources of the emerging information society.
0	    To exploit the potential of available expert knowledge, comprehension and application skills (i.e. expert competences) are necessary.
2	    The ability to acquire these skills is limited for any individual human.
0	    Consequently, the capacities to solve problems based on human knowledge in a manual (i.e. mental) way are strongly limited.
1	    We envision a new systemic approach to enable scalable knowledge deployment without expert competences.
1	    Eventually, the system is meant to instantly deploy humanity's total knowledge in full depth for every individual challenge.
1	    To this end, we propose a socio-technical framework that transforms expert knowledge into a solution creation system.
1	    Knowledge is represented by automated algorithms (knowledge engines).
0	    Executable compositions of knowledge engines (networks of knowledge engines) generate requested individual information at runtime.
1	    We outline how these knowledge representations could yield legal, ethical and social challenges and nurture new business and remuneration models on knowledge.
1	    We identify major technological and economic concepts that are already pushing the boundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge bases, ontologies, advanced search tools, automation of knowledge work, the API economy.
2	    We indicate impacts on society, economy and labour.
1	    Existing developments are linked, including a specific use case in engineering design.


# 363
### http://arxiv.org/abs/1901.10933v1
## Securing Fog-to-Things Environment Using Intrusion Detection System Based On Ensemble Learning


0	    The growing interest in the Internet of Things (IoT) applications is associated with an augmented volume of security threats.
0	    In this vein, the Intrusion detection systems (IDS) have emerged as a viable solution for the detection and prevention of malicious activities.
0	    Unlike the signature-based detection approaches, machine learning-based solutions are a promising means for detecting unknown attacks.
0	    However, the machine learning models need to be accurate enough to reduce the number of false alarms.
2	    More importantly, they need to be trained and evaluated on realistic datasets such that their efficacy can be validated on real-time deployments.
0	    Many solutions proposed in the literature are reported to have high accuracy but are ineffective in real applications due to the non-representativity of the dataset used for training and evaluation of the underlying models.
0	    On the other hand, some of the existing solutions overcome these challenges but yield low accuracy which hampers their implementation for commercial tools.
1	    These solutions are majorly based on single learners and are therefore directly affected by the intrinsic limitations of each learning algorithm.
1	    The novelty of this paper is to use the most realistic dataset available for intrusion detection called NSL-KDD, and combine multiple learners to build ensemble learners that increase the accuracy of the detection.
1	    Furthermore, a deployment architecture in a fog-to-things environment that employs two levels of classifications is proposed.
1	    In such architecture, the first level performs an anomaly detection which reduces the latency of the classification substantially, while the second level, executes attack classifications, enabling precise prevention measures.
2	    Finally, the experimental results demonstrate the effectiveness of the proposed IDS in comparison with the other state-of-the-arts on the NSL-KDD dataset.


# 364
### http://arxiv.org/abs/1902.10319v1
## Neural Packet Classification


0	    Packet classification is a fundamental problem in computer networking.
0	    This problem exposes a hard tradeoff between the computation and state complexity, which makes it particularly challenging.
0	    To navigate this tradeoff, existing solutions rely on complex hand-tuned heuristics, which are brittle and hard to optimize.
1	    In this paper, we propose a deep reinforcement learning (RL) approach to solve the packet classification problem.
0	    There are several characteristics that make this problem a good fit for Deep RL.
1	    First, many of the existing solutions are iteratively building a decision tree by splitting nodes in the tree.
1	    Second, the effects of these actions (e.g., splitting nodes) can only be evaluated once we are done with building the tree.
1	    These two characteristics are naturally captured by the ability of RL to take actions that have sparse and delayed rewards.
1	    Third, it is computationally efficient to generate data traces and evaluate decision trees, which alleviate the notoriously high sample complexity problem of Deep RL algorithms.
1	    Our solution, NeuroCuts, uses succinct representations to encode state and action space, and efficiently explore candidate decision trees to optimize for a global objective.
1	    It produces compact decision trees optimized for a specific set of rules and a given performance metric, such as classification time, memory footprint, or a combination of the two.
2	    Evaluation on ClassBench shows that NeuroCuts outperforms existing hand-crafted algorithms in classification time by 18% at the median, and reduces both time and memory footprint by up to 3x.


# 365
### http://arxiv.org/abs/1903.01073v1
## Designing Optimal Multiplex Networks for Certain Laplacian Spectral Properties


1	    We discuss the design of interlayer edges in a multiplex network, under a limited budget, with the goal of improving its overall performance.
1	    We analyze the following three problems separately; first, we maximize the smallest nonzero eigenvalue, also known as the algebraic connectivity; secondly, we minimize the largest eigenvalue, also known as the spectral radius; and finally, we minimize the spectral width.
0	    Maximizing the algebraic connectivity requires identical weights on the interlayer edges for budgets less than a threshold value.
0	    However, for larger budgets, the optimal weights are generally non-uniform.
1	    The dual formulation transforms the problem into a graph realization (embedding) problem that allows us to give a fuller picture.
1	    Namely, before the threshold budget, the optimal realization is one-dimensional with nodes in the same layer embedded to a single point; while, beyond the threshold, the optimal embeddings generally unfold into spaces with dimension bounded by the multiplicity of the algebraic connectivity.
2	    Finally, for extremely large budgets the embeddings revert again to lower dimensions.
1	    Minimizing the largest eigenvalue is driven by the spectral radius of the individual networks and its corresponding eigenvector.
1	    Before a threshold, the total budget is distributed among interlayer edges corresponding to the nodal lines of this eigenvector, and the optimal largest eigenvalue of the Laplacian remains constant.
2	    For larger budgets, the weight distribution tends to be almost uniform.
1	    In the dual picture, the optimal graph embedding is one-dimensional and non-homogeneous at first and beyond this threshold, the optimal embedding expands to be multi-dimensional, and for larger values of the budget, the two layers fill the embedding space.
2	    Finally, we show how these two problems are connected to minimizing the spectral width.


# 366
### http://arxiv.org/abs/1903.04844v1
## Satellite Based IoT for MC Applications


0	    In the recent years, world has witnessed the ubiquitous applications of Internet of things (IoT) for many different scenarios.
0	    There are several critical applications where the results are essential and the mission has to be successful at any cost.
0	    Such applications are well known as mission critical applications.
0	    These applications are really critical and deal with very serious situations such as disaster management, rescue operations and military applications.
0	    IoT can provide both accuracy and sustainability in these applications.
0	    IoT in fact, is suitable for several critical applications because it can be deployed at locations where human presence is not possible due to the dangers to human life.
0	    In such cases, collection of information can be done through IoT sensors and it can be sent directly to the processing hubs.
2	    These days we find several mission critical applications where both increased reliability and coverage have very high priorities.
0	    Hybridization of IoT and satellite networks can be a game changer in these applications.
1	    In this article, we present the general features of mission critical IoT and the motivation for connecting it with the satellite networks.
1	    Then we present the main deployment related issues of these hybrid networks.
1	    We focused on the hybridization aspects of narrowband IoT (NBIoT) with the satellite networks.
0	    Because NBIoT has the energy efficiency which can make the satellite based IoT networks sustainable in the long term.


# 367
### http://arxiv.org/abs/1404.6687v1
## When Queueing Meets Coding: Optimal-Latency Data Retrieving Scheme in Storage Clouds


1	    In this paper, we study the problem of reducing the delay of downloading data from cloud storage systems by leveraging multiple parallel threads, assuming that the data has been encoded and stored in the clouds using fixed rate forward error correction (FEC) codes with parameters (n, k).
1	    That is, each file is divided into k equal-sized chunks, which are then expanded into n chunks such that any k chunks out of the n are sufficient to successfully restore the original file.
1	    The model can be depicted as a multiple-server queue with arrivals of data retrieving requests and a server corresponding to a thread.
0	    However, this is not a typical queueing model because a server can terminate its operation, depending on when other servers complete their service (due to the redundancy that is spread across the threads).
0	    Hence, to the best of our knowledge, the analysis of this queueing model remains quite uncharted.
0	    Recent traces from Amazon S3 show that the time to retrieve a fixed size chunk is random and can be approximated as a constant delay plus an i.i.d.
1	    exponentially distributed random variable.
1	    For the tractability of the theoretical analysis, we assume that the chunk downloading time is i.i.d.
2	    Under this assumption, we show that any work-conserving scheme is delay-optimal among all on-line scheduling schemes when k = 1.
1	    When k > 1, we find that a simple greedy scheme, which allocates all available threads to the head of line request, is delay optimal among all on-line scheduling schemes.
2	    We also provide some numerical results that point to the limitations of the exponential assumption, and suggest further research directions.


# 368
### http://arxiv.org/abs/1804.04048v1
## Cost-Aware Learning and Optimization for Opportunistic Spectrum Access


0	    In this paper, we investigate cost-aware joint learning and optimization for multi-channel opportunistic spectrum access in a cognitive radio system.
1	    We investigate a discrete time model where the time axis is partitioned into frames.
1	    Each frame consists of a sensing phase, followed by a transmission phase.
0	    During the sensing phase, the user is able to sense a subset of channels sequentially before it decides to use one of them in the following transmission phase.
1	    We assume the channel states alternate between busy and idle according to independent Bernoulli random processes from frame to frame.
1	    To capture the inherent uncertainty in channel sensing, we assume the reward of each transmission when the channel is idle is a random variable.
1	    We also associate random costs with sensing and transmission actions.
1	    Our objective is to understand how the costs and reward of the actions would affect the optimal behavior of the user in both offline and online settings, and design the corresponding opportunistic spectrum access strategies to maximize the expected cumulative net reward (i.e., reward-minus-cost).
1	    We start with an offline setting where the statistics of the channel status, costs and reward are known beforehand.
2	    We show that the the optimal policy exhibits a recursive double threshold structure, and the user needs to compare the channel statistics with those thresholds sequentially in order to decide its actions.
1	    With such insights, we then study the online setting, where the statistical information of the channels, costs and reward are unknown a priori.
1	    We judiciously balance exploration and exploitation, and show that the cumulative regret scales in O(log T).
1	    We also establish a matched lower bound, which implies that our online algorithm is order-optimal.
2	    Simulation results corroborate our theoretical analysis.


